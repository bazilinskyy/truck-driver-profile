{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis**\n",
    "\n",
    "In this notebook we will explore the different datasets and visualize them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\AOS_SUMMARY.csv',delimiter=';', encoding='unicode_escape',usecols=[\"Latitude\",\"Longitude\",\"Road_type\",\"Event/action_type\"])\n",
    "\n",
    "# headway_warning=[41]\n",
    "df = df[df['Event/action_type']==41]\n",
    "# df = df[df['Road_type']==0]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\brake_warnings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from pathlib import *\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,plot,iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import hvplot.pandas\n",
    "import holoviews as hv, pandas as pd, colorcet as cc\n",
    "from holoviews.element.tiles import EsriImagery\n",
    "from holoviews.operation.datashader import datashade\n",
    "hv.extension('bokeh')\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import os\n",
    "import datashader\n",
    "import datashader.transfer_functions\n",
    "from datashader.utils import lnglat_to_meters\n",
    "from bokeh.models import BoxZoomTool\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from datashader.utils import lnglat_to_meters\n",
    "from bokeh.tile_providers import get_provider, Vendors \n",
    "import holoviews.operation.datashader as hd\n",
    "from datashader.colors import Hot\n",
    "import datashader as ds\n",
    "from datashader import transfer_functions as tf\n",
    "from datashader.colors import Greys9\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bokeh Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Class for viz aos data points -- Bokeh Plots \n",
    "class Map_Viz:\n",
    "    \n",
    "    # Define general parameters for the Bokeh plot\n",
    "    Netherlands = x_range, y_range = ((384019.630105,865878.656414), (6577253.409883,7156951.832398))\n",
    "\n",
    "    plot_width  = int(990)\n",
    "    plot_height = int(plot_width//1.2)\n",
    "\n",
    "    \n",
    "    tile_provider = get_provider(Vendors.CARTODBPOSITRON)\n",
    "    \n",
    "    def __init__(self,event_file_name):\n",
    "        self.event_file_name=event_file_name\n",
    "        \n",
    "    def import_data_aos(self):\n",
    "        \"\"\"\n",
    "        Load data from a csv file.\n",
    "        \"\"\"\n",
    "        fields = ['Latitude', 'Longitude']\n",
    "        complete_path=os.path.join(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\", self.event_file_name)\n",
    "        df=pd.read_csv(complete_path,delimiter=';', skipinitialspace=True, usecols=fields, encoding= 'unicode_escape',dtype={'Latitude': float,'Longitude':float},skiprows=range(1,2))\n",
    "        return df\n",
    "\n",
    "    # Reusable function to create simple Bokeh plots\n",
    "\n",
    "    def base_plot(self,tools='pan,wheel_zoom,reset', plot_width=plot_width, plot_height=plot_height, **plot_kwargs):\n",
    "        base_plot = figure(tools=tools, plot_width=Map_Viz.plot_width, plot_height=Map_Viz.plot_height,\n",
    "            x_range=Map_Viz.x_range, y_range=Map_Viz.y_range, outline_line_color=None,\n",
    "            min_border=0, min_border_left=0, min_border_right=0,\n",
    "            min_border_top=0, min_border_bottom=0, **plot_kwargs)\n",
    "        \n",
    "        base_plot.axis.visible = False\n",
    "        base_plot.xgrid.grid_line_color = None\n",
    "        base_plot.ygrid.grid_line_color = None\n",
    "        \n",
    "        base_plot.add_tools(BoxZoomTool(match_aspect=True))\n",
    "        \n",
    "        return base_plot\n",
    "    \n",
    "    def process_data(self):\n",
    "        df=self.import_data_aos()\n",
    "        df[\"Longitude\"] = df[\"Longitude\"].astype(float)\n",
    "        df[\"Latitude\"] = df[\"Latitude\"].astype(float)\n",
    "        \n",
    "        df.loc[:, 'Longitude'], df.loc[:, 'Latitude'] = lnglat_to_meters(df.Longitude,df.Latitude)\n",
    "        \n",
    "        return df       \n",
    "    \n",
    "    def plot_map(self,number_of_data_points):\n",
    "        df=self.process_data()\n",
    "        samples = df.sample(n=number_of_data_points)\n",
    "        p = self.base_plot()\n",
    "        p.add_tile(Map_Viz.tile_provider)\n",
    "        options = dict(line_color=None, fill_color='forestgreen', size=5)\n",
    "        p.circle(x=samples['Longitude'], y=samples['Latitude'], **options)\n",
    "        show(p)\n",
    "    \n",
    "    def plot_map_better(self,number_of_data_points):\n",
    "        df=self.process_data()\n",
    "        samples = df.sample(n=number_of_data_points)\n",
    "        options = dict(line_color=None, fill_color='forestgreen', size=1, alpha=0.1)\n",
    "        p = self.base_plot()\n",
    "        p.add_tile(Map_Viz.tile_provider)\n",
    "        p.circle(x=samples['Longitude'], y=samples['Latitude'], **options)\n",
    "        show(p)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "map_viz = Map_Viz(\"AOS_SUMMARY.csv\")\n",
    "\n",
    "\"\"\"Plotting individual events -- uncomment below\"\"\"\n",
    "# map_viz=Map_Viz(\"brake_warnings.csv\") \n",
    "# map_viz=Map_Viz(\"headway_warnings.csv\")\n",
    "# map_viz=Map_Viz(\"right_left_lane_departure_warning.csv\")\n",
    "\n",
    "# map_viz.plot_map(number_of_data_points=1000000) # overplotting\n",
    "map_viz.plot_map_better(number_of_data_points=1000000) # no overplotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Class for viz all data points\n",
    "\"\"\"https://datashader.org/ --> Big data viz library \"\"\"\n",
    "\n",
    "class Map_Viz_Datashader:\n",
    "    plot_width  = int(990)\n",
    "    plot_height = int(plot_width//1.2)\n",
    "    Netherlands = x_range, y_range = ((384019.630105,865878.656414), (6577253.409883,7156951.832398))\n",
    "    def __init__(self,event_file_name):\n",
    "        self.event_file_name=event_file_name\n",
    "        \n",
    "        \n",
    "    def import_data_td(self):\n",
    "        \"\"\"\n",
    "        Load data from a csv file.\n",
    "        \"\"\"\n",
    "\n",
    "        fields = ['Latitude', 'Longitude']\n",
    "        complete_path=os.path.join(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\", self.event_file_name)\n",
    "        df=pd.read_csv(complete_path,delimiter=';', skipinitialspace=True, usecols=fields, encoding= 'unicode_escape',dtype={'Latitude': float,'Longitude':float},skiprows=range(1,2))\n",
    "        return df\n",
    "        \n",
    "    def import_data_aos(self):\n",
    "            fields = ['Latitude', 'Longitude']\n",
    "            complete_path=os.path.join(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\", self.event_file_name)\n",
    "            df=pd.read_csv(complete_path,delimiter=';', skipinitialspace=True, usecols=fields, encoding= 'unicode_escape',dtype={'Latitude': float,'Longitude':float},skiprows=range(1,2))\n",
    "        \n",
    "            return df\n",
    "        \n",
    "    def process_data_aos(self):\n",
    "        df=self.import_data_aos()\n",
    "        df[\"Longitude\"] = df[\"Longitude\"].astype(float)\n",
    "        df[\"Latitude\"] = df[\"Latitude\"].astype(float)\n",
    "        \n",
    "        df.loc[:, 'Longitude'], df.loc[:, 'Latitude'] = lnglat_to_meters(df.Longitude,df.Latitude)\n",
    "        \n",
    "        return df    \n",
    "    \n",
    "    def process_data_td(self):\n",
    "        df=self.import_data_td()\n",
    "        df[\"Longitude\"] = df[\"Longitude\"].astype(float)\n",
    "        df[\"Latitude\"] = df[\"Latitude\"].astype(float)\n",
    "        \n",
    "        df.loc[:, 'Longitude'], df.loc[:, 'Latitude'] = lnglat_to_meters(df.Longitude,df.Latitude)\n",
    "        \n",
    "        return df    \n",
    "    \n",
    "\n",
    "\"\"\"Plot Trip Detail - uncomment below\"\"\"\n",
    "# map_viz = Map_Viz_Datashader(\"TRIP_DETAIL.csv\")\n",
    "# df=map_viz.process_data_td() \n",
    "\n",
    "\"\"\"Plotting individual events -- uncomment below\"\"\"\n",
    "# map_viz=Map_Viz_Datashader(\"brake_warnings.csv\") \n",
    "# map_viz=Map_Viz_Datashader(\"headway_warnings.csv\")\n",
    "# map_viz=Map_Viz_Datashader(\"right_left_lane_departure_warning.csv\")\n",
    "map_viz=Map_Viz_Datashader(\"AOS_SUMMARY.csv\")\n",
    "df=map_viz.process_data_aos() \n",
    "\n",
    "plot_width  = int(990)\n",
    "plot_height = int(plot_width//1.2)\n",
    "Netherlands = x_range, y_range = ((384019.630105,865878.656414), (6577253.409883,7156951.832398))\n",
    "\n",
    "cvs = ds.Canvas(plot_width=plot_width, plot_height=plot_height, x_range=x_range, y_range=y_range)\n",
    "agg = cvs.points(df, 'Longitude', 'Latitude')\n",
    "img = tf.shade(agg, cmap=\"green\", how='log')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save image locally\n",
    "# bgcolor can be white/black/whatever\n",
    "from datashader.utils import export_image\n",
    "export_image(img, \"out1\", background=\"white\", export_path=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO -> Create functions for repetitive tasks\n",
    "# ,nrows=20000000,skiprows=range(3, 260000000)\n",
    "# ,skiprows=range(3, 260000000)\n",
    "# Input the csv\n",
    "# Extracting a subset of 1000000 rows by default\n",
    "def load_data(dir_name,base_filename):\n",
    "    complete_path=os.path.join(dir_name, base_filename + \".\" + \"csv\")\n",
    "    # df=pd.read_csv(complete_path,sep=';',encoding= 'unicode_escape',nrows=10000,engine='c',infer_datetime_format=True,usecols=['Trip_Summary_Id','Numberplate','Point_time-stamp','Latitude',\n",
    "    #                                                                                                                           'Longitude','Meters_travelled','Time_elapsed','Point_speed','Number_of_lanes',\n",
    "    #                                                                                                                           'Road_type','Road_class','Road_form','Speed_restriction','TNO_Time-stamp'])\n",
    "    # df = pd.concat((chunk for chunk in pd.read_csv(complete_path,sep=';',nrows=5000000,encoding= 'unicode_escape',engine='c',infer_datetime_format=True,chunksize=1000000,low_memory=False,usecols=['Numberplate','Latitude',\n",
    "    #                                                                                                                           'Longitude','Meters_travelled','Time_elapsed','Point_speed','Number_of_lanes',\n",
    "    #                                                                                                                           'Road_type','Road_class','Speed_restriction','TNO_Time-stamp'])))\n",
    "    \n",
    "    df = pd.concat((chunk for chunk in pd.read_csv(complete_path,sep=';',encoding= 'unicode_escape',engine='c',infer_datetime_format=True,chunksize=1000000,low_memory=False)))\n",
    "    return df\n",
    "\n",
    "# Dropping the first and last row of csv (\"------\")\n",
    "def drop_first_row(df):\n",
    "    df=df.iloc[1:]\n",
    "    df=df[:-1]\n",
    "    return df\n",
    "\n",
    "def resetIndex(df):\n",
    "    return df.reset_index()\n",
    "\n",
    "\n",
    "##TODO -> Rewrite this function\n",
    "\n",
    "def cast_to_correct_dtype(df):\n",
    "    \n",
    "    if 'Id' in df.columns:\n",
    "        df['Id'] = df['Id'].astype('int')\n",
    "        \n",
    "    if 'AOS_position_Id' in df.columns:\n",
    "        df['AOS_position_Id'] = df['AOS_position_Id'].astype('int')\n",
    "    \n",
    "    if 'Acceleration_x' in df.columns:\n",
    "        df['Acceleration_x'] = df['Acceleration_x'].astype('float')\n",
    "        \n",
    "    if 'Acceleration_y' in df.columns:\n",
    "        df['Acceleration_y'] = df['Acceleration_y'].astype('float')\n",
    "        \n",
    "    if 'TNO_Valid' in df.columns:\n",
    "        df['TNO_Valid'] = df['TNO_Valid'].astype('int')\n",
    "    \n",
    "    if 'Latitude' in df.columns:\n",
    "        df['Latitude'] = df['Latitude'].astype('float')\n",
    "        \n",
    "    if 'Longitude' in df.columns:\n",
    "        df['Longitude'] = df['Longitude'].astype('float')\n",
    "        \n",
    "    if 'Event/action_speed' in df.columns:\n",
    "        df['Event/action_speed'] = df['Event/action_speed'].astype('int')\n",
    "        \n",
    "    if 'Event/action_type' in df.columns:\n",
    "        df['Event/action_type'] = df['Event/action_type'].astype('int')    \n",
    "        \n",
    "    if 'Number_of_lanes' in df.columns:\n",
    "        df['Number_of_lanes'] = df['Number_of_lanes'].astype('int')\n",
    "        \n",
    "    if 'Road_class' in df.columns:\n",
    "        df['Road_class'] = df['Road_class'].astype('int')\n",
    "        \n",
    "    if 'Road_type' in df.columns:\n",
    "        df['Road_type'] = df['Road_type'].astype('int')\n",
    "        \n",
    "    if 'Crash_position_Id' in df.columns:\n",
    "        df['Crash_position_Id']=df['Crash_position_Id'].astype('int')\n",
    "        \n",
    "    if 'Crash_position_Id' in df.columns:\n",
    "        df['Crash_position_Id'] = df['Crash_position_Id'].astype('int')\n",
    "        \n",
    "    if 'Point_speed' in df.columns:\n",
    "        df['Point_speed'] = df['Point_speed'].astype('float')\n",
    "        \n",
    "    if 'Average_speed_fpp' in df.columns:\n",
    "        df['Average_speed_fpp'] = df['Average_speed_fpp'].astype('float')  \n",
    "        \n",
    "    if 'Average_Speed' in df.columns:\n",
    "        df['Average_Speed'] = df['Average_Speed'].astype('float')        \n",
    "\n",
    "    if 'Maximum_speed' in df.columns:\n",
    "        df['Maximum_speed'] = df['Maximum_speed'].astype('float')     \n",
    "        \n",
    "    if 'Meters_travelled' in df.columns:\n",
    "        df['Meters_travelled'] = df['Meters_travelled'].astype('int')  \n",
    "\n",
    "    if 'Road_form' in df.columns:\n",
    "        df['Road_form'] = df['Road_form'].astype('int') \n",
    "        \n",
    "    if 'Speed_restriction' in df.columns:\n",
    "        df['Speed_restriction'] = df['Speed_restriction'].astype('int') \n",
    "        \n",
    "    if 'Crash_speed' in df.columns:\n",
    "        df['Crash_speed'] = df['Crash_speed'].astype('int')\n",
    "        \n",
    "    if 'Maximum_acceleration' in df.columns:\n",
    "        df['Maximum_acceleration'] = df['Maximum_acceleration'].astype('float')\n",
    "        \n",
    "    if 'Numberplate' in df.columns:\n",
    "        df['Numberplate']=df['Numberplate'].astype('str')\n",
    "        \n",
    "\n",
    "    return df\n",
    "\n",
    "            \n",
    "\n",
    "## Handling date time related fields\n",
    "\n",
    "def cast_date_time(df):\n",
    "    if 'TNO_Trip-start' in df.columns:\n",
    "        df['TNO_Trip-start'] = pd.to_datetime(df['TNO_Trip-start'],errors='coerce')\n",
    "        df['TNO_Trip-start_hour'] = df['TNO_Trip-start'].dt.hour\n",
    "        \n",
    "    if 'TNO_Trip-end' in df.columns:\n",
    "        df['TNO_Trip-end'] = pd.to_datetime(df['TNO_Trip-end'],errors='coerce')\n",
    "        \n",
    "    if 'Position_time' in df.columns:\n",
    "        df['Position_time'] = pd.to_datetime(df['Position_time'],errors='coerce')\n",
    "\n",
    "    if 'TNO_Time-stamp' in df.columns:\n",
    "        df['TNO_Time-stamp'] = pd.to_datetime(df['TNO_Time-stamp'],errors='coerce')\n",
    "        df['TNO_Time-stamp_hour'] = df['TNO_Time-stamp'].dt.hour\n",
    "        \n",
    "    if 'Trip_start_time-stamp' in df.columns:\n",
    "        df['Trip_start_time-stamp'] = pd.to_datetime(df['Trip_start_time-stamp'],errors='coerce')\n",
    "        df['Trip_start_time-stamp_hour'] = df['Trip_start_time-stamp'].dt.hour\n",
    "        \n",
    "    if 'Trip_start_date-stamp' in df.columns:\n",
    "        df['Trip_start_date-stamp'] = pd.to_datetime(df['Trip_start_date-stamp'],errors='coerce')\n",
    "        df['Trip_start_date-stamp_hour'] = df['Trip_start_date-stamp'].dt.hour\n",
    "    return df\n",
    "\n",
    "## Converting Time Stamps to datetime\n",
    "\n",
    "def date_and_time_columns(df):\n",
    "    if 'TNO_Time-stamp' in df.columns:\n",
    "        df['TNO Trip Date'] = df['TNO_Time-stamp'].dt.date\n",
    "        df['TNO Trip Time'] = df['TNO_Time-stamp'].dt.time\n",
    "        df['TNO Trip Hour']=df['TNO_Time-stamp'].dt.hour\n",
    "        df['TNO Trip Month'] = df['TNO_Time-stamp'].dt.hour\n",
    "    \n",
    "\n",
    "    if 'Trip_start_date-stamp' in df.columns:\n",
    "        df['TNO Trip Date'] = df['Trip_start_date-stamp'].dt.date\n",
    "        # df['TNO Trip Time'] = df['Trip_start_date-stamp'].dt.time\n",
    "        # df['TNO Trip Hour']=df['Trip_start_date-stamp'].dt.hour\n",
    "        df['TNO Trip Month']=df['Trip_start_date-stamp'].dt.month\n",
    "        \n",
    "    if 'Trip_start_time-stamp' in df.columns:\n",
    "        # df['TNO Trip Date'] = df['Trip_start_date-stamp'].dt.date\n",
    "        df['TNO Trip Time'] = df['Trip_start_time-stamp'].dt.time\n",
    "        df['TNO Trip Hour']=df['Trip_start_time-stamp'].dt.hour\n",
    "        # df['TNO Trip Month']=df['Trip_start_date-stamp'].dt.month\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def Time_of_the_day(x):\n",
    "    if (x > 4) and (x <= 8):\n",
    "        return 'Early Morning'\n",
    "    elif (x > 8) and (x < 12 ):\n",
    "        return 'Morning'\n",
    "    elif (x >= 12) and (x <= 16):\n",
    "        return'Noon'\n",
    "    elif (x > 16) and (x <= 20) :\n",
    "        return 'Evening'\n",
    "    elif (x > 20) and (x <= 24):\n",
    "        return'Night'\n",
    "    elif (x <= 4):\n",
    "        return'Late Night'\n",
    "    \n",
    "    \n",
    "def rename_some_stuff(df):\n",
    "    if 'Event/action_type' in df.columns:\n",
    "        df[\"Event type Rename\"]=df[\"Event/action_type\"].replace({0: 'Headway Warning = OFF', 1: 'Headway Warning (long)', 2: 'Headway Warning (medium)'\n",
    "                                                                                 ,3: 'Headway Warning (short)',10:'Lane Departure Warning = OFF',11:'Left Lane Departure Warning = ON'\n",
    "                                                                                 ,12:'Right Lane Departure Warning = ON',13:'Left and Right Lane Departure Warning = ON'\n",
    "                                                                                 ,20:' Indicators = OFF',21:'Left Indicator = ON',22:'Right Indicator = ON',23:'Left and Right Indicator = ON'\n",
    "                                                                                 ,40:'Brakes = OFF',41:'Brakes = ON'})\n",
    "        \n",
    "    if 'Road_type' in df.columns:\n",
    "        df[\"Road_type_Rename\"]=df[\"Road_type\"].replace({0: \"Urban\", 1: \"Motorway\",2:\"Extra Urban\",3:\"Unavailable\"})\n",
    "        \n",
    "    # if 'TNO Trip Month' in df.columns:\n",
    "    #     df[\"TNO_Trip_Month_Rename\"]=df[\"TNO Trip Month\"].replace({1: \"January\", 2: \"February\",3:\"March\",4:\"April\",5:\"May\",6:\"June\",7:\"July\",8:\"August\",9:\"September\",10:\"October\",11:\"November\",12:\"December\"})\n",
    "        \n",
    "    return df\n",
    "\n",
    "def detect_overspeeding_count(df):\n",
    "    # create a list of our conditions\n",
    "    # if 'Event/action_speed' and 'Speed_restriction' in df.columns:\n",
    "    #     conditions = [(df['Event/action_speed']> df['Speed_restriction'])]\n",
    "    #     # # create a list of the values we want to assign for each condition\n",
    "    #     values = [1]\n",
    "    #     # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    #     df['Overspeeding_event'] = np.select(conditions, values)\n",
    "        \n",
    "    # return df\n",
    "\n",
    "    if 'Point_speed' and 'Speed_restriction' in df.columns:\n",
    "        conditions = [(df['Point_speed']> df['Speed_restriction'])]\n",
    "        # # create a list of the values we want to assign for each condition\n",
    "        values = [1]\n",
    "        # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "        df['Overspeeding_event'] = np.select(conditions, values)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def some_processing(df):\n",
    "    if 'Meters_travelled' in df.columns:\n",
    "        df['KmTravelled']=df['Meters_travelled']/1000\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TRIP_SUMMARY = (load_data(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_SUMMARY\",\"TRIP_SUMMARY\")\n",
    "                                      .pipe(drop_first_row)\n",
    "                                      .pipe(resetIndex)\n",
    "                                      .pipe(cast_to_correct_dtype)\n",
    "                                      .pipe(cast_date_time)\n",
    "                                      .pipe(date_and_time_columns)\n",
    "                                      .pipe(rename_some_stuff))\n",
    "df_TRIP_SUMMARY['Part of Day'] = df_TRIP_SUMMARY['TNO Trip Hour'].apply(Time_of_the_day)\n",
    "df_TRIP_SUMMARY['Count']=1\n",
    "# df_TRIP_SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_grp = df_TRIP_SUMMARY.groupby(\"Trip_start_date-stamp\")[\"Meters_travelled\"].sum()\n",
    "month_grp=month_grp.to_frame()\n",
    "month_grp=month_grp.reset_index()\n",
    "month_grp['km_travelled']=month_grp['Meters_travelled']/1000\n",
    "month_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cbook as cbook\n",
    "\n",
    "# Load a numpy structured array from yahoo csv data with fields date, open,\n",
    "# close, volume, adj_close from the mpl-data/example directory.  This array\n",
    "# stores the date as an np.datetime64 with a day unit ('D') in the 'date'\n",
    "# column.\n",
    "data = month_grp\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(6.4, 7), constrained_layout=True)\n",
    "# common to all three:\n",
    "for ax in axs:\n",
    "    ax.plot('Trip_start_date-stamp', 'Meters_travelled', data=data)\n",
    "    # Major ticks every half year, minor ticks every month,\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(bymonth=(1, 7)))\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    ax.grid(True)\n",
    "    ax.set_ylabel(r'Price [\\$]')\n",
    "\n",
    "# different formats:\n",
    "ax = axs[0]\n",
    "ax.set_title('DefaultFormatter', loc='left', y=0.85, x=0.02, fontsize='medium')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_title('ConciseFormatter', loc='left', y=0.85, x=0.02, fontsize='medium')\n",
    "ax.xaxis.set_major_formatter(\n",
    "    mdates.ConciseDateFormatter(ax.xaxis.get_major_locator()))\n",
    "\n",
    "ax = axs[2]\n",
    "ax.set_title('Manual DateFormatter', loc='left', y=0.85, x=0.02,\n",
    "             fontsize='medium')\n",
    "# Text in the x axis will be displayed in 'YYYY-mm' format.\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%b'))\n",
    "# Rotates and right-aligns the x labels so they don't crowd each other.\n",
    "for label in ax.get_xticklabels(which='major'):\n",
    "    label.set(rotation=30, horizontalalignment='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Trip_start_date-stamp\", y=\"Meters_travelled\",data=month_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "# sns.lineplot(x=month_grp[\"Trip_start_date-stamp\"].dt.month, y=month_grp['Meters_travelled'], ax=ax)\n",
    "# # ax.legend(title='Month', bbox_to_anchor=(1, 1), loc='upper left')\n",
    "# ax.set(xlabel='Month')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(month_grp, x = month_grp[\"Trip_start_date-stamp\"], y = month_grp[\"Meters_travelled\"]/1000,title=\"Total distance covered (Meters) over time\",template=\"seaborn\").update_layout(\n",
    "    xaxis_title=\"Date\", yaxis_title=\"Distance Travelled (Meters)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TRIP_SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp = df_TRIP_SUMMARY.groupby([\"TNO Trip Month\", \"TNO Trip Hour\"])[\"Meters_travelled\"].sum()\n",
    "merge_grp=merge_grp.to_frame()\n",
    "merge_grp=merge_grp.reset_index()\n",
    "merge_grp\n",
    "# month_grp['km_travelled']=month_grp['Meters_travelled']/1000\n",
    "# month_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp[\"TNO_Trip_Month_Rename\"]=merge_grp[\"TNO Trip Month\"].replace({1: \"January\", 2: \"February\",3:\"March\",4:\"April\",5:\"May\",6:\"June\",7:\"July\",8:\"August\",9:\"September\",10:\"October\",11:\"November\",12:\"December\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=merge_grp['TNO Trip Hour'],y=merge_grp['Meters_travelled'],hue=merge_grp[\"TNO_Trip_Month_Rename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_grp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TRIP_SUMMARY.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import vaex # https://vaex.io/docs/index.html\n",
    "import pathlib\n",
    "from pathlib import *\n",
    "import os\n",
    "import pickle\n",
    "# import cufflinks as cf\n",
    "# import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,plot,iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_TD=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df20M.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_TD['Month'] = pd.DatetimeIndex(df1_TD['TNO_Time-stamp']).month\n",
    "df1_TD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp = df1_TD.groupby([\"Month\", \"TNO Trip Hour\"])[\"Meters_travelled\"].sum()\n",
    "merge_grp=merge_grp.to_frame()\n",
    "merge_grp=merge_grp.reset_index()\n",
    "merge_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp.to_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month_hour\\month_hour_td40M.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp = df1_TD.groupby(\"Month\")[\"Meters_travelled\"].sum()\n",
    "merge_grp=merge_grp.to_frame()\n",
    "merge_grp=merge_grp.reset_index()\n",
    "merge_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp.to_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month40M.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp = df1_TD.groupby(\"TNO Trip Hour\")[\"Meters_travelled\"].sum()\n",
    "merge_grp=merge_grp.to_frame()\n",
    "merge_grp=merge_grp.reset_index()\n",
    "merge_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp.to_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\hour\\hour40M.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp = df1_TD.groupby(\"TNO Trip Hour\")[\"Point_speed\"].mean()\n",
    "merge_grp=merge_grp.to_frame()\n",
    "merge_grp=merge_grp.reset_index()\n",
    "merge_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp.to_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\hour\\hour_pointspeed40M.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=merge_grp['TNO Trip Hour'],y=merge_grp['Meters_travelled'],hue=merge_grp[\"Month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_TD.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month20M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month20M.csv\")\n",
    "month20M.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "month20M.rename(columns={'Meters_travelled': 'Meters_travelled20M'},inplace=True, errors='raise')\n",
    "\n",
    "\n",
    "month40M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month40M.csv\")\n",
    "month40M.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "month40M.rename(columns={'Meters_travelled': 'Meters_travelled40M'},inplace=True, errors='raise')\n",
    "\n",
    "month60M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month60M.csv\")\n",
    "month60M.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "month60M.rename(columns={'Meters_travelled': 'Meters_travelled60M'},inplace=True, errors='raise')\n",
    "\n",
    "month80M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month80M.csv\")\n",
    "month80M.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "month80M.rename(columns={'Meters_travelled': 'Meters_travelled80M'},inplace=True, errors='raise')\n",
    "\n",
    "\n",
    "month100M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month100M.csv\")\n",
    "month100M.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "month100M.rename(columns={'Meters_travelled': 'Meters_travelled100M'},inplace=True, errors='raise')\n",
    "\n",
    "month120M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month120M.csv\")\n",
    "month120M.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "month120M.rename(columns={'Meters_travelled': 'Meters_travelled120M'},inplace=True, errors='raise')\n",
    "\n",
    "month140M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month140M.csv\")\n",
    "month140M.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "month140M.rename(columns={'Meters_travelled': 'Meters_travelled140M'},inplace=True, errors='raise')\n",
    "\n",
    "month160M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month160M.csv\")\n",
    "month160M.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "month160M.rename(columns={'Meters_travelled': 'Meters_travelled160M'},inplace=True, errors='raise')\n",
    "\n",
    "month180M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month180M.csv\")\n",
    "month180M.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "month180M.rename(columns={'Meters_travelled': 'Meters_travelled180M'},inplace=True, errors='raise')\n",
    "\n",
    "month200M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month200M.csv\")\n",
    "month200M.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "month200M.rename(columns={'Meters_travelled': 'Meters_travelled200M'},inplace=True, errors='raise')\n",
    "\n",
    "month220M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month220M.csv\")\n",
    "month220M.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "month220M.rename(columns={'Meters_travelled': 'Meters_travelled220M'},inplace=True, errors='raise')\n",
    "\n",
    "month240M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month240M.csv\")\n",
    "month240M.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "month240M.rename(columns={'Meters_travelled': 'Meters_travelled240M'},inplace=True, errors='raise') \n",
    "month260M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month260M.csv\")\n",
    "month260M.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "month260M.rename(columns={'Meters_travelled': 'Meters_travelled260M'},inplace=True, errors='raise')\n",
    "month280M=pd.read_csv(\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\month\\month280M.csv\")\n",
    "month280M.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "month280M.rename(columns={'Meters_travelled': 'Meters_travelled280M'},inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month20M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# compile the list of dataframes you want to merge\n",
    "data_frames = [month20M, month40M, month60M,month80M,month100M,month120M,month140M,month160M,month180M,month200M,month220M,month240M,month260M,month280M]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Month'],how='outer'), data_frames).fillna(0)\n",
    "# df[\"TNO_Trip_Month_Rename\"]=df[\"TNO Trip Month\"].replace({1: \"January\", 2: \"February\",3:\"March\",4:\"April\",5:\"May\",6:\"June\",7:\"July\",8:\"August\",9:\"September\",10:\"October\",11:\"November\",12:\"December\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged=df_merged.sort_values(by=['Month'],ascending=True)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_my_columns = ['Meters_travelled20M', 'Meters_travelled40M', 'Meters_travelled60M','Meters_travelled80M','Meters_travelled100M','Meters_travelled120M','Meters_travelled140M','Meters_travelled160M','Meters_travelled180M','Meters_travelled200M','Meters_travelled220M','Meters_travelled240M','Meters_travelled260M','Meters_travelled280M']\n",
    "df_merged['total_distance'] = df_merged[list_of_my_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"TNO_Trip_Month_Rename\"]=df_merged[\"Month\"].replace({1: \"January\", 2: \"February\",3:\"March\",4:\"April\",5:\"May\",6:\"June\",7:\"July\",8:\"August\",9:\"September\",10:\"October\",11:\"November\",12:\"December\"})\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total = df_merged['total_distance'].sum()\n",
    "print(Total/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df_merged[\"TNO_Trip_Month_Rename\"],y=df_merged[\"total_distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import vaex # https://vaex.io/docs/index.html\n",
    "import pathlib\n",
    "from pathlib import *\n",
    "import os\n",
    "import pickle\n",
    "# import cufflinks as cf\n",
    "# import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,plot,iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\aos_summary_140M.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Event type Rename'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df280M.csv\")\n",
    "# df['Count'] = 1\n",
    "# df = df.drop(df[df['Point_speed']==0].index)\n",
    "# df['TNO_Time-stamp'] = pd.to_datetime(df['TNO_Time-stamp'],errors='coerce')\n",
    "# df['Month'] = pd.DatetimeIndex(df['TNO_Time-stamp']).month\n",
    "# df['weekday'] = df['TNO_Time-stamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban= df.loc[df['Road_type']==0] #Urban\n",
    "df_motorway= df.loc[df['Road_type']==1] #Urban\n",
    "df_extra_urban= df.loc[df['Road_type']==2] #Urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_extra_urban)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp_urban = df_urban.groupby([\"TNO Trip Hour\",\"weekday\"]).sum()\n",
    "# merge_grp_urban=merge_grp_urban.to_frame()\n",
    "merge_grp_urban=merge_grp_urban.reset_index()\n",
    "merge_grp_urban[\"weekday\"]=merge_grp_urban[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})\n",
    "# merge_grp_urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp_urban.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\sum_hour\\urban\\sum_hour1_urban.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp_motorway = df_motorway.groupby([\"TNO Trip Hour\",\"weekday\"]).sum()\n",
    "# merge_grp_motorway=merge_grp_motorway.to_frame()\n",
    "merge_grp_motorway=merge_grp_motorway.reset_index()\n",
    "merge_grp_motorway[\"weekday\"]=merge_grp_motorway[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})\n",
    "# merge_grp_motorway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp_motorway.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\sum_hour\\motorway\\sum_hour1_motorway.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp_extra_urban = df_extra_urban.groupby([\"TNO Trip Hour\",\"weekday\"]).sum()\n",
    "# merge_grp_extra_urban=merge_grp_extra_urban.to_frame()\n",
    "merge_grp_extra_urban=merge_grp_extra_urban.reset_index()\n",
    "merge_grp_extra_urban[\"weekday\"]=merge_grp_extra_urban[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp_extra_urban.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\sum_hour\\extra_urban\\sum_hour1_extra_urban.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_urban = df_urban.groupby([\"Month\",\"TNO Trip Hour\"]).sum()\n",
    "# # merge_grp_urban=merge_grp_urban.to_frame()\n",
    "# merge_grp_urban=merge_grp_urban.reset_index()\n",
    "# merge_grp_urban[\"weekday\"]=merge_grp_urban[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})\n",
    "# merge_grp_urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_urban.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\sum_month\\urban\\sum_month13_urban.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_urban = df_urban.groupby([\"Month\"]).mean()\n",
    "# # merge_grp_urban=merge_grp_urban.to_frame()\n",
    "# merge_grp_urban=merge_grp_urban.reset_index()\n",
    "# merge_grp_urban[\"weekday\"]=merge_grp_urban[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})\n",
    "# # merge_grp_urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_urban.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\mean_month\\urban\\mean_month13_urban.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_urban = df_urban.groupby([\"TNO Trip Hour\"]).mean()\n",
    "# # merge_grp_urban=merge_grp_urban.to_frame()\n",
    "# merge_grp_urban=merge_grp_urban.reset_index()\n",
    "# merge_grp_urban[\"weekday\"]=merge_grp_urban[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})\n",
    "# merge_grp_urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_urban.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\mean_hour\\urban\\mean_hour13_urban.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motorway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_motorway.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\mean_month\\motorway\\mean_month13_motorway.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_motorway = df_motorway.groupby([\"Month\"]).sum()\n",
    "# # merge_grp_motorway=merge_grp_motorway.to_frame()\n",
    "# merge_grp_motorway=merge_grp_motorway.reset_index()\n",
    "# merge_grp_motorway[\"weekday\"]=merge_grp_motorway[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})\n",
    "# merge_grp_motorway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_motorway.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\sum_month\\motorway\\sum_month13_motorway.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_motorway = df_motorway.groupby([\"Month\"]).mean()\n",
    "# # merge_grp_motorway=merge_grp_motorway.to_frame()\n",
    "# merge_grp_motorway=merge_grp_motorway.reset_index()\n",
    "# merge_grp_motorway[\"weekday\"]=merge_grp_motorway[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_motorway = df_motorway.groupby([\"TNO Trip Hour\"]).mean()\n",
    "# # merge_grp_motorway=merge_grp_motorway.to_frame()\n",
    "# merge_grp_motorway=merge_grp_motorway.reset_index()\n",
    "# merge_grp_motorway[\"weekday\"]=merge_grp_motorway[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_motorway.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\mean_hour\\motorway\\mean_hour13_motorway.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_extra_urban = df_extra_urban.groupby([\"Month\"]).sum()\n",
    "# # merge_grp_extra_urban=merge_grp_extra_urban.to_frame()\n",
    "# merge_grp_extra_urban=merge_grp_extra_urban.reset_index()\n",
    "# merge_grp_extra_urban[\"weekday\"]=merge_grp_extra_urban[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_extra_urban.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\sum_month\\extra_urban\\sum_month13_extra_urban.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_extra_urban = df_extra_urban.groupby([\"Month\"]).mean()\n",
    "# # merge_grp_extra_urban=merge_grp_extra_urban.to_frame()\n",
    "# merge_grp_extra_urban=merge_grp_extra_urban.reset_index()\n",
    "# merge_grp_extra_urban[\"weekday\"]=merge_grp_extra_urban[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_extra_urban.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\mean_month\\extra_urban\\mean_month13_extra_urban.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_extra_urban = df_extra_urban.groupby([\"TNO Trip Hour\"]).mean()\n",
    "# # merge_grp_extra_urban=merge_grp_extra_urban.to_frame()\n",
    "# merge_grp_extra_urban=merge_grp_extra_urban.reset_index()\n",
    "# merge_grp_extra_urban[\"weekday\"]=merge_grp_extra_urban[\"weekday\"].replace({0: \"Monday\", 1: \"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_grp_extra_urban.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\mean_hour\\extra_urban\\mean_hour13_extra_urban.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_grp=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\Point Speed\\extra_urban\\Point_Speed_hour_weekday1_extra_urban.csv\")\n",
    "merge_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.lineplot(x=merge_grp[\"TNO Trip Hour\"],y=merge_grp[\"Point_Speed_extra_urban\"],hue=merge_grp[\"weekday\"],linewidth=3.5,palette=\"plasma\")\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"Mean Point Speed (km/h)\")\n",
    "ax.legend(title=\"Day\",fontsize=9)\n",
    "ax.legend(bbox_to_anchor=(1.30, 1), loc='upper right', borderaxespad=0.,title=\"Day\",fontsize=10)\n",
    "plt.title(\"Road Type - Motorway\")\n",
    "# plt.xlim(-0.5, 23.5)\n",
    "# plt.ylim(60,80)\n",
    "plt.yticks([50,55,60,65,70,75,80,85,90])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_speed_3_roads=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\Point Speed\\point_Speed_3_roads.csv\")\n",
    "point_speed_3_roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_palette(\"plasma\")\n",
    "# g=sns.set(rc={'figure.figsize':(25,25)})\n",
    "g = sns.FacetGrid(point_speed_3_roads, col=\"Road Type\", hue=\"Day\")\n",
    "g.map(sns.lineplot, \"Hour of the day\", \"Mean Point Speed (km/h)\",linewidth=3)\n",
    "g.add_legend()\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.figure(figsize=(30,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_weekdayhour = plt.figure(figsize=(20,20))\n",
    "cat_weekdayhour = sns.set_context(\"paper\")\n",
    "cat_weekdayhour = sns.set(style=\"darkgrid\", font_scale=1.0)\n",
    "\n",
    "# weekdayhour.shape\n",
    "cat_weekdayhour = sns.catplot(x=\"weekday\", y=\"Point_speed\", hue=\"TNO Trip Hour\", kind=\"swarm\", palette=\"plasma\", data=merge_grp)\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"Point Speed (km/h)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap Point Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "array = [[77.22471574,77.00576039,77.04276253,76.66354794,74.73674937,70.26279195,64.99583406,64.11780805,67.32261922,67.4417012,67.92093776,68.50080438,68.20613442,68.54404583,68.01214693,67.30968616,68.29744322,71.67173326,74.74030784,76.04037086,76.94580085,77.46864638,77.6337138\t,77.54019212],\n",
    "         [77.58487678,77.12636287,77.35606058,76.62639839,74.97134469,70.71204615,64.65517226,62.37591014,65.13490569,66.24463835,66.81356514,67.35355036,67.28952508,67.79335749,67.14422461,65.73402689,66.10111251,70.44871094,73.99677083,75.7210203,76.98769201,77.28153685,77.79414812,77.66129885],\n",
    "         [77.71227616,77.32505013,77.11338543,76.52528385,75.07151652,71.51354144,66.39985513,64.19732536,65.98183477,66.70262755,67.12801674,67.64410009,67.65705701,67.78497747,67.14781776,65.49176472,66.40422316,70.69216089,74.23322216,76.22591126,77.0432851,77.22845356,77.53349755,77.63168969],\n",
    "         [77.41244795,77.32615656,77.12885478,76.77565419,74.99209271,71.11471833,65.25202936,62.85999191,64.97971213,66.59077725,66.93169665,67.66745195,67.58621413,67.37432462,66.3065311,64.91929278,65.46313308,69.24527448,73.50462848,75.06979324,76.5818323,77.20799775,78.04440063,77.64564254],\n",
    "         [77.85786061,77.63882374,77.10733693,76.4463634,75.26956079,72.66602215,68.72508737,66.24742181,66.79307725,66.56816482,66.32152526,66.42297562,66.32069838,65.64733442,65.28090003,65.61329746,67.49609688,70.64440015,73.2811676,74.913803,76.2048574,77.04932829,76.94008507,77.06635231],\n",
    "         [77.68160878,76.94236289,74.29844095,74.74768892,75.17134319,73.88660436,72.89003509,71.74867695,71.67956774,70.83777232,71.251072,71.52631129,71.35013599,71.77554966,71.66986874,71.91587171,72.87131457,74.29727998,74.58549105,75.55970443,75.74164292,77.71788856,77.62651907,75.93864547],\n",
    "         [78.16621971,78.12108976,77.27216559,77.08828218,77.21876289,76.27232365,73.85003252,72.44362085,72.08952198,72.50421241,72.86943397,72.12960513,72.09311982,71.60853231,71.43704883,72.81159132,74.92322085,77.11530333,76.84421714,78.12607556,77.90170889,78.06509106,77.69170247,78.1283126]]\n",
    "\n",
    "index=[\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\"]\n",
    "# labels = [\"Eindhoven\",\"Rotterdam\",\"Amsterdam\",\"Utrecht\",\"Zwolle\"]\n",
    "df_cm = pd.DataFrame(array, index = index,\n",
    "                  columns = columns)\n",
    "\n",
    "# matrix = np.triu(df_cm)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "# plt.title('')\n",
    "sn.heatmap(df_cm, annot=False,fmt=\".1f\", \n",
    "           linewidths=0.5, cmap=\"coolwarm\",cbar_kws={'label': 'Mean Point Speed (km/h)'})\n",
    "plt.xlabel('Hour of the day',fontweight=\"bold\",fontsize=13)\n",
    "plt.ylabel('Day of the week',fontweight=\"bold\",fontsize=13)\n",
    "plt.title(r\"Heatmap depicting change in mean point speed (km/h)\"+\"\\n\"+r\"(over different days and hours) - All road types\",fontsize=13,fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/lpegram85/Python_Queries/blob/master/Visualization_Correlation_Matrix.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_travelled=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\sum_hour\\total_sum_hour_road_type.csv\")\n",
    "distance_travelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.lineplot(x=distance_travelled[\"TNO Trip Hour\"],y=distance_travelled[\"km_sum\"],hue=distance_travelled['road_type'],linewidth=3.5,palette=\"plasma\")\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"Distance Covered (km)\")\n",
    "g.get_legend().remove()\n",
    "# ax.legend(title=\"Road Type\")\n",
    "# ax.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0.,title=\"Road Type\",fontsize=10)\n",
    "# plt.title(\"Road Type - Urban\")\n",
    "# plt.xlim(-0.5, 23.5)\n",
    "# plt.ylim(60,80)\n",
    "# plt.yticks([50,55,60,65,70,75,80,85,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.lineplot(x=distance_travelled[\"TNO Trip Hour\"],y=distance_travelled[\"km_sum\"],hue=distance_travelled['road_type'],linewidth=3.5,palette=\"plasma\")\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"Distance Covered (km)\")\n",
    "ax.legend(title=\"Road Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.barplot(x=distance_travelled[\"TNO Trip Hour\"],y=distance_travelled[\"km_sum\"],hue=distance_travelled['road_type'],linewidth=3.5,palette=\"plasma\")\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"Distance Covered (kilometers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AOS events plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds, pandas as pd, colorcet as cc\n",
    "\n",
    "fields = ['Latitude', 'Longitude','Event/action_type']\n",
    "df = pd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\AOS_SUMMARY.csv',delimiter=';', skipinitialspace=True, usecols=fields, encoding= 'unicode_escape',dtype={'Latitude': float,'Longitude':float},skiprows=range(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "from holoviews.element.tiles import StamenTerrain\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import BoxZoomTool\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "# Define general parameters for the Bokeh plot\n",
    "x_range, y_range = ((-1477374.882696,3639625.538827), (4197310.097196,9646964.465816))\n",
    "\n",
    "plot_width  = int(990)\n",
    "plot_height = int(plot_width//1.2)\n",
    "\n",
    "options = dict(line_color=None, fill_color='blue', size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.defaults(\n",
    "    opts.Points(width=plot_width, height=plot_height, size=5, color='blue'),\n",
    "    opts.Overlay(width=plot_width, height=plot_height, xaxis=None, yaxis=None),\n",
    "    opts.RGB(width=plot_width, height=plot_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df.sample(frac=1e-4)\n",
    "tiles = StamenTerrain().redim.range(x=x_range, y=y_range)\n",
    "points = hv.Points(samples, ['Longitude', 'Latitude'])\n",
    "(tiles * points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "from datashader import transfer_functions as tf\n",
    "from datashader.colors import Greys9\n",
    "Greys9_r = list(reversed(Greys9))[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cvs = ds.Canvas(plot_width=plot_width, plot_height=plot_height, x_range=x_range, y_range=y_range)\n",
    "agg = cvs.points(df, 'Longitude', 'Latitude')\n",
    "img = tf.shade(agg, cmap=[\"white\", 'darkblue'], how='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shade(agg, cmap=Greys9_r, how='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shade(agg, cmap=Greys9_r, how='eq_hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews.operation.datashader as hd\n",
    "from datashader.colors import Hot\n",
    "shaded = hd.datashade(hv.Points(df, ['Longitude', 'Latitude']), cmap=Hot, aggregator=ds.count('Event/action_type'))\n",
    "hd.dynspread(shaded, threshold=0.5, max_px=4).opts(bgcolor='black', xaxis=None, yaxis=None, width=900, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(overlay):\n",
    "    picks = overlay.get(0).redim(Longitude='x', Latitude='y')\n",
    "    events=\n",
    "    # drops = overlay.get(1).redim(dropoff_x='x', dropoff_y='y')\n",
    "    # pick_agg = picks.data.Count.data\n",
    "    # drop_agg = drops.data.Count.data\n",
    "    # more_picks = picks.clone(picks.data.where(pick_agg>drop_agg))\n",
    "    # more_drops = drops.clone(drops.data.where(drop_agg>pick_agg))\n",
    "    return (hd.shade(picks, cmap=['lightcyan', \"blue\"]) *\n",
    "            hd.shade(more_picks, cmap=['mistyrose', \"red\"]))\n",
    "\n",
    "picks = hv.Points(df, ['pickup_x',  'pickup_y'])\n",
    "drops = hv.Points(df, ['dropoff_x', 'dropoff_y'])\n",
    "((hd.rasterize(picks) * hd.rasterize(drops))).apply(transform).opts(\n",
    "    bgcolor='white', xaxis=None, yaxis=None, width=900, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\AOS_SUMMARY.csv',delimiter=';', encoding='unicode_escape',usecols=[\"Latitude\",\"Longitude\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "# df = df[df['Road_type']==0]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\AOS_warnings_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Latitude\"] = df[\"Latitude\"].astype(float)\n",
    "df[\"Longitude\"] = df[\"Longitude\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\headway_warnings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import BoxZoomTool\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "# Define general parameters for the Bokeh plot\n",
    "NYC = x_range, y_range = ((-1477374.882696,3639625.538827), (4197310.097196,9646964.465816))\n",
    "\n",
    "plot_width  = int(990)\n",
    "plot_height = int(plot_width//1.2)\n",
    "\n",
    "options = dict(line_color=None, fill_color='blue', size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable function to create simple Bokeh plots\n",
    "\n",
    "def base_plot(tools='pan,wheel_zoom,reset', plot_width=plot_width, plot_height=plot_height, **plot_kwargs):\n",
    "    p = figure(tools=tools, plot_width=plot_width, plot_height=plot_height,\n",
    "        x_range=x_range, y_range=y_range, outline_line_color=None,\n",
    "        min_border=0, min_border_left=0, min_border_right=0,\n",
    "        min_border_top=0, min_border_bottom=0, **plot_kwargs)\n",
    "    \n",
    "    p.axis.visible = False\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    \n",
    "    p.add_tools(BoxZoomTool(match_aspect=True))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datashader.utils import lnglat_to_meters\n",
    "df.loc[:, 'Longitude'], df.loc[:, 'Latitude'] = lnglat_to_meters(df.Longitude,df.Latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.tile_providers import get_provider, Vendors \n",
    "\n",
    "tile_provider = get_provider(Vendors.CARTODBPOSITRON)\n",
    "\n",
    "samples = df.sample(n=100000)\n",
    "p = base_plot()\n",
    "p.add_tile(tile_provider)\n",
    "\n",
    "p.circle(x=samples['Longitude'], y=samples['Latitude'], **options)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.tile_providers import get_provider, Vendors \n",
    "import holoviews.operation.datashader as hd\n",
    "from datashader.colors import Hot\n",
    "\n",
    "tile_provider = get_provider(Vendors.CARTODBPOSITRON)\n",
    "options = dict(line_color=None, fill_color='blue', size=1, alpha=0.2)\n",
    "samples = df.sample(n=1000000)\n",
    "p = base_plot()\n",
    "p.add_tile(tile_provider)\n",
    "p.circle(x=samples['Longitude'], y=samples['Latitude'], **options)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import export_png\n",
    "\n",
    "export_png(p, filename=\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import export_png\n",
    "\n",
    "export_png(p, filename=\"brake_on.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#load the dataset\n",
    "df = sns.load_dataset('iris')\n",
    "df\n",
    "# #calculate correlation\n",
    "# corr_matrix = df.corr('pearson') #kind of correlation->  ‘pearson’, ‘kendall’, ‘spearman’\n",
    "# #plot correlation\n",
    "# corr_matrix.style.background_gradient(cmap='coolwarm')\n",
    "# # 'RdBu_r', 'BrBG_r', & PuOr_r are other good diverging colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\Overview\\Point Speed\\point_Speed_3_roads.csv\")\n",
    "df_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_hour.corr('pearson') #kind of correlation->  ‘pearson’, ‘kendall’, ‘spearman’\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr('pearson') #kind of correlation->  ‘pearson’, ‘kendall’, ‘spearman’\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_td = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\TRIP_DETAIL.csv',delimiter=';', encoding='unicode_escape', usecols=['TNO_Time-stamp','Point_speed'])\n",
    "df_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Point_speed']\n",
    "df = pd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\TRIP_DETAIL.csv',delimiter=';', skipinitialspace=True, usecols=fields, encoding= 'unicode_escape',dtype={'Point_speed': float},skiprows=range(1,2),nrows=10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Speed_restriction']\n",
    "df = pd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\TRIP_DETAIL.csv',delimiter=';', skipinitialspace=True, usecols=fields, encoding= 'unicode_escape',dtype={'Speed_restriction': float},skiprows=range(1,2),nrows=55000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Point_speed','Average_speed_fpp','Road_type_Rename']\n",
    "df = pd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df20M.csv', skipinitialspace=True, usecols=fields, encoding= 'unicode_escape',dtype={'Point_speed': float,'Average_speed_fpp':float,'Road_type_Rename':str},skiprows=range(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['Average_speed_fpp']==0].index)\n",
    "df = df.drop(df[df['Point_speed']==0].index)\n",
    "df = df.drop(df[df['Point_speed']<20].index)\n",
    "df = df.drop(df[df['Point_speed']>140].index)\n",
    "\n",
    "\n",
    "df = df.drop(df[df['Road_type_Rename']==\"Unavailable\"].index)\n",
    "df = df.drop(df[df['Road_type_Rename']==\"-2\"].index)\n",
    "# df = df.drop(df[df['Road_type_Rename']>120].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Road_type_Rename'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df, x=\"Point_speed\",palette=\"crest\")\n",
    "plt.xlabel(\"Point Speed (km/h)\")\n",
    "plt.title(\"Distribution of Point Speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=cwReturnVehiclePositions_4750[cwReturnVehiclePositions_4750['ReceivedTime_Sep']=='2008-08-08']\n",
    "import joypy\n",
    "from matplotlib import cm\n",
    "\n",
    "joypy.joyplot(df, column=['Point_speed'], by=\"Road_type_Rename\", ylim='own',linecolor=\"blue\", colormap=cm.autumn_r,title=\"Distribution of Point Speed on different road types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joypy.joyplot(df,column=['Point_speed'], by=\"Road_type_Rename\", ylim='own',fill=False, colormap=cm.coolwarm,title=\"Distribution of Point Speed on different road types\",linewidth=2.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joypy.joyplot(df,column=['Point_speed'], by=\"Road_type_Rename\", ylim='own',fill=False, colormap=cm.CMRmap,title=\"Distribution of Point Speed on different road types\",linewidth=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joypy.joyplot(df,column=['Point_speed'], by=\"Road_type_Rename\", ylim='own',fill=False, colormap=cm.PuRd,title=\"Distribution of Point Speed on different road types\",linewidth=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=cwReturnVehiclePositions_4750[cwReturnVehiclePositions_4750['ReceivedTime_Sep']=='2008-08-08']\n",
    "import joypy\n",
    "from matplotlib import cm\n",
    "\n",
    "joypy.joyplot(df, column=['Point_speed'], by=\"Road_type_Rename\", ylim='own',linecolor=\"blue\", colormap=cm.PuRd,title=\"Distribution of Point Speed on different road types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df20M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_20M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df40M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_40M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df60M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_60M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df80M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_80M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df100M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_100M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df120M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_120M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df140M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_140M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df160M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_160M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df180M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_180M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df200M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_200M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df220M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_220M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df240M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_240M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df260M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_260M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\df280M.csv', encoding='unicode_escape',assume_missing=True,usecols=[\"Point_speed\",\"Numberplate\",\"TNO_Time-stamp\",\"TNO_Time-stamp_hour\"])\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==1]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1\\hour1_TD_280M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\aos_summary_20M.csv', encoding='unicode_escape',assume_missing=True)\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==0]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour\\Hour0\\hour0_AOS_20M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\aos_summary_40M.csv', encoding='unicode_escape',assume_missing=True)\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==0]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour\\Hour0\\hour0_AOS_40M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\aos_summary_60M.csv', encoding='unicode_escape',assume_missing=True)\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==0]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour\\Hour0\\hour0_AOS_60M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\aos_summary_80M.csv', encoding='unicode_escape',assume_missing=True)\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==0]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour\\Hour0\\hour0_AOS_80M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\aos_summary_100M.csv', encoding='unicode_escape',assume_missing=True)\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==0]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour\\Hour0\\hour0_AOS_100M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\aos_summary_120M.csv', encoding='unicode_escape',assume_missing=True)\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==0]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour\\Hour0\\hour0_AOS_120M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\aos_summary_140M.csv', encoding='unicode_escape',assume_missing=True)\n",
    "\n",
    "# headway_warning=[11,12,13]\n",
    "# df = df[df['Event/action_type'].isin(headway_warning)]\n",
    "df = df[df['TNO_Time-stamp_hour']==0]\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour\\Hour0\\hour0_AOS_140M.csv\")\n",
    "# df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour0'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour0 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour0 = df_TD_hour0.drop(df_TD_hour0[df_TD_hour0['Point_speed']==0].index)\n",
    "df_TD_hour0.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour0.rename(columns={'Point_speed':'0'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour0['Count'] = np.arange(len(df_TD_hour0))\n",
    "\n",
    "df_TD_hour0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour1 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour1 = df_TD_hour1.drop(df_TD_hour1[df_TD_hour1['Point_speed']==0].index)\n",
    "df_TD_hour1.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour1.rename(columns={'Point_speed':'1'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour1['Count'] = np.arange(len(df_TD_hour1))\n",
    "\n",
    "df_TD_hour1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour2'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour2 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour2 = df_TD_hour2.drop(df_TD_hour2[df_TD_hour2['Point_speed']==0].index)\n",
    "df_TD_hour2.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour2.rename(columns={'Point_speed':'2'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour2['Count'] = np.arange(len(df_TD_hour2))\n",
    "df_TD_hour2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour3'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour3 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour3 = df_TD_hour3.drop(df_TD_hour3[df_TD_hour3['Point_speed']==0].index)\n",
    "df_TD_hour3.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour3.rename(columns={'Point_speed':'3'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour3['Count'] = np.arange(len(df_TD_hour3))\n",
    "\n",
    "df_TD_hour3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour4'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour4 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour4 = df_TD_hour4.drop(df_TD_hour4[df_TD_hour4['Point_speed']==0].index)\n",
    "df_TD_hour4.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour4.rename(columns={'Point_speed':'4'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour4['Count'] = np.arange(len(df_TD_hour4))\n",
    "\n",
    "df_TD_hour4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour5'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour5 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour5 = df_TD_hour5.drop(df_TD_hour5[df_TD_hour5['Point_speed']==0].index)\n",
    "df_TD_hour5.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour5.rename(columns={'Point_speed':'5'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour5['Count'] = np.arange(len(df_TD_hour5))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour6'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour6 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour6 = df_TD_hour6.drop(df_TD_hour6[df_TD_hour6['Point_speed']==0].index)\n",
    "df_TD_hour6.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour6.rename(columns={'Point_speed':'6'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour6['Count'] = np.arange(len(df_TD_hour6))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour7'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour7 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour7 = df_TD_hour7.drop(df_TD_hour7[df_TD_hour7['Point_speed']==0].index)\n",
    "df_TD_hour7.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour7.rename(columns={'Point_speed':'7'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour7['Count'] = np.arange(len(df_TD_hour7))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour8'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour8 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour8 = df_TD_hour8.drop(df_TD_hour8[df_TD_hour8['Point_speed']==0].index)\n",
    "df_TD_hour8\n",
    "# df_TD_hour8.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "# df_TD_hour8.rename(columns={'Point_speed':'8'},\n",
    "        #   inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "# df_TD_hour8['Count'] = np.arange(len(df_TD_hour8))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour9'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour9 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour9 = df_TD_hour9.drop(df_TD_hour9[df_TD_hour9['Point_speed']==0].index)\n",
    "# df_TD_hour9.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "# df_TD_hour9.rename(columns={'Point_speed':'9'},\n",
    "#           inplace=True, errors='raise')\n",
    "# # df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "# df_TD_hour9['Count'] = np.arange(len(df_TD_hour9))\n",
    "\n",
    "df_TD_hour9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_drivers=(np.intersect1d(df_TD_hour8['Numberplate'], df_TD_hour9['Numberplate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TD_hour8 = df_TD_hour8[df_TD_hour8['Numberplate'].isin(common_drivers)]\n",
    "df_TD_hour8 = df_TD_hour8.groupby(['Numberplate']).agg(Point_speed_hourly_average_8 = ('Point_speed', 'mean'))\n",
    "df_TD_hour8.reset_index(inplace=True)\n",
    "# df_TRIP_DETAIL_Motorway_10['Hour'] = '14'\n",
    "# df_TD_hour8\n",
    "\n",
    "df_TD_hour9 = df_TD_hour9[df_TD_hour9['Numberplate'].isin(common_drivers)]\n",
    "df_TD_hour9 = df_TD_hour9.groupby(['Numberplate']).agg(Point_speed_hourly_average_9 = ('Point_speed', 'mean'))\n",
    "df_TD_hour9.reset_index(inplace=True)\n",
    "\n",
    "# df_TD_hour9\n",
    "# df_TRIP_DETAIL_Motorway_9['Hour'] = '15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8thand9thHour = pd.merge(df_TD_hour8, df_TD_hour9, on='Numberplate', how='inner') #here id is common column\n",
    "\n",
    "df_8thand9thHour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import pandas as pd \n",
    "#  import seaborn as sns\n",
    "#  import matplotlib.pyplot as plt \n",
    "# import stats\n",
    "from scipy import stats\n",
    "\n",
    "p = sns.lmplot(x=\"Point_speed_hourly_average_8\", y=\"Point_speed_hourly_average_9\",\n",
    "        data=df_8thand9thHour,scatter_kws={\"color\": \"cornflowerblue\"},\n",
    "        line_kws={'label':\"Linear Reg\",\"color\":\"cornflowerblue\"}, legend=True)\n",
    "\n",
    "ax = p.axes[0, 0]\n",
    "ax.legend()\n",
    "leg = ax.get_legend()\n",
    "L_labels = leg.get_texts()\n",
    "# assuming you computed r_squared which is the coefficient of determination somewhere else\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_8thand9thHour[\"Point_speed_hourly_average_8\"],df_8thand9thHour[\"Point_speed_hourly_average_9\"])\n",
    "label_line_1 = r'$y={0:.1f}x+{1:.1f}'.format(slope,intercept)\n",
    "label_line_2 = r'$r:{0:.2f}$'.format(r_value) # as an exampple or whatever you want[!\n",
    "# L_labels[0].set_text(label_line_1)\n",
    "L_labels[0].set_text(label_line_2)\n",
    "# plt.title(\"Normalized Braking Events - Amsterdam & the NL (Urban Roads)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TRIP_DETAIL_Motorway_9=df_TRIP_DETAIL_Motorway[df_TRIP_DETAIL_Motorway['TNO_Time-stamp_hour']==15]\n",
    "df_TRIP_DETAIL_Motorway_10=df_TRIP_DETAIL_Motorway[df_TRIP_DETAIL_Motorway['TNO_Time-stamp_hour']==14]\n",
    "\n",
    "common_drivers=(np.intersect1d(df_TRIP_DETAIL_Motorway_9['Numberplate'], df_TRIP_DETAIL_Motorway_10['Numberplate']))\n",
    "\n",
    "df_TRIP_DETAIL_Motorway_10 = df_TRIP_DETAIL_Motorway_10[df_TRIP_DETAIL_Motorway_10['Numberplate'].isin(common_drivers)]\n",
    "df_TRIP_DETAIL_Motorway_10['Hour'] = '14'\n",
    "\n",
    "\n",
    "df_TRIP_DETAIL_Motorway_9 = df_TRIP_DETAIL_Motorway_9[df_TRIP_DETAIL_Motorway_9['Numberplate'].isin(common_drivers)]\n",
    "df_TRIP_DETAIL_Motorway_9['Hour'] = '15'\n",
    "\n",
    "\n",
    "df_TRIP_DETAIL_Motorway_9 = df_TRIP_DETAIL_Motorway_9.groupby(['Numberplate']).agg(Point_speed_hourly_average = ('Point_speed', 'mean'))\n",
    "df_TRIP_DETAIL_Motorway_9['Hour']='15'\n",
    "\n",
    "df_TRIP_DETAIL_Motorway_10 = df_TRIP_DETAIL_Motorway_10.groupby(['Numberplate']).agg(Point_speed_hourly_average = ('Point_speed', 'mean'))\n",
    "df_TRIP_DETAIL_Motorway_10['Hour']='14'\n",
    "\n",
    "frames=[df_TRIP_DETAIL_Motorway_9,df_TRIP_DETAIL_Motorway_10]\n",
    "df_9thand10thHour=pd.concat(frames)\n",
    "\n",
    "\n",
    "df_9thand10thHour = df_9thand10thHour.drop(df_9thand10thHour[df_9thand10thHour['Point_speed_hourly_average']==0].index)\n",
    "\n",
    "x_axis=df_9thand10thHour[df_9thand10thHour['Hour']=='15']['Point_speed_hourly_average']\n",
    "y_axis=df_9thand10thHour[df_9thand10thHour['Hour']=='14']['Point_speed_hourly_average']\n",
    "\n",
    "sns.regplot(x=y_axis, y=x_axis, data=df_9thand10thHour)\n",
    "plt.title('Point Speed of drivers on Motorways \\n (First 2 million Datapoints) \\n Correlation Coefficient : 0.323')\n",
    "plt.xlabel('Mean Point Speed (km/h) at 2 pm')\n",
    "plt.ylabel('Mean Point Speed (km/h) at 3 pm')\n",
    "\n",
    "# df_9thand10thHour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour9'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour9 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour9 = df_TD_hour9.drop(df_TD_hour9[df_TD_hour9['Point_speed']==0].index)\n",
    "df_TD_hour9.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour9.rename(columns={'Point_speed':'9'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour9['Count'] = np.arange(len(df_TD_hour9))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour10'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour10 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour10 = df_TD_hour10.drop(df_TD_hour10[df_TD_hour10['Point_speed']==0].index)\n",
    "df_TD_hour10.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour10.rename(columns={'Point_speed':'10'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour10['Count'] = np.arange(len(df_TD_hour10))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour11'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour11 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour11 = df_TD_hour11.drop(df_TD_hour11[df_TD_hour11['Point_speed']==0].index)\n",
    "df_TD_hour11.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour11.rename(columns={'Point_speed':'11'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour11['Count'] = np.arange(len(df_TD_hour11))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour12'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour12 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour12 = df_TD_hour12.drop(df_TD_hour12[df_TD_hour12['Point_speed']==0].index)\n",
    "df_TD_hour12.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour12.rename(columns={'Point_speed':'12'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour12['Count'] = np.arange(len(df_TD_hour12))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour13'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour13 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour13 = df_TD_hour13.drop(df_TD_hour13[df_TD_hour13['Point_speed']==0].index)\n",
    "df_TD_hour13.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour13.rename(columns={'Point_speed':'13'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour13['Count'] = np.arange(len(df_TD_hour13))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour14'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour14 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour14 = df_TD_hour14.drop(df_TD_hour14[df_TD_hour14['Point_speed']==0].index)\n",
    "df_TD_hour14.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour14.rename(columns={'Point_speed':'14'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour14['Count'] = np.arange(len(df_TD_hour14))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour15'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour15 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour15 = df_TD_hour15.drop(df_TD_hour15[df_TD_hour15['Point_speed']==0].index)\n",
    "df_TD_hour15.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour15.rename(columns={'Point_speed':'15'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour15['Count'] = np.arange(len(df_TD_hour15))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour16'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour16 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour16 = df_TD_hour16.drop(df_TD_hour16[df_TD_hour16['Point_speed']==0].index)\n",
    "df_TD_hour16.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour16.rename(columns={'Point_speed':'16'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour16['Count'] = np.arange(len(df_TD_hour16))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour17'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour17 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour17 = df_TD_hour17.drop(df_TD_hour17[df_TD_hour17['Point_speed']==0].index)\n",
    "df_TD_hour17.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour17.rename(columns={'Point_speed':'17'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour17['Count'] = np.arange(len(df_TD_hour17))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour18'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour18 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour18 = df_TD_hour18.drop(df_TD_hour18[df_TD_hour18['Point_speed']==0].index)\n",
    "df_TD_hour18.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour18.rename(columns={'Point_speed':'18'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour18['Count'] = np.arange(len(df_TD_hour18))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour19'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour19 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour19 = df_TD_hour19.drop(df_TD_hour19[df_TD_hour19['Point_speed']==0].index)\n",
    "df_TD_hour19.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour19.rename(columns={'Point_speed':'19'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour19['Count'] = np.arange(len(df_TD_hour19))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour20'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour20 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour20 = df_TD_hour20.drop(df_TD_hour20[df_TD_hour20['Point_speed']==0].index)\n",
    "df_TD_hour20.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour20.rename(columns={'Point_speed':'20'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour20['Count'] = np.arange(len(df_TD_hour20))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour21'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour21 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour21 = df_TD_hour21.drop(df_TD_hour21[df_TD_hour21['Point_speed']==0].index)\n",
    "df_TD_hour21.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour21.rename(columns={'Point_speed':'21'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour21['Count'] = np.arange(len(df_TD_hour21))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour22'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour22 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour22 = df_TD_hour22.drop(df_TD_hour22[df_TD_hour22['Point_speed']==0].index)\n",
    "df_TD_hour22.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour22.rename(columns={'Point_speed':'22'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour22['Count'] = np.arange(len(df_TD_hour22))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour23'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour23 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour23 = df_TD_hour23.drop(df_TD_hour23[df_TD_hour23['Point_speed']==0].index)\n",
    "df_TD_hour23.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "df_TD_hour23.rename(columns={'Point_speed':'23'},\n",
    "          inplace=True, errors='raise')\n",
    "# df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "df_TD_hour23['Count'] = np.arange(len(df_TD_hour23))\n",
    "\n",
    "# df_TD_hour5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# compile the list of dataframes you want to merge\n",
    "data_frames = [df_TD_hour0, df_TD_hour1, df_TD_hour2,df_TD_hour3,df_TD_hour4,df_TD_hour5,df_TD_hour6,df_TD_hour7,df_TD_hour8,df_TD_hour9,df_TD_hour10,df_TD_hour11,df_TD_hour12,df_TD_hour13,df_TD_hour14,\n",
    "               df_TD_hour15,df_TD_hour16,df_TD_hour17,df_TD_hour18,df_TD_hour19,df_TD_hour20,df_TD_hour21,df_TD_hour22,df_TD_hour23]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Count'],\n",
    "                                            how='inner'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# cmap =sns.diverging_palette(145, 300, s=60, as_cmap=True)\n",
    "\n",
    "# sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "sns.heatmap(df_merged.corr(), annot=False,fmt=\".1f\", \n",
    "           linewidths=0.5,cbar_kws={'label': 'Correlation Coefficient'},cmap=\"Spectral_r\")\n",
    "plt.xlabel('Hour of the day',fontweight=\"bold\",fontsize=13)\n",
    "plt.ylabel('Hour of the day',fontweight=\"bold\",fontsize=13)\n",
    "plt.title(r\"Heatmap depicting correlation of Point Speed\"+\"\\n\"+r\"(hours) - All road types\",fontsize=13,fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outer = pd.merge(df_TD_hour2, df_TD_hour3, on='Count', how='inner') #here Numberplate is common column\n",
    "# df_merged.drop(['Count'], axis = 1, inplace = True) \n",
    "sns.heatmap(df_merged.corr(),vmin=0,vmax=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour2'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour4 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour4 = df_TD_hour4.drop(df_TD_hour4[df_TD_hour4['Point_speed']==0].index)\n",
    "df_TD_hour4.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp'], axis = 1, inplace = True) \n",
    "df_TD_hour4.rename(columns={'TNO_Time-stamp_hour': 'Hour',\n",
    "                            'Point_speed':'Point Speed'},\n",
    "          inplace=True, errors='raise')\n",
    "df_TD_hour4[\"Hour\"] = df_TD_hour4[\"Hour\"].astype(int)\n",
    "df_TD_hour4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = sns.load_dataset(\"flights\")\n",
    "flights\n",
    "# flights = flights.pivot(\"month\", \"year\", \"passengers\")\n",
    "ax = sns.heatmap(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = flights.pivot(\"month\", \"year\", \"passengers\")\n",
    "flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_TD_hour8 = df_TD_hour8[df_TD_hour8['Numberplate'].isin(common_drivers)]\n",
    "# df_TD_hour8 = df_TD_hour8.groupby(['Numberplate']).agg(Point_speed_hourly_average_8 = ('Point_speed', 'mean'))\n",
    "# df_TD_hour8.reset_index(inplace=True)\n",
    "# df_TRIP_DETAIL_Motorway_10['Hour'] = '14'\n",
    "# df_TD_hour8\n",
    "\n",
    "# df_TD_hour9 = df_TD_hour9[df_TD_hour9['Numberplate'].isin(common_drivers)]\n",
    "df_TD_hour9 = df_TD_hour9.groupby(['Numberplate']).agg(Point_speed_hourly_average_9 = ('Point_speed', 'mean'))\n",
    "df_TD_hour9.reset_index(inplace=True)\n",
    "\n",
    "# df_TD_hour9\n",
    "# df_TRIP_DETAIL_Motorway_9['Hour'] = '15'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numberplate Temporal Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour0'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour0 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour0 = df_TD_hour0.drop(df_TD_hour0[df_TD_hour0['Point_speed']==0].index)\n",
    "df_TD_hour0 = df_TD_hour0.groupby(['Numberplate']).agg(Point_speed_hourly_average_0 = ('Point_speed', 'mean'))\n",
    "df_TD_hour0.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TD_hour0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour1'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour1 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour1 = df_TD_hour1.drop(df_TD_hour1[df_TD_hour1['Point_speed']==0].index)\n",
    "df_TD_hour1 = df_TD_hour1.groupby(['Numberplate']).agg(Point_speed_hourly_average_1 = ('Point_speed', 'mean'))\n",
    "df_TD_hour1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour2'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour2 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour2 = df_TD_hour2.drop(df_TD_hour2[df_TD_hour2['Point_speed']==0].index)\n",
    "df_TD_hour2 = df_TD_hour2.groupby(['Numberplate']).agg(Point_speed_hourly_average_2 = ('Point_speed', 'mean'))\n",
    "df_TD_hour2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour3'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour3 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour3 = df_TD_hour3.drop(df_TD_hour3[df_TD_hour3['Point_speed']==0].index)\n",
    "df_TD_hour3 = df_TD_hour3.groupby(['Numberplate']).agg(Point_speed_hourly_average_3 = ('Point_speed', 'mean'))\n",
    "df_TD_hour3.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour4'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour4 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour4 = df_TD_hour4.drop(df_TD_hour4[df_TD_hour4['Point_speed']==0].index)\n",
    "df_TD_hour4 = df_TD_hour4.groupby(['Numberplate']).agg(Point_speed_hourly_average_4 = ('Point_speed', 'mean'))\n",
    "df_TD_hour4.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour5'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour5 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour5 = df_TD_hour5.drop(df_TD_hour5[df_TD_hour5['Point_speed']==0].index)\n",
    "df_TD_hour5 = df_TD_hour5.groupby(['Numberplate']).agg(Point_speed_hourly_average_5 = ('Point_speed', 'mean'))\n",
    "df_TD_hour5.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour6'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour6 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour6 = df_TD_hour6.drop(df_TD_hour6[df_TD_hour6['Point_speed']==0].index)\n",
    "df_TD_hour6 = df_TD_hour6.groupby(['Numberplate']).agg(Point_speed_hourly_average_6 = ('Point_speed', 'mean'))\n",
    "df_TD_hour6.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour7'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour7 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour7 = df_TD_hour7.drop(df_TD_hour7[df_TD_hour7['Point_speed']==0].index)\n",
    "df_TD_hour7 = df_TD_hour7.groupby(['Numberplate']).agg(Point_speed_hourly_average_7 = ('Point_speed', 'mean'))\n",
    "df_TD_hour7.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour8'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour8 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour8 = df_TD_hour8.drop(df_TD_hour8[df_TD_hour8['Point_speed']==0].index)\n",
    "df_TD_hour8 = df_TD_hour8.groupby(['Numberplate']).agg(Point_speed_hourly_average_8 = ('Point_speed', 'mean'))\n",
    "df_TD_hour8.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour9'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour9 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour9 = df_TD_hour9.drop(df_TD_hour9[df_TD_hour9['Point_speed']==0].index)\n",
    "df_TD_hour9 = df_TD_hour9.groupby(['Numberplate']).agg(Point_speed_hourly_average_9 = ('Point_speed', 'mean'))\n",
    "df_TD_hour9.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour10'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour10 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour10 = df_TD_hour10.drop(df_TD_hour10[df_TD_hour10['Point_speed']==0].index)\n",
    "df_TD_hour10 = df_TD_hour10.groupby(['Numberplate']).agg(Point_speed_hourly_average_10 = ('Point_speed', 'mean'))\n",
    "df_TD_hour10.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour11'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour11 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour11 = df_TD_hour11.drop(df_TD_hour11[df_TD_hour11['Point_speed']==0].index)\n",
    "df_TD_hour11 = df_TD_hour11.groupby(['Numberplate']).agg(Point_speed_hourly_average_11 = ('Point_speed', 'mean'))\n",
    "df_TD_hour11.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour12'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour12 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour12 = df_TD_hour12.drop(df_TD_hour12[df_TD_hour12['Point_speed']==0].index)\n",
    "df_TD_hour12 = df_TD_hour12.groupby(['Numberplate']).agg(Point_speed_hourly_average_12 = ('Point_speed', 'mean'))\n",
    "df_TD_hour12.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour13'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour13 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour13 = df_TD_hour13.drop(df_TD_hour13[df_TD_hour13['Point_speed']==0].index)\n",
    "df_TD_hour13 = df_TD_hour13.groupby(['Numberplate']).agg(Point_speed_hourly_average_13 = ('Point_speed', 'mean'))\n",
    "df_TD_hour13.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour14'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour14 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour14 = df_TD_hour14.drop(df_TD_hour14[df_TD_hour14['Point_speed']==0].index)\n",
    "df_TD_hour14 = df_TD_hour14.groupby(['Numberplate']).agg(Point_speed_hourly_average_14 = ('Point_speed', 'mean'))\n",
    "df_TD_hour14.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour15'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour15 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour15 = df_TD_hour15.drop(df_TD_hour15[df_TD_hour15['Point_speed']==0].index)\n",
    "df_TD_hour15 = df_TD_hour15.groupby(['Numberplate']).agg(Point_speed_hourly_average_15 = ('Point_speed', 'mean'))\n",
    "df_TD_hour15.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour16'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour16 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour16 = df_TD_hour16.drop(df_TD_hour16[df_TD_hour16['Point_speed']==0].index)\n",
    "df_TD_hour16 = df_TD_hour16.groupby(['Numberplate']).agg(Point_speed_hourly_average_16 = ('Point_speed', 'mean'))\n",
    "df_TD_hour16.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour17'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour17 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour17 = df_TD_hour17.drop(df_TD_hour17[df_TD_hour17['Point_speed']==0].index)\n",
    "df_TD_hour17 = df_TD_hour17.groupby(['Numberplate']).agg(Point_speed_hourly_average_17 = ('Point_speed', 'mean'))\n",
    "df_TD_hour17.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour18'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour18 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour18 = df_TD_hour18.drop(df_TD_hour18[df_TD_hour18['Point_speed']==0].index)\n",
    "df_TD_hour18 = df_TD_hour18.groupby(['Numberplate']).agg(Point_speed_hourly_average_18 = ('Point_speed', 'mean'))\n",
    "df_TD_hour18.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour19'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour19 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour19 = df_TD_hour19.drop(df_TD_hour19[df_TD_hour19['Point_speed']==0].index)\n",
    "df_TD_hour19 = df_TD_hour19.groupby(['Numberplate']).agg(Point_speed_hourly_average_19 = ('Point_speed', 'mean'))\n",
    "df_TD_hour19.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour20'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour20 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour20 = df_TD_hour20.drop(df_TD_hour20[df_TD_hour20['Point_speed']==0].index)\n",
    "df_TD_hour20 = df_TD_hour20.groupby(['Numberplate']).agg(Point_speed_hourly_average_20 = ('Point_speed', 'mean'))\n",
    "df_TD_hour20.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour21'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour21 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour21 = df_TD_hour21.drop(df_TD_hour21[df_TD_hour21['Point_speed']==0].index)\n",
    "df_TD_hour21 = df_TD_hour21.groupby(['Numberplate']).agg(Point_speed_hourly_average_21 = ('Point_speed', 'mean'))\n",
    "df_TD_hour21.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour22'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour22 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour22 = df_TD_hour22.drop(df_TD_hour22[df_TD_hour22['Point_speed']==0].index)\n",
    "df_TD_hour22 = df_TD_hour22.groupby(['Numberplate']).agg(Point_speed_hourly_average_22 = ('Point_speed', 'mean'))\n",
    "df_TD_hour22.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\split_data\\Hour\\Hour23'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_TD_hour23 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "df_TD_hour23 = df_TD_hour23.drop(df_TD_hour23[df_TD_hour23['Point_speed']==0].index)\n",
    "df_TD_hour23 = df_TD_hour23.groupby(['Numberplate']).agg(Point_speed_hourly_average_23 = ('Point_speed', 'mean'))\n",
    "df_TD_hour23.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# compile the list of dataframes you want to merge\n",
    "data_frames = [df_TD_hour0, df_TD_hour1, df_TD_hour2,df_TD_hour3,df_TD_hour4,df_TD_hour5,df_TD_hour6,df_TD_hour7,df_TD_hour8,df_TD_hour9,df_TD_hour10,df_TD_hour11,df_TD_hour12,df_TD_hour13,df_TD_hour14,\n",
    "               df_TD_hour15,df_TD_hour16,df_TD_hour17,df_TD_hour18,df_TD_hour19,df_TD_hour20,df_TD_hour21,df_TD_hour22,df_TD_hour23]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Numberplate'],\n",
    "                                            how='inner'), data_frames)\n",
    "\n",
    "df_merged.rename(columns={'Point_speed_hourly_average_0': '0',\n",
    "                            'Point_speed_hourly_average_1': '1',\n",
    "                            'Point_speed_hourly_average_2': '2',\n",
    "                            'Point_speed_hourly_average_3': '3',\n",
    "                            'Point_speed_hourly_average_4': '4',\n",
    "                            'Point_speed_hourly_average_5': '5',\n",
    "                            'Point_speed_hourly_average_6': '6',\n",
    "                            'Point_speed_hourly_average_7': '7',\n",
    "                            'Point_speed_hourly_average_8': '8',\n",
    "                            'Point_speed_hourly_average_9': '9',\n",
    "                            'Point_speed_hourly_average_10': '10',\n",
    "                            'Point_speed_hourly_average_11': '11',\n",
    "                            'Point_speed_hourly_average_12': '12',\n",
    "                            'Point_speed_hourly_average_13': '13',\n",
    "                            'Point_speed_hourly_average_14': '14',\n",
    "                            'Point_speed_hourly_average_15': '15',\n",
    "                            'Point_speed_hourly_average_16': '16',\n",
    "                            'Point_speed_hourly_average_17': '17',\n",
    "                            'Point_speed_hourly_average_18': '18',\n",
    "                            'Point_speed_hourly_average_19': '19',\n",
    "                            'Point_speed_hourly_average_20': '20',\n",
    "                            'Point_speed_hourly_average_21': '21',\n",
    "                            'Point_speed_hourly_average_22': '22',\n",
    "                            'Point_speed_hourly_average_23': '23'},inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop(['Numberplate'], axis = 1, inplace = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# df_cm = pd.DataFrame(array)\n",
    "\n",
    "# matrix = np.triu(df_cm)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "# plt.title('')\n",
    "sn.heatmap(df_merged.corr(), annot=False,fmt=\".1f\", \n",
    "           linewidths=0.5, cmap=\"coolwarm\",cbar_kws={'label': 'Mean Point Speed (km/h)'})\n",
    "plt.xlabel('Hour of the day',fontweight=\"bold\",fontsize=13)\n",
    "plt.ylabel('Hour of the day',fontweight=\"bold\",fontsize=13)\n",
    "plt.title(r\"Heatmap - Mean Point Speed \"+\"\\n\"+r\"(over hours of the day) - All road types\",fontsize=13,fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr=df_merged.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# mask\n",
    "mask = np.triu(np.ones_like(df_corr, dtype=np.bool))\n",
    "# adjust mask and df\n",
    "mask = mask[1:, :-1]\n",
    "corr = df_corr.iloc[1:,:-1].copy()\n",
    "# color map\n",
    "# cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
    "# plot heatmap\n",
    "\n",
    "# sns.heatmap(df_merged.corr(), annot=False,fmt=\".1f\", \n",
    "#            linewidths=0.5, cmap=\"coolwarm\",cbar_kws={'label': 'Mean Point Speed (km/h)'})\n",
    "\n",
    "sns.heatmap(corr, mask=mask, annot=False, fmt=\".2f\", \n",
    "           linewidths=0.5, cmap=\"coolwarm\", square=True,cbar_kws={'label': 'Correlation Coefficient'})\n",
    "# ticks\n",
    "yticks = [i.upper() for i in corr.index]\n",
    "xticks = [i.upper() for i in corr.columns]\n",
    "plt.yticks(plt.yticks()[0], labels=yticks, rotation=0)\n",
    "plt.xticks(plt.xticks()[0], labels=xticks)\n",
    "# title\n",
    "plt.xlabel('Hour of the day',fontweight=\"bold\",fontsize=13)\n",
    "plt.ylabel('Hour of the day',fontweight=\"bold\",fontsize=13)\n",
    "plt.title(r\"Heatmap - Mean Point Speed (km/h) \"+\"\\n\"+r\"(over hours of the day) - All road types\",fontsize=13,fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AOS Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def count_of_vals(which_hour,hour_val):\n",
    "    path=r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour'+which_hour\n",
    "    all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "    df_aos_summary0 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "    df_aos_summary0=df_aos_summary0.groupby(['Numberplate','Event type Rename']).size().unstack(fill_value=0)\n",
    "    df_aos_summary0.drop([' Indicators = OFF', 'Brakes = OFF','Headway Warning = OFF','Lane Departure Warning = OFF', 'Left Indicator = ON','Left and Right Indicator = ON',\n",
    "        'Right Indicator = ON','Headway Warning (long)','Headway Warning (medium)','Left Lane Departure Warning = ON','Brakes = ON','Right Lane Departure Warning = ON'], axis = 1, inplace = True) \n",
    "    df_aos_summary0.rename(columns={'Headway Warning (short)': 'L(III)-HW'+hour_val},inplace=True, errors='raise')\n",
    "    # df_aos_summary0.rename(columns={'Brakes = ON': 'Braking Events'+hour_val,\n",
    "    #                             'Headway Warning (long)': 'L(I)-HW'+hour_val,\n",
    "    #                             'Headway Warning (medium)': 'L(I)-HW'+hour_val,\n",
    "    #                             'Headway Warning (short)': 'L(I)-HW'+hour_val,\n",
    "    #                             'Left Lane Departure Warning = ON': 'L-LDW'+hour_val,\n",
    "    #                             'Right Lane Departure Warning = ON': 'R-LDW'+hour_val},inplace=True, errors='raise')\n",
    "    df_aos_summary0.reset_index(inplace=True)\n",
    "    # df_aos_summary0.drop(['Event type Rename'],axis=1,inplace=True)\n",
    "    \n",
    "    return df_aos_summary0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aos_summary0=count_of_vals('\\Hour0','0')\n",
    "df_aos_summary1=count_of_vals('\\Hour1','1')\n",
    "df_aos_summary2=count_of_vals('\\Hour2','2')\n",
    "df_aos_summary3=count_of_vals('\\Hour3','3')\n",
    "df_aos_summary4=count_of_vals('\\Hour4','4')\n",
    "df_aos_summary5=count_of_vals('\\Hour5','5')\n",
    "df_aos_summary6=count_of_vals('\\Hour6','6')\n",
    "df_aos_summary7=count_of_vals('\\Hour7','7')\n",
    "df_aos_summary8=count_of_vals('\\Hour8','8')\n",
    "df_aos_summary9=count_of_vals('\\Hour9','9')\n",
    "df_aos_summary10=count_of_vals('\\Hour10','10')\n",
    "df_aos_summary11=count_of_vals('\\Hour11','11')\n",
    "df_aos_summary12=count_of_vals('\\Hour12','12')\n",
    "df_aos_summary13=count_of_vals('\\Hour13','13')\n",
    "df_aos_summary14=count_of_vals('\\Hour14','14')\n",
    "df_aos_summary15=count_of_vals('\\Hour15','15')\n",
    "df_aos_summary16=count_of_vals('\\Hour16','16')\n",
    "df_aos_summary17=count_of_vals('\\Hour17','17')\n",
    "df_aos_summary18=count_of_vals('\\Hour18','18')\n",
    "df_aos_summary19=count_of_vals('\\Hour19','19')\n",
    "df_aos_summary20=count_of_vals('\\Hour20','20')\n",
    "df_aos_summary21=count_of_vals('\\Hour21','21')\n",
    "df_aos_summary22=count_of_vals('\\Hour22','22')\n",
    "df_aos_summary23=count_of_vals('\\Hour23','23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = pd.DatetimeIndex(df['Date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# compile the list of dataframes you want to merge\n",
    "data_frames = [df_aos_summary0, df_aos_summary1, df_aos_summary2,df_aos_summary3,df_aos_summary4,df_aos_summary5,df_aos_summary6,df_aos_summary7,df_aos_summary8,df_aos_summary9,df_aos_summary10,df_aos_summary11,df_aos_summary12,df_aos_summary13,df_aos_summary14,\n",
    "               df_aos_summary15,df_aos_summary16,df_aos_summary17,df_aos_summary18,df_aos_summary19,df_aos_summary20,df_aos_summary21,df_aos_summary22,df_aos_summary23]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Numberplate'],\n",
    "                                            how='inner'), data_frames)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.rename(columns={'Braking Events0': '0',\n",
    "#                                 'Braking Events1': '1',\n",
    "#                                 'Braking Events2': '2',\n",
    "#                                 'Braking Events3': '3',\n",
    "#                                 'Braking Events4': '4',\n",
    "#                                 'Braking Events5': '5',\n",
    "#                                 'Braking Events6': '6',\n",
    "#                                 'Braking Events7': '7',\n",
    "#                                 'Braking Events8': '8',\n",
    "#                                 'Braking Events9': '9',\n",
    "#                                 'Braking Events10': '10',\n",
    "#                                 'Braking Events11': '11',\n",
    "#                                 'Braking Events12': '12',\n",
    "#                                 'Braking Events13': '13',\n",
    "#                                 'Braking Events14': '14',\n",
    "#                                 'Braking Events15': '15',\n",
    "#                                 'Braking Events16': '16',\n",
    "#                                 'Braking Events17': '17',\n",
    "#                                 'Braking Events18': '18',\n",
    "#                                 'Braking Events19': '19',\n",
    "#                                 'Braking Events20': '20',\n",
    "#                                 'Braking Events21': '21',\n",
    "#                                 'Braking Events22': '22',\n",
    "#                                 'Braking Events23': '23'},inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.rename(columns={'R-LDW0': '0',\n",
    "#                                 'R-LDW1': '1',\n",
    "#                                 'R-LDW2': '2',\n",
    "#                                 'R-LDW3': '3',\n",
    "#                                 'R-LDW4': '4',\n",
    "#                                 'R-LDW5': '5',\n",
    "#                                 'R-LDW6': '6',\n",
    "#                                 'R-LDW7': '7',\n",
    "#                                 'R-LDW8': '8',\n",
    "#                                 'R-LDW9': '9',\n",
    "#                                 'R-LDW10': '10',\n",
    "#                                 'R-LDW11': '11',\n",
    "#                                 'R-LDW12': '12',\n",
    "#                                 'R-LDW13': '13',\n",
    "#                                 'R-LDW14': '14',\n",
    "#                                 'R-LDW15': '15',\n",
    "#                                 'R-LDW16': '16',\n",
    "#                                 'R-LDW17': '17',\n",
    "#                                 'R-LDW18': '18',\n",
    "#                                 'R-LDW19': '19',\n",
    "#                                 'R-LDW20': '20',\n",
    "#                                 'R-LDW21': '21',\n",
    "#                                 'R-LDW22': '22',\n",
    "#                                 'R-LDW23': '23'},inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.rename(columns={'L(III)-HW0': '0',\n",
    "                                'L(III)-HW1': '1',\n",
    "                                'L(III)-HW2': '2',\n",
    "                                'L(III)-HW3': '3',\n",
    "                                'L(III)-HW4': '4',\n",
    "                                'L(III)-HW5': '5',\n",
    "                                'L(III)-HW6': '6',\n",
    "                                'L(III)-HW7': '7',\n",
    "                                'L(III)-HW8': '8',\n",
    "                                'L(III)-HW9': '9',\n",
    "                                'L(III)-HW10': '10',\n",
    "                                'L(III)-HW11': '11',\n",
    "                                'L(III)-HW12': '12',\n",
    "                                'L(III)-HW13': '13',\n",
    "                                'L(III)-HW14': '14',\n",
    "                                'L(III)-HW15': '15',\n",
    "                                'L(III)-HW16': '16',\n",
    "                                'L(III)-HW17': '17',\n",
    "                                'L(III)-HW18': '18',\n",
    "                                'L(III)-HW19': '19',\n",
    "                                'L(III)-HW20': '20',\n",
    "                                'L(III)-HW21': '21',\n",
    "                                'L(III)-HW22': '22',\n",
    "                                'L(III)-HW23': '23'},inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr=df_merged.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# mask\n",
    "mask = np.triu(np.ones_like(df_corr, dtype=np.bool))\n",
    "# adjust mask and df\n",
    "mask = mask[1:, :-1]\n",
    "corr = df_corr.iloc[1:,:-1].copy()\n",
    "# color map\n",
    "# cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
    "# plot heatmap\n",
    "\n",
    "# sns.heatmap(df_merged.corr(), annot=False,fmt=\".1f\", \n",
    "#            linewidths=0.5, cmap=\"coolwarm\",cbar_kws={'label': 'Mean Point Speed (km/h)'})\n",
    "\n",
    "sns.heatmap(corr, mask=mask, annot=False, fmt=\".2f\", \n",
    "           linewidths=0.5, cmap=\"coolwarm\", square=True,cbar_kws={'label': 'Correlation Coefficient'})\n",
    "# ticks\n",
    "yticks = [i.upper() for i in corr.index]\n",
    "xticks = [i.upper() for i in corr.columns]\n",
    "plt.yticks(plt.yticks()[0], labels=yticks, rotation=0)\n",
    "plt.xticks(plt.xticks()[0], labels=xticks)\n",
    "# title\n",
    "plt.xlabel('Hour of the day',fontweight=\"bold\",fontsize=13)\n",
    "plt.ylabel('Hour of the day',fontweight=\"bold\",fontsize=13)\n",
    "plt.title(r\"Heatmap : L(III)-HW \"+\"\\n\"+r\"(over hours of the day) - All road types\",fontsize=13,fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/visualizing-three-dimensional-data-heatmaps-contours-and-3d-plots-with-python-bd718d1b42b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meshgrid\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "X, Y = np.meshgrid(np.linspace(0, 24,1), np.linspace(0, 24, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = ax.plot_surface(X=X, Y=Y, Z=df_merged.corr(), cmap='YlGnBu_r', vmin=0, vmax=200)\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AOS Summary count plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import vaex # https://vaex.io/docs/index.html\"\n",
    "import pathlib\n",
    "from pathlib import *\n",
    "import os\n",
    "import pickle\n",
    "# import cufflinks as cf\n",
    "# import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,plot,iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path=r'D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour\\Hour23'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df_aos_hour0 = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "# df_TD_hour0 = df_TD_hour0.drop(df_TD_hour0[df_TD_hour0['Point_speed']==0].index)\n",
    "# df_TD_hour0.drop(['Unnamed: 0', 'Numberplate','TNO_Time-stamp','TNO_Time-stamp_hour'], axis = 1, inplace = True) \n",
    "# df_TD_hour0.rename(columns={'Point_speed':'0'},\n",
    "#           inplace=True, errors='raise')\n",
    "# # df_TD_hour3[\"Hour\"] = df_TD_hour3[\"Hour\"].astype(int)\n",
    "# df_aos_hour0['Count'] = np.arange(len(df_aos_hour0))\n",
    "\n",
    "df_aos_hour0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_aos_event_count(df):\n",
    "    df=df.groupby(['Event type Rename','Road_type_Rename']).size().unstack(fill_value=0)\n",
    "    df.reset_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aos_hour0=total_aos_event_count(df_aos_hour0)\n",
    "df_aos_hour0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aos_hour0.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour\\df_aos_hour23.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_travelled=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour\\Urban\\df_aos_hour0.csv\")\n",
    "distance_travelled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"pastel\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Brakes = ON\"],linewidth=3.5,label=\"Braking Events\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Headway Warning (long)\"],linewidth=3.5,label=\"HW-L(I)\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Headway Warning (medium)\"],linewidth=3.5,label=\"HW-L(II)\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Headway Warning (short)\"],linewidth=3.5,label=\"HW-L(III)\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Left Lane Departure Warning = ON\"],linewidth=3.5,label=\"L-LDW\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Right Lane Departure Warning = ON\"],linewidth=3.5,label=\"R-LDW\")\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"Number of Data Points\")\n",
    "plt.legend(title=\"AOS Events\")\n",
    "plt.title(\"AOS events recorded in Urban areas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_travelled1=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\AOS_SUMMARY\\split_data\\Hour\\Motorway\\df_aos_hour0.csv\")\n",
    "distance_travelled1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_palette(\"plasma\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Brakes = ON\"],linewidth=3.5,label=\"Braking Events\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Headway Warning (long)\"],linewidth=3.5,label=\"HW-L(I)\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Headway Warning (medium)\"],linewidth=3.5,label=\"HW-L(II)\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Headway Warning (short)\"],linewidth=3.5,label=\"HW-L(III)\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Left Lane Departure Warning = ON\"],linewidth=3.5,label=\"L-LDW\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Right Lane Departure Warning = ON\"],linewidth=3.5,label=\"R-LDW\")\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylabel(\"Number of Data Points\")\n",
    "plt.legend(title=\"AOS Events\")\n",
    "plt.title(\"AOS events recorded in Urban areas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Left Lane Departure Warning = ON\"],linewidth=3.5,label=\"Urban\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Left Lane Departure Warning = ON\"],linewidth=3.5,label=\"Motorway\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Left Lane Departure Warning = ON\"],linewidth=3.5,label=\"Motorway\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Left Lane Departure Warning = ON\"],linewidth=3.5,label=\"Urban\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_travelled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Right Lane Departure Warning = ON\"],linewidth=3.5,label=\"R-LDW\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Right Indicator = ON\"],linewidth=3.5,label=\"Right Indicator = ON\")\n",
    "plt.ylabel(\"Number of Data Points\")\n",
    "plt.title(\"AOS Events recorded in Urban Areas\")\n",
    "# sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Right Lane Departure Warning = ON\"],linewidth=3.5,label=\"Motorway\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Right Lane Departure Warning = ON\"],linewidth=3.5,label=\"R-LDW\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Right Indicator = ON\"],linewidth=3.5,label=\"Right Indicator = ON\")\n",
    "plt.ylabel(\"Number of Data Points\")\n",
    "plt.title(\"AOS Events recorded on Motorways\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Left Lane Departure Warning = ON\"],linewidth=3.5,label=\"L-LDW\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Left Indicator = ON\"],linewidth=3.5,label=\"Left Indicator = ON\")\n",
    "plt.ylabel(\"Number of Data Points\")\n",
    "plt.title(\"AOS Events recorded on Motorways\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Left Lane Departure Warning = ON\"],linewidth=3.5,label=\"L-LDW\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Left Indicator = ON\"],linewidth=3.5,label=\"Left Indicator = ON\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Right Lane Departure Warning = ON\"],linewidth=3.5,label=\"R-LDW\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Right Indicator = ON\"],linewidth=3.5,label=\"Right Indicator = ON\")\n",
    "plt.ylabel(\"Number of Data Points\")\n",
    "plt.title(\"AOS Events recorded on Motorways\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Left Lane Departure Warning = ON\"],linewidth=3.5,label=\"L-LDW\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Left Indicator = ON\"],linewidth=3.5,label=\"Left Indicator = ON\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Right Lane Departure Warning = ON\"],linewidth=3.5,label=\"R-LDW\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Right Indicator = ON\"],linewidth=3.5,label=\"Right Indicator = ON\")\n",
    "plt.ylabel(\"Number of Data Points\")\n",
    "plt.title(\"AOS Events recorded in Urban Areas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_travelled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Headway Warning (long)\"],linewidth=3.5,label=\"HW-L(I)\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Headway Warning (medium)\"],linewidth=3.5,label=\"HW-L(II)\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Headway Warning (short)\"],linewidth=3.5,label=\"HW-L(III)\")\n",
    "sns.lineplot(x=distance_travelled[\"Hour\"],y=distance_travelled[\"Brakes = ON\"],linewidth=3.5,label=\"Braking Events\")\n",
    "plt.ylabel(\"Number of Data Points\")\n",
    "plt.title(\"AOS Events recorded in Urban Areas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Headway Warning (long)\"],linewidth=3.5,label=\"HW-L(I)\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Headway Warning (medium)\"],linewidth=3.5,label=\"HW-L(II)\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Headway Warning (short)\"],linewidth=3.5,label=\"HW-L(III)\")\n",
    "sns.lineplot(x=distance_travelled1[\"Hour\"],y=distance_travelled1[\"Brakes = ON\"],linewidth=3.5,label=\"Braking Events\")\n",
    "plt.ylabel(\"Number of Data Points\")\n",
    "plt.title(\"AOS Events recorded on Motorways\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2cfa282833ad131b813daadc2d579e64b9e3379708ebc6d12c1926855f4c941"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import vaex # https://vaex.io/docs/index.html\n",
    "import pathlib\n",
    "from pathlib import *\n",
    "import os\n",
    "import pickle\n",
    "# import cufflinks as cf\n",
    "# import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,plot,iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO -> Create functions for repetitive tasks\n",
    "\n",
    "# ,skiprows=range(3, 260000000)\n",
    "# Input the csv\n",
    "# Extracting a subset of 1000000 rows by default\n",
    "def load_data(dir_name,base_filename):\n",
    "    complete_path=os.path.join(dir_name, base_filename + \".\" + \"csv\")\n",
    "    # df=pd.read_csv(complete_path,sep=';',encoding= 'unicode_escape',nrows=10000,engine='c',infer_datetime_format=True,usecols=['Trip_Summary_Id','Numberplate','Point_time-stamp','Latitude',\n",
    "    #                                                                                                                           'Longitude','Meters_travelled','Time_elapsed','Point_speed','Number_of_lanes',\n",
    "    #                                                                                                                           'Road_type','Road_class','Road_form','Speed_restriction','TNO_Time-stamp'])\n",
    "    # df = pd.concat((chunk for chunk in pd.read_csv(complete_path,sep=';',nrows=5000000,encoding= 'unicode_escape',engine='c',infer_datetime_format=True,chunksize=1000000,low_memory=False,usecols=['Numberplate','Latitude',\n",
    "    #                                                                                                                           'Longitude','Meters_travelled','Time_elapsed','Point_speed','Number_of_lanes',\n",
    "    #                                                                                                                           'Road_type','Road_class','Speed_restriction','TNO_Time-stamp'])))\n",
    "    \n",
    "    df = pd.concat((chunk for chunk in pd.read_csv(complete_path,sep=';',nrows=20000000,encoding= 'unicode_escape',engine='c',infer_datetime_format=True,chunksize=1000000,low_memory=False)))\n",
    "    return df\n",
    "\n",
    "# Dropping the first and last row of csv (\"------\")\n",
    "def drop_first_row(df):\n",
    "    df=df.iloc[1:]\n",
    "    df=df[:-1]\n",
    "    return df\n",
    "\n",
    "def resetIndex(df):\n",
    "    return df.reset_index()\n",
    "\n",
    "\n",
    "##TODO -> Rewrite this function\n",
    "\n",
    "def cast_to_correct_dtype(df):\n",
    "    \n",
    "    if 'Id' in df.columns:\n",
    "        df['Id'] = df['Id'].astype('int')\n",
    "        \n",
    "    if 'AOS_position_Id' in df.columns:\n",
    "        df['AOS_position_Id'] = df['AOS_position_Id'].astype('int')\n",
    "    \n",
    "    if 'Acceleration_x' in df.columns:\n",
    "        df['Acceleration_x'] = df['Acceleration_x'].astype('float')\n",
    "        \n",
    "    if 'Acceleration_y' in df.columns:\n",
    "        df['Acceleration_y'] = df['Acceleration_y'].astype('float')\n",
    "        \n",
    "    if 'TNO_Valid' in df.columns:\n",
    "        df['TNO_Valid'] = df['TNO_Valid'].astype('int')\n",
    "    \n",
    "    if 'Latitude' in df.columns:\n",
    "        df['Latitude'] = df['Latitude'].astype('float')\n",
    "        \n",
    "    if 'Longitude' in df.columns:\n",
    "        df['Longitude'] = df['Longitude'].astype('float')\n",
    "        \n",
    "    if 'Event/action_speed' in df.columns:\n",
    "        df['Event/action_speed'] = df['Event/action_speed'].astype('int')\n",
    "        \n",
    "    if 'Event/action_type' in df.columns:\n",
    "        df['Event/action_type'] = df['Event/action_type'].astype('int')    \n",
    "        \n",
    "    if 'Number_of_lanes' in df.columns:\n",
    "        df['Number_of_lanes'] = df['Number_of_lanes'].astype('int')\n",
    "        \n",
    "    if 'Road_class' in df.columns:\n",
    "        df['Road_class'] = df['Road_class'].astype('int')\n",
    "        \n",
    "    if 'Road_type' in df.columns:\n",
    "        df['Road_type'] = df['Road_type'].astype('int')\n",
    "        \n",
    "    if 'Crash_position_Id' in df.columns:\n",
    "        df['Crash_position_Id']=df['Crash_position_Id'].astype('int')\n",
    "        \n",
    "    if 'Crash_position_Id' in df.columns:\n",
    "        df['Crash_position_Id'] = df['Crash_position_Id'].astype('int')\n",
    "        \n",
    "    if 'Point_speed' in df.columns:\n",
    "        df['Point_speed'] = df['Point_speed'].astype('float')\n",
    "        \n",
    "    if 'Average_speed_fpp' in df.columns:\n",
    "        df['Average_speed_fpp'] = df['Average_speed_fpp'].astype('float')  \n",
    "        \n",
    "    if 'Average_Speed' in df.columns:\n",
    "        df['Average_Speed'] = df['Average_Speed'].astype('float')        \n",
    "\n",
    "    if 'Maximum_speed' in df.columns:\n",
    "        df['Maximum_speed'] = df['Maximum_speed'].astype('float')     \n",
    "        \n",
    "    if 'Meters_travelled' in df.columns:\n",
    "        df['Meters_travelled'] = df['Meters_travelled'].astype('int')  \n",
    "\n",
    "    if 'Road_form' in df.columns:\n",
    "        df['Road_form'] = df['Road_form'].astype('int') \n",
    "        \n",
    "    if 'Speed_restriction' in df.columns:\n",
    "        df['Speed_restriction'] = df['Speed_restriction'].astype('int') \n",
    "        \n",
    "    if 'Crash_speed' in df.columns:\n",
    "        df['Crash_speed'] = df['Crash_speed'].astype('int')\n",
    "        \n",
    "    if 'Maximum_acceleration' in df.columns:\n",
    "        df['Maximum_acceleration'] = df['Maximum_acceleration'].astype('float')\n",
    "        \n",
    "    if 'Numberplate' in df.columns:\n",
    "        df['Numberplate']=df['Numberplate'].astype('str')\n",
    "        \n",
    "\n",
    "    return df\n",
    "\n",
    "            \n",
    "\n",
    "## Handling date time related fields\n",
    "\n",
    "def cast_date_time(df):\n",
    "    if 'AOS_event/action_time' in df.columns:\n",
    "        df['AOS_event/action_time']=pd.datetime(df['AOS_event/action_time'],errors='coerce')\n",
    "        df['AOS_event/action_time_hour']=df['AOS_event/action_time'].dt.hour\n",
    "    \n",
    "    if 'TNO_Trip-start' in df.columns:\n",
    "        df['TNO_Trip-start'] = pd.to_datetime(df['TNO_Trip-start'],errors='coerce')\n",
    "        df['TNO_Trip-start_hour'] = df['TNO_Trip-start'].dt.hour\n",
    "        \n",
    "    if 'TNO_Trip-end' in df.columns:\n",
    "        df['TNO_Trip-end'] = pd.to_datetime(df['TNO_Trip-end'],errors='coerce')\n",
    "        \n",
    "    if 'Position_time' in df.columns:\n",
    "        df['Position_time'] = pd.to_datetime(df['Position_time'],errors='coerce')\n",
    "\n",
    "    if 'TNO_Time-stamp' in df.columns:\n",
    "        df['TNO_Time-stamp'] = pd.to_datetime(df['TNO_Time-stamp'],errors='coerce')\n",
    "        df['TNO_Time-stamp_hour'] = df['TNO_Time-stamp'].dt.hour\n",
    "        \n",
    "    return df\n",
    "\n",
    "## Converting Time Stamps to datetime\n",
    "\n",
    "def date_and_time_columns(df):\n",
    "    if 'AOS_event/action_time' in df.columns:\n",
    "        df['AOS Trip Date']=df['AOS_event/action_time'].dt.date\n",
    "        df['AOS Event Time']=df['AOS_event/action_time'].dt.time\n",
    "        df['AOS Trip Hour']=df['AOS_event/action_time'].dt.hour\n",
    "    \n",
    "    \n",
    "    if 'TNO_Time-stamp' in df.columns:\n",
    "        df['TNO Trip Date'] = df['TNO_Time-stamp'].dt.date\n",
    "        df['TNO Trip Time'] = df['TNO_Time-stamp'].dt.time\n",
    "        df['TNO Trip Hour']=df['TNO_Time-stamp'].dt.hour\n",
    "        # df['TNO Trip Hour'] = df['TNO Trip Time'].dt.hour\n",
    "    return df\n",
    "\n",
    "def Time_of_the_day(x):\n",
    "    if (x > 4) and (x <= 8):\n",
    "        return 'Early Morning'\n",
    "    elif (x > 8) and (x < 12 ):\n",
    "        return 'Morning'\n",
    "    elif (x >= 12) and (x <= 16):\n",
    "        return'Noon'\n",
    "    elif (x > 16) and (x <= 20) :\n",
    "        return 'Evening'\n",
    "    elif (x > 20) and (x <= 24):\n",
    "        return'Night'\n",
    "    elif (x <= 4):\n",
    "        return'Late Night'\n",
    "    \n",
    "    \n",
    "def rename_some_stuff(df):\n",
    "    if 'Event/action_type' in df.columns:\n",
    "        df[\"Event type Rename\"]=df[\"Event/action_type\"].replace({0: 'Headway Warning = OFF', 1: 'Headway Warning (long)', 2: 'Headway Warning (medium)'\n",
    "                                                                                 ,3: 'Headway Warning (short)',10:'Lane Departure Warning = OFF',11:'Left Lane Departure Warning = ON'\n",
    "                                                                                 ,12:'Right Lane Departure Warning = ON',13:'Left and Right Lane Departure Warning = ON'\n",
    "                                                                                 ,20:' Indicators = OFF',21:'Left Indicator = ON',22:'Right Indicator = ON',23:'Left and Right Indicator = ON'\n",
    "                                                                                 ,40:'Brakes = OFF',41:'Brakes = ON'})\n",
    "        \n",
    "    if 'Road_type' in df.columns:\n",
    "        df[\"Road_type_Rename\"]=df[\"Road_type\"].replace({0: \"Urban\", 1: \"Motorway\",2:\"Extra Urban\",3:\"Unavailable\"})\n",
    "        \n",
    "    return df\n",
    "\n",
    "def detect_overspeeding_count(df):\n",
    "    # create a list of our conditions\n",
    "    # if 'Event/action_speed' and 'Speed_restriction' in df.columns:\n",
    "    #     conditions = [(df['Event/action_speed']> df['Speed_restriction'])]\n",
    "    #     # # create a list of the values we want to assign for each condition\n",
    "    #     values = [1]\n",
    "    #     # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    #     df['Overspeeding_event'] = np.select(conditions, values)\n",
    "        \n",
    "    # return df\n",
    "\n",
    "    if 'Point_speed' and 'Speed_restriction' in df.columns:\n",
    "        conditions = [(df['Point_speed']> df['Speed_restriction'])]\n",
    "        # # create a list of the values we want to assign for each condition\n",
    "        values = [1]\n",
    "        # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "        df['Overspeeding_event'] = np.select(conditions, values)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def some_processing(df):\n",
    "    if 'Meters_travelled' in df.columns:\n",
    "        df['KmTravelled']=df['Meters_travelled']/1000\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Extract Files for different cities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add name of city you're exploring\n",
    "city_name='Amsterdam'\n",
    "# city_name='Zwolle'\n",
    "# city_name='Zwolle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 1% Completed | 22.7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivasu\\anaconda3\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:176: DtypeWarning:\n",
      "\n",
      "Columns (0,1,2,6,7,8,9,10,11,12,13,14,15,16,17,18,21,22,23,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#                                       ] | 4% Completed | 45.1s"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "df = dd.read_csv(r'D:\\AOS FOT\\Octo\\CSV Export\\TRIP_DETAIL\\TRIP_DETAIL.csv',delimiter=';', encoding='unicode_escape')\n",
    "\n",
    "df = df[df['Admin_area']==city_name] # Extract trips within a city \n",
    "df = df[df['Road_type']==0] #Urban road\n",
    "with ProgressBar():\n",
    "    df = df.compute()\n",
    "    \n",
    "df['platedate'] = df['Numberplate'] + df['TNO_Time-stamp'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering City\\Trip Detail\\Amsterdam\\trip_detail_within_amsterdam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2cfa282833ad131b813daadc2d579e64b9e3379708ebc6d12c1926855f4c941"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

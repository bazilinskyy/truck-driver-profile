{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Clustering Analysis- Urban Areas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import vaex # https://vaex.io/docs/index.html\n",
    "import pathlib\n",
    "from pathlib import *\n",
    "import os\n",
    "import pickle\n",
    "# import cufflinks as cf\n",
    "# import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,plot,iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions that can be used to create chunks of `TRIP_DETAIL` and `AOS_SUMMARY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO -> Create functions for repetitive tasks\n",
    "\n",
    "# ,skiprows=range(3, 260000000)\n",
    "# Input the csv\n",
    "# Extracting a subset of 1000000 rows by default\n",
    "def load_data(dir_name,base_filename):\n",
    "    complete_path=os.path.join(dir_name, base_filename + \".\" + \"csv\")\n",
    "    # df=pd.read_csv(complete_path,sep=';',encoding= 'unicode_escape',nrows=10000,engine='c',infer_datetime_format=True,usecols=['Trip_Summary_Id','Numberplate','Point_time-stamp','Latitude',\n",
    "    #                                                                                                                           'Longitude','Meters_travelled','Time_elapsed','Point_speed','Number_of_lanes',\n",
    "    #                                                                                                                           'Road_type','Road_class','Road_form','Speed_restriction','TNO_Time-stamp'])\n",
    "    # df = pd.concat((chunk for chunk in pd.read_csv(complete_path,sep=';',nrows=5000000,encoding= 'unicode_escape',engine='c',infer_datetime_format=True,chunksize=1000000,low_memory=False,usecols=['Numberplate','Latitude',\n",
    "    #                                                                                                                           'Longitude','Meters_travelled','Time_elapsed','Point_speed','Number_of_lanes',\n",
    "    #                                                                                                                           'Road_type','Road_class','Speed_restriction','TNO_Time-stamp'])))\n",
    "    \n",
    "    df = pd.concat((chunk for chunk in pd.read_csv(complete_path,sep=';',nrows=20000000,encoding= 'unicode_escape',engine='c',infer_datetime_format=True,chunksize=1000000,low_memory=False)))\n",
    "    return df\n",
    "\n",
    "# Dropping the first and last row of csv (\"------\")\n",
    "def drop_first_row(df):\n",
    "    df=df.iloc[1:]\n",
    "    df=df[:-1]\n",
    "    return df\n",
    "\n",
    "def resetIndex(df):\n",
    "    return df.reset_index()\n",
    "\n",
    "\n",
    "##TODO -> Rewrite this function\n",
    "\n",
    "def cast_to_correct_dtype(df):\n",
    "    \n",
    "    if 'Id' in df.columns:\n",
    "        df['Id'] = df['Id'].astype('int')\n",
    "        \n",
    "    if 'AOS_position_Id' in df.columns:\n",
    "        df['AOS_position_Id'] = df['AOS_position_Id'].astype('int')\n",
    "    \n",
    "    if 'Acceleration_x' in df.columns:\n",
    "        df['Acceleration_x'] = df['Acceleration_x'].astype('float')\n",
    "        \n",
    "    if 'Acceleration_y' in df.columns:\n",
    "        df['Acceleration_y'] = df['Acceleration_y'].astype('float')\n",
    "        \n",
    "    if 'TNO_Valid' in df.columns:\n",
    "        df['TNO_Valid'] = df['TNO_Valid'].astype('int')\n",
    "    \n",
    "    if 'Latitude' in df.columns:\n",
    "        df['Latitude'] = df['Latitude'].astype('float')\n",
    "        \n",
    "    if 'Longitude' in df.columns:\n",
    "        df['Longitude'] = df['Longitude'].astype('float')\n",
    "        \n",
    "    if 'Event/action_speed' in df.columns:\n",
    "        df['Event/action_speed'] = df['Event/action_speed'].astype('int')\n",
    "        \n",
    "    if 'Event/action_type' in df.columns:\n",
    "        df['Event/action_type'] = df['Event/action_type'].astype('int')    \n",
    "        \n",
    "    if 'Number_of_lanes' in df.columns:\n",
    "        df['Number_of_lanes'] = df['Number_of_lanes'].astype('int')\n",
    "        \n",
    "    if 'Road_class' in df.columns:\n",
    "        df['Road_class'] = df['Road_class'].astype('int')\n",
    "        \n",
    "    if 'Road_type' in df.columns:\n",
    "        df['Road_type'] = df['Road_type'].astype('int')\n",
    "        \n",
    "    if 'Crash_position_Id' in df.columns:\n",
    "        df['Crash_position_Id']=df['Crash_position_Id'].astype('int')\n",
    "        \n",
    "    if 'Crash_position_Id' in df.columns:\n",
    "        df['Crash_position_Id'] = df['Crash_position_Id'].astype('int')\n",
    "        \n",
    "    if 'Point_speed' in df.columns:\n",
    "        df['Point_speed'] = df['Point_speed'].astype('float')\n",
    "        \n",
    "    if 'Average_speed_fpp' in df.columns:\n",
    "        df['Average_speed_fpp'] = df['Average_speed_fpp'].astype('float')  \n",
    "        \n",
    "    if 'Average_Speed' in df.columns:\n",
    "        df['Average_Speed'] = df['Average_Speed'].astype('float')        \n",
    "\n",
    "    if 'Maximum_speed' in df.columns:\n",
    "        df['Maximum_speed'] = df['Maximum_speed'].astype('float')     \n",
    "        \n",
    "    if 'Meters_travelled' in df.columns:\n",
    "        df['Meters_travelled'] = df['Meters_travelled'].astype('int')  \n",
    "\n",
    "    if 'Road_form' in df.columns:\n",
    "        df['Road_form'] = df['Road_form'].astype('int') \n",
    "        \n",
    "    if 'Speed_restriction' in df.columns:\n",
    "        df['Speed_restriction'] = df['Speed_restriction'].astype('int') \n",
    "        \n",
    "    if 'Crash_speed' in df.columns:\n",
    "        df['Crash_speed'] = df['Crash_speed'].astype('int')\n",
    "        \n",
    "    if 'Maximum_acceleration' in df.columns:\n",
    "        df['Maximum_acceleration'] = df['Maximum_acceleration'].astype('float')\n",
    "        \n",
    "    if 'Numberplate' in df.columns:\n",
    "        df['Numberplate']=df['Numberplate'].astype('str')\n",
    "        \n",
    "\n",
    "    return df\n",
    "\n",
    "            \n",
    "\n",
    "## Handling date time related fields\n",
    "\n",
    "def cast_date_time(df):\n",
    "    if 'AOS_event/action_time' in df.columns:\n",
    "        df['AOS_event/action_time']=pd.datetime(df['AOS_event/action_time'],errors='coerce')\n",
    "        df['AOS_event/action_time_hour']=df['AOS_event/action_time'].dt.hour\n",
    "    \n",
    "    if 'TNO_Trip-start' in df.columns:\n",
    "        df['TNO_Trip-start'] = pd.to_datetime(df['TNO_Trip-start'],errors='coerce')\n",
    "        df['TNO_Trip-start_hour'] = df['TNO_Trip-start'].dt.hour\n",
    "        \n",
    "    if 'TNO_Trip-end' in df.columns:\n",
    "        df['TNO_Trip-end'] = pd.to_datetime(df['TNO_Trip-end'],errors='coerce')\n",
    "        \n",
    "    if 'Position_time' in df.columns:\n",
    "        df['Position_time'] = pd.to_datetime(df['Position_time'],errors='coerce')\n",
    "\n",
    "    if 'TNO_Time-stamp' in df.columns:\n",
    "        df['TNO_Time-stamp'] = pd.to_datetime(df['TNO_Time-stamp'],errors='coerce')\n",
    "        df['TNO_Time-stamp_hour'] = df['TNO_Time-stamp'].dt.hour\n",
    "        \n",
    "    return df\n",
    "\n",
    "## Converting Time Stamps to datetime\n",
    "\n",
    "def date_and_time_columns(df):\n",
    "    if 'AOS_event/action_time' in df.columns:\n",
    "        df['AOS Trip Date']=df['AOS_event/action_time'].dt.date\n",
    "        df['AOS Event Time']=df['AOS_event/action_time'].dt.time\n",
    "        df['AOS Trip Hour']=df['AOS_event/action_time'].dt.hour\n",
    "    \n",
    "    \n",
    "    if 'TNO_Time-stamp' in df.columns:\n",
    "        df['TNO Trip Date'] = df['TNO_Time-stamp'].dt.date\n",
    "        df['TNO Trip Time'] = df['TNO_Time-stamp'].dt.time\n",
    "        df['TNO Trip Hour']=df['TNO_Time-stamp'].dt.hour\n",
    "        # df['TNO Trip Hour'] = df['TNO Trip Time'].dt.hour\n",
    "    return df\n",
    "\n",
    "def Time_of_the_day(x):\n",
    "    if (x > 4) and (x <= 8):\n",
    "        return 'Early Morning'\n",
    "    elif (x > 8) and (x < 12 ):\n",
    "        return 'Morning'\n",
    "    elif (x >= 12) and (x <= 16):\n",
    "        return'Noon'\n",
    "    elif (x > 16) and (x <= 20) :\n",
    "        return 'Evening'\n",
    "    elif (x > 20) and (x <= 24):\n",
    "        return'Night'\n",
    "    elif (x <= 4):\n",
    "        return'Late Night'\n",
    "    \n",
    "    \n",
    "def rename_some_stuff(df):\n",
    "    if 'Event/action_type' in df.columns:\n",
    "        df[\"Event type Rename\"]=df[\"Event/action_type\"].replace({0: 'Headway Warning = OFF', 1: 'Headway Warning (long)', 2: 'Headway Warning (medium)'\n",
    "                                                                                 ,3: 'Headway Warning (short)',10:'Lane Departure Warning = OFF',11:'Left Lane Departure Warning = ON'\n",
    "                                                                                 ,12:'Right Lane Departure Warning = ON',13:'Left and Right Lane Departure Warning = ON'\n",
    "                                                                                 ,20:' Indicators = OFF',21:'Left Indicator = ON',22:'Right Indicator = ON',23:'Left and Right Indicator = ON'\n",
    "                                                                                 ,40:'Brakes = OFF',41:'Brakes = ON'})\n",
    "        \n",
    "    if 'Road_type' in df.columns:\n",
    "        df[\"Road_type_Rename\"]=df[\"Road_type\"].replace({0: \"Urban\", 1: \"Motorway\",2:\"Extra Urban\",3:\"Unavailable\"})\n",
    "        \n",
    "    return df\n",
    "\n",
    "def detect_overspeeding_count(df):\n",
    "    # create a list of our conditions\n",
    "    # if 'Event/action_speed' and 'Speed_restriction' in df.columns:\n",
    "    #     conditions = [(df['Event/action_speed']> df['Speed_restriction'])]\n",
    "    #     # # create a list of the values we want to assign for each condition\n",
    "    #     values = [1]\n",
    "    #     # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    #     df['Overspeeding_event'] = np.select(conditions, values)\n",
    "        \n",
    "    # return df\n",
    "\n",
    "    if 'Point_speed' and 'Speed_restriction' in df.columns:\n",
    "        conditions = [(df['Point_speed']> df['Speed_restriction'])]\n",
    "        # # create a list of the values we want to assign for each condition\n",
    "        values = [1]\n",
    "        # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "        df['Overspeeding_event'] = np.select(conditions, values)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def some_processing(df):\n",
    "    if 'Meters_travelled' in df.columns:\n",
    "        df['KmTravelled']=df['Meters_travelled']/1000\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Extract Files for different cities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_city_to_explore(city_name):\n",
    "    if city_name=='Amsterdam':\n",
    "        city_coordinates = [(52.430779, 4.737382), (52.422361, 4.811680), (52.418126, 4.850948), \n",
    "                            (52.431506, 4.859627),(52.421959, 4.913905),(52.414543, 4.933522),(52.425437, 4.954927),\n",
    "                            (52.428570, 4.982090),(52.423581, 5.017310),(52.417493, 5.067539),(52.397841, 5.031621),\n",
    "                            (52.373215, 5.014760),(52.352051, 5.030236),(52.324595, 5.019149),(52.304151, 5.024817),\n",
    "                            (52.277836, 4.960200),(52.307825, 4.925153),(52.318055, 4.910773),(52.323740, 4.820309),\n",
    "                            (52.339239, 4.789761),(52.357192, 4.752847),(52.387835, 4.753389),(52.399444, 4.729131),(52.430091, 4.737165)]\n",
    "    elif city_name=='Rotterdam':\n",
    "        city_coordinates = [(51.964720, 4.379695), (51.979081, 4.427803), (51.982006, 4.467663), \n",
    "                            (51.963745, 4.515691),(51.975121, 4.546658),(51.986527, 4.558397),(51.995767, 4.594196),\n",
    "                            (51.968611, 4.599813),(51.955476, 4.566894),(51.943379, 4.576685),(52.397841, 5.031621),\n",
    "                            (51.905291, 4.577125),(51.868921, 4.570220),(51.868888, 4.396928),(51.964029, 4.377486)]\n",
    "        \n",
    "    elif city_name ==\"Zwolle\":\n",
    "        city_coordinates = [(52.549349, 6.004091), (52.568947, 6.063982), (52.554697, 6.089382), (52.568898, 6.101135),\n",
    "                         (52.555875, 6.138225),(52.566288, 6.160296),(52.585973, 6.144575),(52.569103, 6.212615),\n",
    "                         (52.537363, 6.193830),(52.517736, 6.181333),(52.495107, 6.202496),(52.480071, 6.194845),\n",
    "                         (52.467620, 6.150828),(52.447958, 6.155530),(52.440524, 6.103350),(52.508357, 6.024621),\n",
    "                         (52.526347, 6.010919),(52.531352, 6.026051),(52.550606, 5.999967)]\n",
    "        \n",
    "    return city_name,city_coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Select a city to explore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name,city_coords=select_city_to_explore('Amsterdam')\n",
    "# city_name,city_coords=select_city_to_explore('Rotterdam')\n",
    "# city_name,city_coords=select_city_to_explore('Zwolle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note - if files are already saved skip part I and load files directly (Part-II)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part I- Creating files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trip Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "dir_name=r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\TripDetail\"\n",
    "base_filename=city_name\n",
    "\n",
    "path=os.path.join(dir_name, base_filename)\n",
    "# print(path)\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "df_inter_city_trip_detail = pd.concat((pd.read_csv(f,usecols=[\"Numberplate\",\"Latitude\",\"Longitude\",\"Point_speed\",\"Meters_travelled\"]) for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polygon Filtering\n",
    "\n",
    "- Part I : Remove datapoints that have been recorded outside the NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_data_points_outside_nl(df):\n",
    "    # Create a polygon (around nl, some parts of belgium and germany)\n",
    "    coords_nl_belgium_de = [(51.319810, 3.199518), (51.141676, 4.044834), (51.151092, 4.433142), (51.160870, 4.911878),\n",
    "                            (51.119796, 5.379190),(50.916492, 5.347477),(50.732720, 5.558885),(50.646984, 5.868460),\n",
    "                            (50.682498, 6.225990),(50.774220, 6.788565),(51.090741, 6.993645),(51.366330, 7.097475),\n",
    "                            (51.706392, 7.281298),(52.086558, 7.481535),(52.401805, 7.644418),(52.863343, 7.731970),\n",
    "                            (53.276982, 7.739262),(53.781184, 7.597500),(53.531285, 5.602048),(53.350568, 4.873847),\n",
    "                            (53.126881, 4.628008),(52.855526, 4.454778),(52.527262, 4.287084),(52.171565, 4.004032),\n",
    "                            (51.879936, 3.720315),(51.601678, 3.373136),(51.388379, 3.063189)]\n",
    "    poly_nl_belgium_de = Polygon(coords_nl_belgium_de)\n",
    "    \n",
    "    # initialize list of lists\n",
    "    df_poly_nl_belgium_de = pd.DataFrame(coords_nl_belgium_de, columns=['Lat', 'Lon'])\n",
    "    \n",
    "    polygon = Polygon([tuple(x) for x in df_poly_nl_belgium_de[['Lat', 'Lon']].to_numpy()])\n",
    "    \n",
    "    # Check values that are within the NL\n",
    "    df['Within_NL'] = df.apply(lambda x: polygon.contains(Point(x['Latitude'], x['Longitude'])), axis=1)\n",
    "    ## Drop values outide the NL\n",
    "    df = df.drop(df[df['Within_NL']==False].index)\n",
    "    return df\n",
    "    \n",
    "df_inter_city_trip_detail=remove_data_points_outside_nl(df_inter_city_trip_detail)\n",
    "# df.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\TripDetail\\Eindhoven\\eindhoven_not_complete_td1.csv\") Save this file to your local directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Part II : Remove datapoints of the city you're exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_city_datapoints(city_coords,df,name_column):\n",
    "    poly_city = Polygon(city_coords)\n",
    "    df_poly_city = pd.DataFrame(city_coords, columns=['Lat', 'Lon'])\n",
    "    polygon = Polygon([tuple(x) for x in df_poly_city[['Lat', 'Lon']].to_numpy()])\n",
    "    df['name_column'] = df.apply(lambda x: polygon.contains(Point(x['Latitude'], x['Longitude'])), axis=1)\n",
    "    df = df.drop(df[df['name_column']==True].index)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_inter_city_trip_detail=remove_city_datapoints(city_coords,df_inter_city_trip_detail,'Within_'+city_name)\n",
    "# df_inter_city_trip_detail.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\TripDetail\\Amsterdam\\amsterdam_not_complete_td_without_ams.csv\") # save this file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inter_city_trip_detail=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\AOS summary\\Zwolle\\aos_summary_zwolle3.csv\",usecols=['Admin_area'])\n",
    "df_inter_city_trip_detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot datapoints on a dynamic map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(ams_not_complete[0:50000],lat=\"Latitude\",lon=\"Longitude\",color=\"Numberplate\",title=\"Trips in and around the NL (Urban Roads)\")\n",
    "\n",
    "fig.update_layout(mapbox_style=\"open-street-map\",margin={\"r\":0.75,\"t\":25,\"l\":0,\"b\":0},title_x=0.5,title_y=0.985)\n",
    "# fig.update_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inter_city_trip_detail=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\TripDetail\\Rotterdam\\rotterdam_not_complete_td_without_rotterdam.csv\") # save this file locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calucalting mean point speed and total distance travelled by vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def km_trav(df):\n",
    "    df['Km_travelled']=df['Meters_travelled']/1000\n",
    "    return df\n",
    "\n",
    "def filtering_df(df):\n",
    "    df = df.drop(df[df['Point_speed']==0].index)\n",
    "    df = df.drop(df[df['Point_speed']>150].index)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def creating_grps(df):\n",
    "    \"\"\"This function will split df into two groups to calculate mean speed \n",
    "    and total distance travelled by each numberplate in Urban areas within that city\"\"\"\n",
    "    \n",
    "    df_groupby_mean = df.groupby(['Numberplate']).mean()\n",
    "    df_groupby_mean.reset_index(inplace=True)\n",
    "    \n",
    "    df_groupby_sum = df.groupby(['Numberplate']).sum()\n",
    "    df_groupby_sum.reset_index(inplace=True)\n",
    "    \n",
    "    return df_groupby_mean,df_groupby_sum\n",
    "\n",
    "def dropping_columns_mean(df):\n",
    "    df=df.drop(['Meters_travelled','Km_travelled'], axis = 1)\n",
    "    return df \n",
    "\n",
    "def dropping_columns_sum(df):\n",
    "    df=df.drop(['Latitude', 'Longitude', 'Point_speed', 'Within_NL', 'Meters_travelled',], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_mean,df_groupby_sum = (df_inter_city_trip_detail.pipe(km_trav).pipe(filtering_df).pipe(creating_grps))\n",
    "df_groupby_sum=dropping_columns_sum(df_groupby_sum)\n",
    "# df_groupby_mean\n",
    "df_groupby_mean=dropping_columns_mean(df_groupby_mean)\n",
    "\n",
    "\n",
    "def merge(df_groupby_sum,df_groupby_mean):\n",
    "    df = pd.merge(df_groupby_mean,df_groupby_sum, on='Numberplate', how='outer') #here Numberplate is common column\n",
    "    return df\n",
    "    \n",
    "df_city_grouped_trip_detail=merge(df_groupby_sum,df_groupby_mean)\n",
    "df_city_grouped_trip_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Only considering drivers over 50 kms and removing outliers with 2nd condition\n",
    "df_city_grouped_trip_detail=df_city_grouped_trip_detail[df_city_grouped_trip_detail['Km_travelled']>50]\n",
    "df_city_grouped_trip_detail = df_city_grouped_trip_detail.drop(df_city_grouped_trip_detail[df_city_grouped_trip_detail['Point_speed']<20].index)\n",
    "\n",
    "# df_city_grouped_trip_detail.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\TripDetail\\Zwolle\\processed_mean_sum_td_zwolle_not_without_zwolle.csv\") # save this file locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AOS Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "dir_name=r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\AOS summary\"\n",
    "base_filename=city_name\n",
    "\n",
    "path=os.path.join(dir_name, base_filename)\n",
    "# print(path)\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "df_inter_city_aos_summary = pd.concat((pd.read_csv(f,usecols=[\"Numberplate\",\"Latitude\",\"Longitude\",\"Event/action_type\"]) for f in all_files), ignore_index=True)\n",
    "df_inter_city_aos_summary=rename_some_stuff(df_inter_city_aos_summary)\n",
    "df_inter_city_aos_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def total_aos_event_count(df):\n",
    "    df=df.groupby(['Numberplate','Event type Rename']).size().unstack(fill_value=0)\n",
    "    df.reset_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "def merge_aos_events_trip_detail(total_aos_event_count,df_city_grouped_trip_detail):\n",
    "    df = pd.merge(df_city_grouped_trip_detail, total_aos_event_count, on='Numberplate', how='outer') #here id is common column\n",
    "    df = df.dropna(axis = 0, how = 'any')\n",
    "    return df\n",
    "\n",
    "def normalizing_events_count(df):\n",
    "    df['norm_Indicators = OFF']=df[' Indicators = OFF']/df['Km_travelled']\n",
    "    df['norm_brakes = OFF']=df['Brakes = OFF']/df['Km_travelled']\n",
    "    df['norm_brakes = ON']=df['Brakes = ON']/df['Km_travelled']\n",
    "    df['norm_headway_warning(long)']=df['Headway Warning (long)']/df['Km_travelled']\n",
    "    df['norm_headway_warning(medium)']=df['Headway Warning (medium)']/df['Km_travelled']\n",
    "    df['norm_headway_warning(short)']=df['Headway Warning (short)']/df['Km_travelled']\n",
    "    df['norm_Headway Warning = OFF']=df['Headway Warning = OFF']/df['Km_travelled']\n",
    "    df['norm_Lane Departure Warning = OFF']=df['Lane Departure Warning = OFF']/df['Km_travelled']\n",
    "    df['norm_Left Indicator = ON']=df['Left Indicator = ON']/df['Km_travelled']\n",
    "    df['norm_Left Lane Departure Warning = ON']=df['Left Lane Departure Warning = ON']/df['Km_travelled']\n",
    "    df['norm_Left and Right Indicator = ON']=df['Left and Right Indicator = ON']/df['Km_travelled']\n",
    "    df['norm_Right Indicator = ON']=df['Right Indicator = ON']/df['Km_travelled']\n",
    "    df['norm_Right Lane Departure Warning = ON']=df['Right Lane Departure Warning = ON']/df['Km_travelled']\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_total_aos_event_count=total_aos_event_count(df_inter_city_aos_summary)\n",
    "df_grp_aos_trip_detail_complete=merge_aos_events_trip_detail(df_total_aos_event_count,df_city_grouped_trip_detail)\n",
    "df_grp_aos_trip_detail_complete=normalizing_events_count(df_grp_aos_trip_detail_complete)\n",
    "df_grp_aos_trip_detail_complete['City'] = city_name+\"_complete\"\n",
    "# df_grp_aos_trip_detail_complete['City'] = city_name\n",
    "# df_grp_aos_trip_detail_complete.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Zwolle\\df_grp_aos_trip_detail_complete_zwolle_updated.csv\") #save file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp_aos_trip_detail_complete.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Amsterdam\\df_grp_aos_trip_detail_complete_amsterdam_updated2.csv\") #save file locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part II**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load the files and use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(city_name):\n",
    "    # city_name,_=select_city_to_explore('Amsterdam')\n",
    "    if city_name == 'Amsterdam':\n",
    "        df_intra_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Amsterdam\\df_grp_aos_trip_detail_amsterdam.csv\")\n",
    "        df_inter_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Amsterdam\\df_grp_aos_trip_detail_complete_amsterdam_updated2.csv\")\n",
    "        city_name='Amsterdam'\n",
    "        location=\"Amsterdam\"\n",
    "        location1=\"across the NL\"\n",
    "        \n",
    "    elif city_name=='Rotterdam':\n",
    "        df_intra_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Rotterdam\\df_grp_aos_trip_detail_rotterdam.csv\")\n",
    "        df_inter_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Rotterdam\\df_grp_aos_trip_detail_complete_rotterdam_updated2.csv\")\n",
    "        city_name='Rotterdam'\n",
    "        location=\"Rotterdam\"\n",
    "        location1=\"across the NL\"\n",
    "        \n",
    "    elif city_name=='Zwolle':\n",
    "        df_intra_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Zwolle\\df_grp_aos_trip_detail_zwolle.csv\")\n",
    "        df_inter_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Zwolle\\df_grp_aos_trip_detail_complete_zwolle_updated2.csv\")\n",
    "        city_name='Zwolle'\n",
    "        location=\"Zwolle\"\n",
    "        location1=\"across the NL\"\n",
    "        \n",
    "    return df_intra_city,df_inter_city,city_name,location,location1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intra_city,df_inter_city,city_name,location,location1=load_files(city_name) # This function should run automatically if you've called `select_city_to_explore` function before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_processing:\n",
    "    \n",
    "    def __init__(self,df_intra_city,df_inter_city):\n",
    "        self.df_intra_city = df_intra_city\n",
    "        self.df_inter_city = df_inter_city\n",
    "        \n",
    "    def rename_columns(self):\n",
    "        self.df_inter_city.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "        self.df_intra_city.drop(['Unnamed: 0','Overspeeding_event_sum_intra_city','norm_overspeeding'], axis = 1, inplace = True) \n",
    "    \n",
    "        self.df_intra_city.rename(columns={'Point_speed_mean_intra_city': 'Point_speed','KmTravelled_sum_intra_city': 'Km_travelled'},inplace=True, errors='raise')\n",
    "    \n",
    "        return df_intra_city,df_inter_city\n",
    "    \n",
    "    def concat_df(self):\n",
    "        # self.df_intra_city,self.df_inter_city=self.rename_columns()\n",
    "        df_grouped_cities=pd.concat([self.df_intra_city, self.df_inter_city])\n",
    "        return df_grouped_cities\n",
    "    \n",
    "    def filtering_df(self):\n",
    "        df_grouped_cities=self.concat_df()\n",
    "        df_grouped_cities = df_grouped_cities.drop(df_grouped_cities[df_grouped_cities['norm_brakes = ON']>4].index)\n",
    "        df_grouped_cities = df_grouped_cities.drop(df_grouped_cities[df_grouped_cities['norm_headway_warning(long)']>3].index)\n",
    "        df_grouped_cities = df_grouped_cities.drop(df_grouped_cities[df_grouped_cities['Point_speed']<20].index)\n",
    "        df_grouped_cities = df_grouped_cities.drop(df_grouped_cities[df_grouped_cities['Km_travelled']<50].index)\n",
    "        \n",
    "        return df_grouped_cities\n",
    "    \n",
    "    \n",
    "pre_processed_data = pre_processing(df_intra_city,df_inter_city)\n",
    "df_grouped_cities=pre_processed_data.filtering_df() \n",
    "# df_grouped_cities     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Select feature that you want to examine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature_to_examine(feature):\n",
    "    if feature==\"norm_headway_warning(long)\":\n",
    "        feature_name=\"Norm HW-L(I) \"\n",
    "    \n",
    "    elif feature=='norm_headway_warning(medium)':\n",
    "        feature_name=\"Norm HW-L(II) \"\n",
    "\n",
    "    elif feature=='norm_headway_warning(short)':\n",
    "        feature_name=\"Norm HW-L(III) \"\n",
    "        \n",
    "    elif feature=='Point_speed':\n",
    "        feature_name=\"Mean Point Speed \"\n",
    "        \n",
    "    elif feature=='norm_Left Lane Departure Warning = ON':\n",
    "        feature_name=\"Norm L-LDW \"\n",
    "        \n",
    "    elif feature=='norm_Right Lane Departure Warning = ON':\n",
    "        feature_name=\"Norm R-LDW \"\n",
    "        \n",
    "    elif feature=='norm_brakes = ON':\n",
    "        feature_name=\"Norm Braking Events \"\n",
    "        \n",
    "    return feature,feature_name\n",
    "\n",
    "\"\"\"Uncomment feature to be examined\"\"\"\n",
    "\n",
    "feature,feature_name=select_feature_to_examine('Point_speed')\n",
    "# feature,feature_name=select_feature_to_examine('norm_brakes = ON')\n",
    "# feature,feature_name=select_feature_to_examine('norm_headway_warning(long)')\n",
    "# feature,feature_name=select_feature_to_examine('norm_headway_warning(medium)')\n",
    "# feature,feature_name=select_feature_to_examine('norm_headway_warning(short)')\n",
    "# feature,feature_name=select_feature_to_examine('norm_Left Lane Departure Warning = ON')\n",
    "# feature,feature_name=select_feature_to_examine('norm_Right Lane Departure Warning = ON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    def __init__(self,feature,feature_name,df,increment,decrement):\n",
    "        self.feature = feature\n",
    "        self.feature_name = feature_name\n",
    "        self.df=df\n",
    "        self.increment =increment\n",
    "        self.decrement =decrement\n",
    "        \n",
    "    def preprocess(self,df):\n",
    "        \"\"\"Preprocess data for KMeans clustering\"\"\"\n",
    "    \n",
    "        data = np.array(self.df[self.feature])\n",
    "        data=data.reshape(-1, 1)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(data)\n",
    "        data = scaler.transform(data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def elbow_plot(self):\n",
    "        \"\"\"Create elbow plot from normalized data\"\"\"\n",
    "        data=self.preprocess(self.df)\n",
    "        sse = {}\n",
    "        \n",
    "        for k in range(2,11):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "            kmeans.fit(data)\n",
    "            sse[k] = kmeans.inertia_\n",
    "        \n",
    "        plt.title('Elbow plot for K selection'+\"\\n\"+feature_name+'-'+ city_name)\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('SSE')\n",
    "        sns.pointplot(x=list(sse.keys()),y=list(sse.values()),color=\"sandybrown\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def silhouette_coeff(self):\n",
    "        \"\"\"Checking silhouette score\"\"\"\n",
    "        data=self.preprocess(self.df)\n",
    "        range_n_clusters = range(2,10)\n",
    "        \n",
    "        for n_clusters in range_n_clusters:\n",
    "            clusterer = KMeans(n_clusters=n_clusters)\n",
    "            preds = clusterer.fit_predict(data)\n",
    "            centers = clusterer.cluster_centers_\n",
    "\n",
    "            score = silhouette_score(data, preds)\n",
    "            print(\"For n_clusters = {}, silhouette score is {})\".format(n_clusters, score))\n",
    "            \n",
    "            \n",
    "    def find_k(self):\n",
    "        \"\"\"Find the optimum k clusters\"\"\"\n",
    "        \n",
    "        data=self.preprocess(self.df)\n",
    "        sse = {}\n",
    "        \n",
    "        for k in range(2, 21):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "            kmeans.fit(data)\n",
    "            sse[k] = kmeans.inertia_\n",
    "        \n",
    "        kn = KneeLocator(x=list(sse.keys()), \n",
    "                    y=list(sse.values()), \n",
    "                    curve='convex', \n",
    "                    direction='decreasing')\n",
    "        k = kn.knee + self.increment - self.decrement\n",
    "        return k\n",
    "    \n",
    "    \n",
    "    def run_kmeans(self):\n",
    "        \"\"\"Run KMeans clustering, including the preprocessing of the data\n",
    "        and the automatic selection of the optimum k. \n",
    "        \"\"\"\n",
    "\n",
    "        data=self.preprocess(self.df)\n",
    "        k = self.find_k()\n",
    "        print(k)\n",
    "        kmeans = KMeans(n_clusters=k,init='k-means++')\n",
    "        x=kmeans.fit_predict(data)\n",
    "        return self.df.assign(Clusters=kmeans.labels_)\n",
    "    \n",
    "\n",
    "clustering_kmeans = Clustering(feature,feature_name,df_grouped_cities,increment=0, decrement=1) # increase or decrease number of assigned clusters using `increment` or `decrement`\n",
    "clustering_kmeans.elbow_plot() \n",
    "clustering_kmeans.silhouette_coeff()\n",
    "Clusters=clustering_kmeans.run_kmeans()\n",
    "# Clusters\n",
    "# df_grouped_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_classes():\n",
    "    sns.set_palette(\"CMRmap\")\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==0][feature],label=\"0\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==1][feature],label=\"1\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==2][feature],label=\"2\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==3][feature],label=\"3\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==4][feature],label=\"4\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==5][feature],label=\"5\",fill=True,alpha=0.5,linewidth=2)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    # plt.title(r\"Distribution of \"+feature_name+\" in \"+ city_name)\n",
    "    plt.title(r\"Distribution of \"+feature_name+\" in \"+ city_name + \"\\n\"+\" and the NL (Urban Roads) - Clusters\")\n",
    "    plt.xlabel(feature_name)\n",
    "    \n",
    "viz_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def processing_data_plots(df_clusters):\n",
    "    df_city=df_clusters.loc[df_clusters['City'] == city_name]\n",
    "    df_not_city=df_clusters.loc[df_clusters['City'] == city_name+\"_complete\"]\n",
    "    sns.set_context(\"notebook\")\n",
    "    sns.set_palette(\"CMRmap\")\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==0][feature],label=\"0\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==1][feature],label=\"1\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==2][feature],label=\"2\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==3][feature],label=\"3\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==4][feature],label=\"4\",fill=True,alpha=0.5,linewidth=2)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.title(r\"Distribution of \"+ feature_name+\"in \"+city_name,fontsize=15)\n",
    "    plt.xlabel(feature_name,fontsize=15)\n",
    "    plt.ylabel(\"Density\",fontsize=15)\n",
    "    plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\p3.png\")\n",
    "    \n",
    "    df_city.drop([' Indicators = OFF',\n",
    "       'Brakes = OFF', 'Brakes = ON', 'Headway Warning (long)',\n",
    "       'Headway Warning (medium)', 'Headway Warning (short)',\n",
    "       'Headway Warning = OFF', 'Lane Departure Warning = OFF',\n",
    "       'Left Indicator = ON', 'Left Lane Departure Warning = ON',\n",
    "       'Left and Right Indicator = ON', 'Right Indicator = ON',\n",
    "       'Right Lane Departure Warning = ON','norm_Indicators = OFF','norm_brakes = OFF','norm_Headway Warning = OFF','norm_Left Indicator = ON', 'norm_Left and Right Indicator = ON', 'norm_Right Indicator = ON'], axis = 1, inplace = True) \n",
    "    \n",
    "    \n",
    "    df_not_city.drop([' Indicators = OFF',\n",
    "       'Brakes = OFF', 'Brakes = ON', 'Headway Warning (long)',\n",
    "       'Headway Warning (medium)', 'Headway Warning (short)',\n",
    "       'Headway Warning = OFF', 'Lane Departure Warning = OFF',\n",
    "       'Left Indicator = ON', 'Left Lane Departure Warning = ON',\n",
    "       'Left and Right Indicator = ON', 'Right Indicator = ON',\n",
    "       'Right Lane Departure Warning = ON','norm_Indicators = OFF','norm_brakes = OFF','norm_Headway Warning = OFF','norm_Left Indicator = ON', 'norm_Left and Right Indicator = ON', 'norm_Right Indicator = ON'], axis = 1, inplace = True) \n",
    "    \n",
    "    df_city.reset_index(drop=True)\n",
    "    df_city['Numberplate'] = df_city['Numberplate'].astype(str)\n",
    "    df_city['City'] = df_city['City'].astype(str)\n",
    "    df_not_city['Numberplate'] = df_not_city['Numberplate'].astype(str)\n",
    "    df_not_city['City'] = df_not_city['City'].astype(str)\n",
    "    \n",
    "    return df_city,df_not_city\n",
    "\n",
    "    \n",
    "df_city,df_not_city=processing_data_plots(Clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "sns.set_context(\"notebook\")\n",
    "ax = sns.boxplot(x=df_city['Clusters'],y=df_city[feature],fliersize=5)\n",
    "for patch in ax.patches:\n",
    "    r, g, b, a = patch.get_facecolor()\n",
    "    patch.set_facecolor((r, g, b, .82))\n",
    "    \n",
    "\n",
    "plt.ylabel(feature_name+\" - \"+ city_name,fontsize=15)\n",
    "# plt.ylabel(feature_name)\n",
    "plt.xlabel(\"Cluster\",fontsize=15)\n",
    "# plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\p1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city_cluster0=df_city[df_city['Clusters']==0]\n",
    "df_city_cluster0_nums=list(df_city_cluster0['Numberplate'])\n",
    "\n",
    "df_city_cluster1=df_city[df_city['Clusters']==1]\n",
    "df_city_cluster1_nums=list(df_city_cluster1['Numberplate'])\n",
    "\n",
    "df_city_cluster2=df_city[df_city['Clusters']==2]\n",
    "df_city_cluster2_nums=list(df_city_cluster2['Numberplate'])\n",
    "\n",
    "df_city_cluster3=df_city[df_city['Clusters']==3]\n",
    "df_city_cluster3_nums=list(df_city_cluster3['Numberplate'])\n",
    "\n",
    "df_city_cluster4=df_city[df_city['Clusters']==4]\n",
    "df_city_cluster4_nums=list(df_city_cluster4['Numberplate'])\n",
    "\n",
    "df_city_cluster5=df_city[df_city['Clusters']==5]\n",
    "df_city_cluster5_nums=list(df_city_cluster5['Numberplate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city_cluster0[feature].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "sns.set_context(\"notebook\")\n",
    "ax = sns.boxplot(x=df_not_city['Clusters'],y=df_not_city[feature],fliersize=5)\n",
    "for patch in ax.patches:\n",
    "    r, g, b, a = patch.get_facecolor()\n",
    "    patch.set_facecolor((r, g, b, .82))\n",
    "\n",
    "plt.ylabel(feature_name+\" - \"+ location1,fontsize=15)\n",
    "# plt.ylabel(feature_name)\n",
    "plt.xlabel(\"Cluster\",fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "df_not_city_cluster0_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster0_nums)]\n",
    "df_not_city_cluster0_nums['Cluster_city']=0\n",
    "df_not_city_cluster1_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster1_nums)]\n",
    "df_not_city_cluster1_nums['Cluster_city']=1\n",
    "df_not_city_cluster2_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster2_nums)]\n",
    "df_not_city_cluster2_nums['Cluster_city']=2\n",
    "df_not_city_cluster3_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster3_nums)]\n",
    "df_not_city_cluster3_nums['Cluster_city']=3\n",
    "df_not_city_cluster4_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster4_nums)]\n",
    "df_not_city_cluster4_nums['Cluster_city']=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dataframes=[df_not_city_cluster0_nums,df_not_city_cluster1_nums,df_not_city_cluster2_nums,df_not_city_cluster3_nums]\n",
    "df_not_city_new_clus = pd.concat(list_of_dataframes)\n",
    "# df_not_city_new_clus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "sns.set_context(\"notebook\")\n",
    "ax = sns.boxplot(x=df_not_city_new_clus['Cluster_city'],y=df_not_city_new_clus[feature],fliersize=5)\n",
    "for patch in ax.patches:\n",
    "    r, g, b, a = patch.get_facecolor()\n",
    "    patch.set_facecolor((r, g, b, .82))\n",
    "    \n",
    "plt.ylabel(feature_name+\" across cities in the NL\",fontsize=15)\n",
    "plt.xlabel(\"Cluster\",fontsize=15)\n",
    "plt.title(feature_name+ \" of corresponding \"+\"\\n\"+r\"vehicles based on cluster assigned in \"+city_name,fontsize=15)\n",
    "# plt.ylim(-0.1,1.4)\n",
    "plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\p2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer = pd.merge(df_city, df_not_city_new_clus, on='Numberplate', how='inner') #here Numberplate is common column\n",
    "# df_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer.rename(columns={'Point_speed_x': 'Mean Point Speed in '+location,\n",
    "                         'Point_speed_y': 'Mean Point Speed '+location1,\n",
    "                         'norm_brakes = ON_x': 'Norm Braking Events in '+location,\n",
    "                         'norm_brakes = ON_y': 'Norm Braking Events '+location1,\n",
    "                         'norm_headway_warning(long)_x': 'Norm HW-L(I) in '+location,\n",
    "                         'norm_headway_warning(long)_y': 'Norm HW-L(I) '+location1,\n",
    "                         'norm_headway_warning(medium)_x': 'Norm HW-L(II) in '+location,\n",
    "                         'norm_headway_warning(medium)_y': 'Norm HW-L(II) '+location1,\n",
    "                         'norm_headway_warning(short)_x': 'Norm HW-L(III) in '+location,\n",
    "                         'norm_headway_warning(short)_y': 'Norm HW-L(III) '+location1,\n",
    "                         'norm_Right Lane Departure Warning = ON_x': 'Norm R-LDW in '+location,\n",
    "                         'norm_Right Lane Departure Warning = ON_y': 'Norm R-LDW '+location1,\n",
    "                         'norm_Left Lane Departure Warning = ON_x': 'Norm L-LDW in '+location,\n",
    "                         'norm_Left Lane Departure Warning = ON_y': 'Norm L-LDW '+location1\n",
    "                         },\n",
    "          inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x= feature_name+'in '\n",
    "feature_y=feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=df_outer,x=feature_x+location, y=feature_y+location1,color=\"sandybrown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\")\n",
    "sns.jointplot(x=feature_x+location, y=feature_y+location1, data=df_outer, kind=\"reg\",palette=\"pastel\",color=\"sandybrown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import pandas as pd \n",
    "#  import seaborn as sns\n",
    "#  import matplotlib.pyplot as plt \n",
    "# import stats\n",
    "import scipy\n",
    "from scipy import stats\n",
    "# sns.set(rc = {'figure.figsize':(15,8)})\n",
    "# from matplotlib import rcParams\n",
    "\n",
    "# # figure size in inches\n",
    "# rcParams['figure.figsize'] = 15,8\n",
    "# cornflowerblue\n",
    "# sandybrown\n",
    "# feature_x=\"Mean Point Speed in \"\n",
    "# feature_y=\"Mean Point Speed \"\n",
    "# sns.set_style(\"ticks\")\n",
    "# df = pd.read_excel('data.xlsx')\n",
    "# assume some random columns called EAV and PAV in your DataFrame \n",
    "# assume a third variable used for grouping called \"Mammal\" which will be used for color coding\n",
    "p = sns.lmplot(x=feature_x+location, y=feature_y+location1,\n",
    "        data=df_outer,scatter_kws={\"color\": \"mediumseagreen\"},\n",
    "        line_kws={'label':\"Linear Reg\",\"color\":\"mediumseagreen\"}, legend=True)\n",
    "\n",
    "ax = p.axes[0, 0]\n",
    "ax.legend()\n",
    "leg = ax.get_legend()\n",
    "L_labels = leg.get_texts()\n",
    "# assuming you computed r_squared which is the coefficient of determination somewhere else\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_outer[feature_x+location],df_outer[feature_y+location1])\n",
    "label_line_1 = r'$y={0:.1f}x+{1:.1f}'.format(slope,intercept)\n",
    "# label_line_2 = r'$r:{0:.2f}$'.format(r_value) # as an exampple or whatever you want[!\n",
    "# r_value=scipy.stats.spearmanr(df_outer[feature_x+location], df_outer[feature_y+location1])[0]\n",
    "label_line_2= r'$r:{0:.2f}$'.format(r_value)\n",
    "# L_labels[0].set_text(label_line_1)\n",
    "L_labels[0].set_text(label_line_2)\n",
    "plt.xlabel(feature_x+location,fontsize=15)\n",
    "plt.ylabel(feature_y+\"across cities in the NL\",fontsize=15)\n",
    "plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\p7.png\")\n",
    "# plt.title(\"Normalized Braking Events - Amsterdam & the NL (Urban Roads)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(df_outer[feature_x+location], df_outer[feature_y+location1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_city_number_of_points_td=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\TripDetail\\Amsterdam\\mean_point_speed_ams1.csv\",usecols=['Admin_area'])\n",
    "# df_city_number_of_points_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import os\n",
    "\n",
    "\n",
    "# dir_name=r\"D:\\AOS FOT\\Octo\\pickle_files\\Complete_data_Trip_detail\\Urban\"\n",
    "# base_filename=city_name\n",
    "\n",
    "# path=os.path.join(dir_name, base_filename)\n",
    "\n",
    "# all_files = glob.glob(os.path.join(path, \"*.pkl\"))\n",
    "# df_intra_city_trip_detail = pd.concat((pd.read_pickle(f) for f in all_files), ignore_index=True)\n",
    "# df_intra_city_trip_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer['cluster_comp'] = np.where(df_outer['Clusters_x']==df_outer['Clusters_y'], 'True', 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_outer[df_outer['cluster_comp']=='True']\n",
    "# a['clusters_utrecht'].value_counts()\n",
    "len(df_outer[df_outer['cluster_comp']=='True'])/len(df_outer)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Clusters_x'].value_counts()/len(a)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer['Clusters_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dataframes=[df_city,df_not_city_new_clus]\n",
    "df_boxplot_clus = pd.concat(list_of_dataframes)\n",
    "# df_boxplot_clus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"CMRmap\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.kdeplot(df_city[df_city['Clusters']==0][feature],label=\"0\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_city[df_city['Clusters']==1][feature],label=\"1\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_city[df_city['Clusters']==2][feature],label=\"2\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_city[df_city['Clusters']==3][feature],label=\"3\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_city[df_city['Clusters']==4][feature],label=\"4\",fill=True,alpha=0.5,linewidth=2)\n",
    "# sns.kdeplot(df_city[df_city['Clusters']==3]['Point_speed'],label=\"3\",fill=True,alpha=0.5,linewidth=2)\n",
    "# sns.kdeplot(df_city[df_city['Clusters']==4]['Point_speed'],label=\"4\",fill=True,alpha=0.5,linewidth=2)\n",
    "# sns.kdeplot(df_city[df_city['Clusters']==5]['Point_speed'],label=\"5\",fill=True,alpha=0.5,linewidth=2)\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.title(r\"Distribution of \"+feature_name+\" of vehicles in \"+city_name+\" - Clusters\")\n",
    "# plt.xlabel(\"Mean Point Speed (km/h)\")\n",
    "\n",
    "# plt.title(feature_name+\" in \"+ city_name +\"- Clusters\")\n",
    "plt.xlabel(feature_name+\"(km/h)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x= feature_name+'in '\n",
    "feature_y=feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"CMRmap\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.scatterplot(data=df_outer[df_outer['Cluster_city']==0],x=feature_x+location,y=feature_y+location1,alpha=0.8,label=0)\n",
    "sns.scatterplot(data=df_outer[df_outer['Cluster_city']==1],x=feature_x+location,y=feature_y+location1,alpha=0.8,label=1)\n",
    "sns.scatterplot(data=df_outer[df_outer['Cluster_city']==2],x=feature_x+location,y=feature_y+location1,alpha=0.8,label=2)\n",
    "sns.scatterplot(data=df_outer[df_outer['Cluster_city']==3],x=feature_x+location,y=feature_y+location1,alpha=0.8,label=3)\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.xlabel(feature_x+city_name,fontsize=15)\n",
    "plt.ylabel(feature_y+\" in cities across the NL\" +\"\\n\"+\"(urban roads)\",fontsize=15)\n",
    "plt.title(feature_y+\"of vehicles \"+\"\\n\"+\"and their corresponding clusters\",fontsize=15)\n",
    "plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\p4.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting KDE plots for different cities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp_td_aos_ams=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Amsterdam\\df_grp_aos_trip_detail_amsterdam.csv\")\n",
    "df_grp_td_aos_zwolle=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Zwolle\\df_grp_aos_trip_detail_zwolle.csv\")\n",
    "# df_grp_td_aos_ein=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Eindhoven\\df_grp_aos_trip_detail_eindhoven.csv\")\n",
    "df_grp_td_aos_rotte=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Rotterdam\\df_grp_aos_trip_detail_rotterdam.csv\")\n",
    "# df_grp_td_aos_utrecht=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Utrecht\\df_grp_aos_trip_detail_utrecht.csv\")\n",
    "# df_grp_td_aos_zwolle=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Zwolle\\df_grp_aos_trip_detail_zwolle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "list_of_dataframes=[df_grp_td_aos_ams,df_grp_td_aos_rotte,df_grp_td_aos_zwolle]\n",
    "df = pd.concat(list_of_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([' Indicators = OFF', 'Brakes = OFF', 'Brakes = ON',\n",
    "       'Headway Warning (long)', 'Headway Warning (medium)',\n",
    "       'Headway Warning (short)', 'Headway Warning = OFF',\n",
    "       'Lane Departure Warning = OFF', 'Left Indicator = ON',\n",
    "       'Left Lane Departure Warning = ON', 'Left and Right Indicator = ON',\n",
    "       'Right Indicator = ON', 'Right Lane Departure Warning = ON',\n",
    "       'norm_Indicators = OFF', 'norm_brakes = OFF','norm_Headway Warning = OFF',\n",
    "       'norm_Lane Departure Warning = OFF', 'norm_Left Indicator = ON','norm_Right Indicator = ON'], axis = 1, inplace = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Point_speed':'Mean Point Speed (km/h)',\n",
    "                   'Km_travelled':'Distance Covered (km)',\n",
    "                   'norm_brakes = ON':'Normalized Braking Events',\n",
    "                   'norm_headway_warning(long)': 'Normalized Level I-HW',\n",
    "                   'norm_headway_warning(medium)': 'Normalized Level II-HW',\n",
    "                   'norm_headway_warning(short)': 'Normalized Level III-HW',\n",
    "                   'norm_Right Lane Departure Warning = ON': 'Normalized R-LDW',\n",
    "                   'norm_Left Lane Departure Warning = ON': 'Normalized L-LDW'},\n",
    "          inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['Normalized Braking Events']>4].index)\n",
    "df = df.drop(df[df['Normalized Level I-HW']>3].index)\n",
    "# df = df.drop(df[df.score < 50].index)\n",
    "# df = df.drop(df[df.score < 50].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Numberplate Count']=1\n",
    "df_sum=df.groupby(['City']).sum(\"Numberplate\")\n",
    "df_sum.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(20, 10))\n",
    "# sns.set_context(\"notebook\")\n",
    "fig.suptitle('Distribution of Fetaures - Different Cities (Urban Roads)',fontsize=16)\n",
    "# sns.set_context(\"notebook\", font_scale=1.25)\n",
    "sns.barplot(ax=axes[0,0],data=df_sum,y=\"Numberplate Count\",x=\"City\",palette=\"pastel\")\n",
    "axes[0,0].set_xlabel('City',fontsize=15)\n",
    "axes[0,0].set_ylabel('Number Plate Count',fontsize=13)\n",
    "sns.kdeplot(ax=axes[0, 1], data=df, x='Distance Covered (km)',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[0,1].set_ylabel('Density',fontsize=13)\n",
    "axes[0,1].set_xlabel('Distance Covered (km)',fontsize=13)\n",
    "sns.kdeplot(ax=axes[0, 2], data=df, x='Mean Point Speed (km/h)',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[0,2].set_ylabel('Density',fontsize=13)\n",
    "axes[0,2].set_xlabel('Mean Point Speed (km/h)',fontsize=13)\n",
    "sns.kdeplot(ax=axes[1, 0], data=df, x='Normalized Braking Events',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[1,0].set_ylabel('Density',fontsize=13)\n",
    "axes[1,0].set_xlabel('Normalized Braking Events',fontsize=13)\n",
    "sns.kdeplot(ax=axes[1, 1], data=df, x='Normalized Level I-HW',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[1,1].set_ylabel('Density',fontsize=13)\n",
    "axes[1,1].set_xlabel('Normalized Level I-HW',fontsize=13)\n",
    "sns.kdeplot(ax=axes[1, 2], data=df, x='Normalized Level II-HW',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[1,2].set_ylabel('Density',fontsize=13)\n",
    "axes[1,2].set_xlabel('Normalized Level II-HW',fontsize=13)\n",
    "sns.kdeplot(ax=axes[2, 0], data=df, x='Normalized Level III-HW',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[2,0].set_ylabel('Density',fontsize=13)\n",
    "axes[2,0].set_xlabel('Normalized Level III-HW',fontsize=13)\n",
    "sns.kdeplot(ax=axes[2, 1], data=df, x='Normalized R-LDW',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[2,1].set_ylabel('Density',fontsize=13)\n",
    "axes[2,1].set_xlabel('Normalized R-LDW',fontsize=13)\n",
    "sns.kdeplot(ax=axes[2,2], data=df, x='Normalized L-LDW',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[2,2].set_ylabel('Density',fontsize=13)\n",
    "axes[2,2].set_xlabel('Normalized L-LDW',fontsize=13)\n",
    "plt.subplots_adjust(wspace = 0.3, hspace = 0.3) #make the figure look better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(30, 10))\n",
    "# sns.set_context(\"notebook\")\n",
    "fig.suptitle('Distribution of Fetaures - Different Cities (Urban Roads)',fontsize=16)\n",
    "# sns.set_context(\"notebook\", font_scale=1.25)\n",
    "# sns.barplot(ax=axes[0,0],data=df_sum,y=\"Numberplate Count\",x=\"City\",palette=\"pastel\")\n",
    "# axes[0,0].set_xlabel('City',fontsize=11, fontdict=dict(weight='bold'))\n",
    "axes[0,0].set_ylabel('Number Plate Count',fontsize=16)\n",
    "sns.kdeplot(ax=axes[0, 0], data=df, x='Distance Covered (km)',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[0,0].set_ylabel('Density',fontsize=14)\n",
    "axes[0,0].set_xlabel('Distance Covered (km)',fontsize=14)\n",
    "sns.kdeplot(ax=axes[0, 1], data=df, x='Mean Point Speed (km/h)',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[0,1].set_ylabel('Density',fontsize=14)\n",
    "axes[0,1].set_xlabel('Mean Point Speed (km/h)',fontsize=14)\n",
    "sns.kdeplot(ax=axes[0, 2], data=df, x='Normalized Braking Events',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[0,2].set_ylabel('Density',fontsize=14)\n",
    "axes[0,2].set_xlabel('Normalized Braking Events',fontsize=14)\n",
    "sns.kdeplot(ax=axes[0, 3], data=df, x='Normalized Level I-HW',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[0, 3].set_ylabel('Density',fontsize=14)\n",
    "axes[0, 3].set_xlabel('Normalized Level I-HW',fontsize=14)\n",
    "sns.kdeplot(ax=axes[1, 0], data=df, x='Normalized Level II-HW',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[1,0].set_ylabel('Density',fontsize=14)\n",
    "axes[1,0].set_xlabel('Normalized Level II-HW',fontsize=14)\n",
    "sns.kdeplot(ax=axes[1,1], data=df, x='Normalized Level III-HW',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[1,1].set_ylabel('Density',fontsize=14)\n",
    "axes[1,1].set_xlabel('Normalized Level III-HW',fontsize=14)\n",
    "sns.kdeplot(ax=axes[1, 2], data=df, x='Normalized R-LDW',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[1,2].set_ylabel('Density',fontsize=14)\n",
    "axes[1,2].set_xlabel('Normalized R-LDW',fontsize=14)\n",
    "sns.kdeplot(ax=axes[1,3], data=df, x='Normalized L-LDW',linewidth=2.5,hue=\"City\",palette=\"pastel\")\n",
    "axes[1,3].set_ylabel('Density',fontsize=14)\n",
    "axes[1,3].set_xlabel('Normalized L-LDW',fontsize=14)\n",
    "plt.subplots_adjust(wspace = 0.3, hspace = 0.3) #make the figure look better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2cfa282833ad131b813daadc2d579e64b9e3379708ebc6d12c1926855f4c941"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Motorway Clustering**\n",
    "\n",
    "This is the shorter version of `motorway_clustering.ipynb` file.\n",
    "\n",
    "In this we dive directly into clustering. \n",
    "\n",
    "This can be used after merged files of Trip Detail and AOS have already been created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import vaex # https://vaex.io/docs/index.html\n",
    "import pathlib\n",
    "from pathlib import *\n",
    "import os\n",
    "import pickle\n",
    "# import cufflinks as cf\n",
    "# import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,plot,iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO -> Create functions for repetitive tasks\n",
    "\n",
    "# ,skiprows=range(3, 260000000)\n",
    "# Input the csv\n",
    "# Extracting a subset of 1000000 rows by default\n",
    "def load_data(dir_name,base_filename):\n",
    "    complete_path=os.path.join(dir_name, base_filename + \".\" + \"csv\")\n",
    "    df=pd.read_csv(complete_path)\n",
    "#     df = pd.concat((chunk for chunk in pd.read_csv(complete_path,sep=';',nrows=5000000,encoding= 'unicode_escape',engine='c',infer_datetime_format=True,chunksize=1000000,low_memory=False,usecols=['Numberplate','Latitude',\n",
    "    #                                                                                                                           'Longitude','Meters_travelled','Time_elapsed','Point_speed','Number_of_lanes',\n",
    "    #                                                                                                                           'Road_type','Road_class','Speed_restriction','TNO_Time-stamp'])))\n",
    "    \n",
    "#     df = pd.concat((chunk for chunk in pd.read_csv(complete_path,sep=';',nrows=20000000,encoding= 'unicode_escape',engine='c',infer_datetime_format=True,chunksize=1000000,low_memory=False)))\n",
    "    return df\n",
    "\n",
    "# Dropping the first and last row of csv (\"------\")\n",
    "def drop_first_row(df):\n",
    "    df=df.iloc[1:]\n",
    "    df=df[:-1]\n",
    "    return df\n",
    "\n",
    "def resetIndex(df):\n",
    "    return df.reset_index()\n",
    "\n",
    "\n",
    "##TODO -> Rewrite this function\n",
    "\n",
    "def cast_to_correct_dtype(df):\n",
    "    \n",
    "    if 'Id' in df.columns:\n",
    "        df['Id'] = df['Id'].astype('int')\n",
    "        \n",
    "    if 'AOS_position_Id' in df.columns:\n",
    "        df['AOS_position_Id'] = df['AOS_position_Id'].astype('int')\n",
    "    \n",
    "    if 'Acceleration_x' in df.columns:\n",
    "        df['Acceleration_x'] = df['Acceleration_x'].astype('float')\n",
    "        \n",
    "    if 'Acceleration_y' in df.columns:\n",
    "        df['Acceleration_y'] = df['Acceleration_y'].astype('float')\n",
    "        \n",
    "    if 'TNO_Valid' in df.columns:\n",
    "        df['TNO_Valid'] = df['TNO_Valid'].astype('int')\n",
    "    \n",
    "    if 'Latitude' in df.columns:\n",
    "        df['Latitude'] = df['Latitude'].astype('float')\n",
    "        \n",
    "    if 'Longitude' in df.columns:\n",
    "        df['Longitude'] = df['Longitude'].astype('float')\n",
    "        \n",
    "    if 'Event/action_speed' in df.columns:\n",
    "        df['Event/action_speed'] = df['Event/action_speed'].astype('int')\n",
    "        \n",
    "    if 'Event/action_type' in df.columns:\n",
    "        df['Event/action_type'] = df['Event/action_type'].astype('int')    \n",
    "        \n",
    "    if 'Number_of_lanes' in df.columns:\n",
    "        df['Number_of_lanes'] = df['Number_of_lanes'].astype('int')\n",
    "        \n",
    "    if 'Road_class' in df.columns:\n",
    "        df['Road_class'] = df['Road_class'].astype('int')\n",
    "        \n",
    "    if 'Road_type' in df.columns:\n",
    "        df['Road_type'] = df['Road_type'].astype('int')\n",
    "        \n",
    "    if 'Crash_position_Id' in df.columns:\n",
    "        df['Crash_position_Id']=df['Crash_position_Id'].astype('int')\n",
    "        \n",
    "    if 'Crash_position_Id' in df.columns:\n",
    "        df['Crash_position_Id'] = df['Crash_position_Id'].astype('int')\n",
    "        \n",
    "    if 'Point_speed' in df.columns:\n",
    "        df['Point_speed'] = df['Point_speed'].astype('float')\n",
    "        \n",
    "    if 'Average_speed_fpp' in df.columns:\n",
    "        df['Average_speed_fpp'] = df['Average_speed_fpp'].astype('float')  \n",
    "        \n",
    "    if 'Average_Speed' in df.columns:\n",
    "        df['Average_Speed'] = df['Average_Speed'].astype('float')        \n",
    "\n",
    "    if 'Maximum_speed' in df.columns:\n",
    "        df['Maximum_speed'] = df['Maximum_speed'].astype('float')     \n",
    "        \n",
    "    if 'Meters_travelled' in df.columns:\n",
    "        df['Meters_travelled'] = df['Meters_travelled'].astype('int')  \n",
    "\n",
    "    if 'Road_form' in df.columns:\n",
    "        df['Road_form'] = df['Road_form'].astype('int') \n",
    "        \n",
    "    if 'Speed_restriction' in df.columns:\n",
    "        df['Speed_restriction'] = df['Speed_restriction'].astype('int') \n",
    "        \n",
    "    if 'Crash_speed' in df.columns:\n",
    "        df['Crash_speed'] = df['Crash_speed'].astype('int')\n",
    "        \n",
    "    if 'Maximum_acceleration' in df.columns:\n",
    "        df['Maximum_acceleration'] = df['Maximum_acceleration'].astype('float')\n",
    "        \n",
    "    if 'Numberplate' in df.columns:\n",
    "        df['Numberplate']=df['Numberplate'].astype('str')\n",
    "        \n",
    "\n",
    "    return df\n",
    "\n",
    "            \n",
    "\n",
    "## Handling date time related fields\n",
    "\n",
    "def cast_date_time(df):\n",
    "    if 'AOS_event/action_time' in df.columns:\n",
    "        df['AOS_event/action_time']=pd.datetime(df['AOS_event/action_time'],errors='coerce')\n",
    "        df['AOS_event/action_time_hour']=df['AOS_event/action_time'].dt.hour\n",
    "    \n",
    "    if 'TNO_Trip-start' in df.columns:\n",
    "        df['TNO_Trip-start'] = pd.to_datetime(df['TNO_Trip-start'],errors='coerce')\n",
    "        df['TNO_Trip-start_hour'] = df['TNO_Trip-start'].dt.hour\n",
    "        \n",
    "    if 'TNO_Trip-end' in df.columns:\n",
    "        df['TNO_Trip-end'] = pd.to_datetime(df['TNO_Trip-end'],errors='coerce')\n",
    "        \n",
    "    if 'Position_time' in df.columns:\n",
    "        df['Position_time'] = pd.to_datetime(df['Position_time'],errors='coerce')\n",
    "\n",
    "    if 'TNO_Time-stamp' in df.columns:\n",
    "        df['TNO_Time-stamp'] = pd.to_datetime(df['TNO_Time-stamp'],errors='coerce')\n",
    "        df['TNO_Time-stamp_hour'] = df['TNO_Time-stamp'].dt.hour\n",
    "        \n",
    "    return df\n",
    "\n",
    "## Converting Time Stamps to datetime\n",
    "\n",
    "def date_and_time_columns(df):\n",
    "    if 'AOS_event/action_time' in df.columns:\n",
    "        df['AOS Trip Date']=df['AOS_event/action_time'].dt.date\n",
    "        df['AOS Event Time']=df['AOS_event/action_time'].dt.time\n",
    "        df['AOS Trip Hour']=df['AOS_event/action_time'].dt.hour\n",
    "    \n",
    "    \n",
    "    if 'TNO_Time-stamp' in df.columns:\n",
    "        df['TNO Trip Date'] = df['TNO_Time-stamp'].dt.date\n",
    "        df['TNO Trip Time'] = df['TNO_Time-stamp'].dt.time\n",
    "        df['TNO Trip Hour']=df['TNO_Time-stamp'].dt.hour\n",
    "        # df['TNO Trip Hour'] = df['TNO Trip Time'].dt.hour\n",
    "    return df\n",
    "\n",
    "def Time_of_the_day(x):\n",
    "    if (x > 4) and (x <= 8):\n",
    "        return 'Early Morning'\n",
    "    elif (x > 8) and (x < 12 ):\n",
    "        return 'Morning'\n",
    "    elif (x >= 12) and (x <= 16):\n",
    "        return'Noon'\n",
    "    elif (x > 16) and (x <= 20) :\n",
    "        return 'Evening'\n",
    "    elif (x > 20) and (x <= 24):\n",
    "        return'Night'\n",
    "    elif (x <= 4):\n",
    "        return'Late Night'\n",
    "    \n",
    "    \n",
    "def rename_some_stuff(df):\n",
    "    if 'Event/action_type' in df.columns:\n",
    "        df[\"Event type Rename\"]=df[\"Event/action_type\"].replace({0: 'Headway Warning = OFF', 1: 'Headway Warning (long)', 2: 'Headway Warning (medium)'\n",
    "                                                                                 ,3: 'Headway Warning (short)',10:'Lane Departure Warning = OFF',11:'Left Lane Departure Warning = ON'\n",
    "                                                                                 ,12:'Right Lane Departure Warning = ON',13:'Left and Right Lane Departure Warning = ON'\n",
    "                                                                                 ,20:' Indicators = OFF',21:'Left Indicator = ON',22:'Right Indicator = ON',23:'Left and Right Indicator = ON'\n",
    "                                                                                 ,40:'Brakes = OFF',41:'Brakes = ON'})\n",
    "        \n",
    "    if 'Road_type' in df.columns:\n",
    "        df[\"Road_type_Rename\"]=df[\"Road_type\"].replace({0: \"Urban\", 1: \"Motorway\",2:\"Extra Urban\",3:\"Unavailable\"})\n",
    "        \n",
    "    return df\n",
    "\n",
    "def detect_overspeeding_count(df):\n",
    "    # create a list of our conditions\n",
    "#     if 'Event/action_speed' and 'Speed_restriction' in df.columns:\n",
    "#         conditions = [(df['Event/action_speed']> df['Speed_restriction'])]\n",
    "#         # # create a list of the values we want to assign for each condition\n",
    "#         values = [1]\n",
    "#         # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "#         df['Overspeeding_event'] = np.select(conditions, values)\n",
    "        \n",
    "    # return df\n",
    "\n",
    "    if 'Point_speed' and 'Speed_restriction' in df.columns:\n",
    "        conditions = [(df['Point_speed']> df['Speed_restriction'])]\n",
    "        # # create a list of the values we want to assign for each condition\n",
    "        values = [1]\n",
    "        # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "        df['Overspeeding_event'] = np.select(conditions, values)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def some_processing(df):\n",
    "    if 'Meters_travelled' in df.columns:\n",
    "        df['KmTravelled']=df['Meters_travelled']/1000\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select Motorway to Explore**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utrecht-Eindhoven Highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp_aos_trip_detail_ue_highway=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering Motorway\\df_grp_aos_trip_detail_utrecht_eindhoven_highway.csv\")\n",
    "df_grp_aos_trip_detail_ue_highway_complete=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering Motorway\\df_grp_aos_trip_detail_complete_utrecht_eindhoven_highway.csv\")\n",
    "# city_name='Amsterdam'\n",
    "location=\"Utrecht-Eindhoven Highway (M2)\"\n",
    "location1=\"across motorways in the NL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utrecht-Leek Highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_grp_aos_trip_detail_ul_highway=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering Motorway\\df_grp_aos_trip_detail_utrecht_leek_highway.csv\")\n",
    "# df_grp_aos_trip_detail_ul_highway_complete=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering Motorway\\df_grp_aos_trip_detail_complete_utrecht_leek_highway.csv\")\n",
    "# location=\"Utrecht-Leek Highway (M1)\"\n",
    "# location1=\"across motorways in the NL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Correlation Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature_to_examine(feature):\n",
    "    if feature==\"Normalized Level I-HW\":\n",
    "        feature_name=\"Norm HW-L(I) \"\n",
    "    \n",
    "    elif feature=='Normalized Level II-HW':\n",
    "        feature_name=\"Norm HW-L(II) \"\n",
    "\n",
    "    elif feature=='Normalized Level III-HW':\n",
    "        feature_name=\"Norm HW-L(III) \"\n",
    "        \n",
    "    elif feature=='Mean Point Speed (km/h)':\n",
    "        feature_name=\"Mean Point Speed \"\n",
    "        \n",
    "    elif feature=='Normalized L-LDW':\n",
    "        feature_name=\"Norm L-LDW \"\n",
    "        \n",
    "    elif feature=='Normalized R-LDW':\n",
    "        feature_name=\"Norm R-LDW \"\n",
    "        \n",
    "    elif feature=='Normalized Braking Events':\n",
    "        feature_name=\"Norm Braking Events \"\n",
    "        \n",
    "    return feature,feature_name\n",
    "\n",
    "\"\"\"Uncomment feature to be examined\"\"\"\n",
    "\n",
    "# feature,feature_name=select_feature_to_examine('Mean Point Speed (km/h)')\n",
    "# feature,feature_name=select_feature_to_examine('Normalized Braking Events')\n",
    "# feature,feature_name=select_feature_to_examine('Normalized Level I-HW')\n",
    "# feature,feature_name=select_feature_to_examine('Normalized Level II-HW')\n",
    "# feature,feature_name=select_feature_to_examine('Normalized Level III-HW')\n",
    "# feature,feature_name=select_feature_to_examine('Normalized L-LDW')\n",
    "feature,feature_name=select_feature_to_examine('Normalized R-LDW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(df1,df2):\n",
    "    df_outer = pd.merge(df1, df2, on='Numberplate', how='inner') #here Numberplate is common column\n",
    "    return df_outer\n",
    "\n",
    "df_outer=merge_dfs(df_grp_aos_trip_detail_ue_highway,df_grp_aos_trip_detail_ue_highway_complete)\n",
    "# df_outer=merge_dfs(df_grp_aos_trip_detail_ul_highway,df_grp_aos_trip_detail_ul_highway_complete)\n",
    "# df_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_data(df):\n",
    "    df = df.drop(df[df['Normalized Braking Events_x']>4].index)\n",
    "    df = df.drop(df[df['Normalized Level I-HW_x']>3].index)\n",
    "    df = df.drop(df[df['Normalized Braking Events_y']>4].index)\n",
    "    df = df.drop(df[df['Normalized Level I-HW_y']>3].index)\n",
    "    return df\n",
    "\n",
    "df_outer=drop_data(df_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer.rename(columns={'Mean Point Speed (km/h)_x': 'Mean Point Speed on '+location,\n",
    "                         'Mean Point Speed (km/h)_y': 'Mean Point Speed '+location1,\n",
    "                         'Normalized Braking Events_x': 'Norm Braking Events on '+location,\n",
    "                         'Normalized Braking Events_y': 'Norm Braking Events '+location1,\n",
    "                         'Normalized Level I-HW_x': 'Norm HW-L(I) on '+location,\n",
    "                         'Normalized Level I-HW_y': 'Norm HW-L(I) '+location1,\n",
    "                         'Normalized Level II-HW_x': 'Norm HW-L(II) on '+location,\n",
    "                         'Normalized Level II-HW_y': 'Norm HW-L(II) '+location1,\n",
    "                         'Normalized Level III-HW_x': 'Norm HW-L(III) on '+location,\n",
    "                         'Normalized Level III-HW_y': 'Norm HW-L(III) '+location1,\n",
    "                         'Normalized R-LDW_x': 'Norm R-LDW on '+location,\n",
    "                         'Normalized R-LDW_y': 'Norm R-LDW '+location1,\n",
    "                         'Normalized L-LDW_x': 'Norm L-LDW on '+location,\n",
    "                         'Normalized L-LDW_y': 'Norm L-LDW '+location1\n",
    "                         },\n",
    "          inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x= feature_name+'on '+location\n",
    "feature_y=feature_name+location1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=df_outer,x=feature_x, y=feature_y,color=\"sandybrown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=feature_x, y=feature_y, data=df_outer, kind=\"reg\",palette=\"pastel\",color=\"sandybrown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import pandas as pd \n",
    "#  import seaborn as sns\n",
    "#  import matplotlib.pyplot as plt \n",
    "# import stats\n",
    "from scipy import stats\n",
    "# sns.set(rc = {'figure.figsize':(15,8)})\n",
    "# from matplotlib import rcParams\n",
    "\n",
    "# # figure size in inches\n",
    "# rcParams['figure.figsize'] = 15,8\n",
    "\n",
    "\n",
    "# feature_x=\"Mean Point Speed in \"\n",
    "# feature_y=\"Mean Point Speed \"\n",
    "# sns.set_style(\"ticks\")\n",
    "# df = pd.read_excel('data.xlsx')\n",
    "# mediumseagreen\n",
    "# cornflowerblue\n",
    "sns.set_context(\"notebook\")\n",
    "p = sns.lmplot(x=feature_x, y=feature_y,\n",
    "        data=df_outer,scatter_kws={\"color\": \"mediumseagreen\"},\n",
    "        line_kws={'label':\"Linear Reg\",\"color\":\"mediumseagreen\"}, legend=True)\n",
    "\n",
    "ax = p.axes[0, 0]\n",
    "ax.legend()\n",
    "leg = ax.get_legend()\n",
    "L_labels = leg.get_texts()\n",
    "# assuming you computed r_squared which is the coefficient of determination somewhere else\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_outer[feature_x],df_outer[feature_y])\n",
    "label_line_1 = r'$y={0:.1f}x+{1:.1f}'.format(slope,intercept)\n",
    "label_line_2 = r'$r:{0:.2f}$'.format(r_value) # as an exampple or whatever you want[!\n",
    "# L_labels[0].set_text(label_line_1)\n",
    "L_labels[0].set_text(label_line_2)\n",
    "plt.xlabel(feature_x,fontsize=15)\n",
    "plt.ylabel(feature_y,fontsize=15)\n",
    "# plt.title(\"Normalized Braking Events - Amsterdam & the NL (Urban Roads)\")\n",
    "plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\p1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "scipy.stats.spearmanr(df_outer[feature_x], df_outer[feature_y])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grp_dfs_highway_highway_complete(df1,df2):\n",
    "    df1.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "    df2.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "    df_grouped_cities=pd.concat([df1, df2])\n",
    "    df_grouped_cities = df_grouped_cities.drop(df_grouped_cities[df_grouped_cities['Normalized Braking Events']>4].index)\n",
    "    df_grouped_cities = df_grouped_cities.drop(df_grouped_cities[df_grouped_cities['Normalized Level I-HW']>3].index)\n",
    "    \n",
    "    return df_grouped_cities\n",
    "\n",
    "df_grouped_cities=grp_dfs_highway_highway_complete(df_grp_aos_trip_detail_ue_highway,df_grp_aos_trip_detail_ue_highway_complete) #Utrecht-Eindhoven Highway\n",
    "# df_grouped_cities=grp_dfs_highway_highway_complete(df_grp_aos_trip_detail_ul_highway,df_grp_aos_trip_detail_ul_highway_complete) #Utrecht-Leek Highway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viz the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise data of lists.\n",
    "data = {'Motorway':['Utrecht to Eindhoven', 'Utrecht to Leek'],\n",
    "        'Vehicle Count':[112, 32]}\n",
    "  \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "  \n",
    "# Print the output.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\")\n",
    "fig, axes = plt.subplots(2, 4, figsize=(30, 10))\n",
    "# sns.set_context(\"notebook\")\n",
    "fig.suptitle('Distribution of Fetaures - on M1 and M2',fontsize=16)\n",
    "# sns.set_context(\"notebook\", font_scale=1.25)\n",
    "sns.barplot(ax=axes[0,0],data=df,y=\"Vehicle Count\",x=\"Motorway\",palette=\"Set2\")\n",
    "axes[0,0].set_xlabel('Motorway',fontsize=15)\n",
    "axes[0,0].set_ylabel('Vehicle Count',fontsize=15)\n",
    "\n",
    "sns.kdeplot(ax=axes[0,1],data=df_grouped_cities,x=\"Mean Point Speed (km/h)\",hue=\"Motorway\",palette=\"Set2\",linewidth=2.5)\n",
    "axes[0,1].set_xlabel('Density',fontsize=15)\n",
    "axes[0,1].set_xlabel('Mean Point Speed (km/h)',fontsize=15)\n",
    "\n",
    "sns.kdeplot(ax=axes[0, 2], data=df_grouped_cities, x=\"Normalized Braking Events\",linewidth=2.5,hue=\"Motorway\",palette=\"Set2\")\n",
    "axes[0,2].set_ylabel('Density',fontsize=15)\n",
    "axes[0,2].set_xlabel('Norm Braking Events',fontsize=15)\n",
    "\n",
    "sns.kdeplot(ax=axes[0, 3], data=df_grouped_cities, x='Normalized Level I-HW',linewidth=2.5,hue=\"Motorway\",palette=\"Set2\")\n",
    "axes[0,3].set_ylabel('Density',fontsize=15)\n",
    "axes[0,3].set_xlabel('Norm HW-L(I)',fontsize=15)\n",
    "\n",
    "sns.kdeplot(ax=axes[1, 0], data=df_grouped_cities, x='Normalized Level II-HW',linewidth=2.5,hue=\"Motorway\",palette=\"Set2\")\n",
    "axes[1,0].set_ylabel('Density',fontsize=15)\n",
    "axes[1,0].set_xlabel('Norm HW-L(II)',fontsize=15)\n",
    "\n",
    "sns.kdeplot(ax=axes[1, 1], data=df_grouped_cities, x='Normalized Level III-HW',linewidth=2.5,hue=\"Motorway\",palette=\"Set2\")\n",
    "axes[1,1].set_ylabel('Density',fontsize=15)\n",
    "axes[1,1].set_xlabel('Norm HW-L(III)',fontsize=15)\n",
    "\n",
    "sns.kdeplot(ax=axes[1,2], data=df_grouped_cities, x='Normalized R-LDW',linewidth=2.5,hue=\"Motorway\",palette=\"Set2\")\n",
    "axes[1,2].set_ylabel('Density',fontsize=15)\n",
    "axes[1,2].set_xlabel('Norm R-LDW',fontsize=15)\n",
    "\n",
    "sns.kdeplot(ax=axes[1,3], data=df_grouped_cities, x='Normalized L-LDW',linewidth=2.5,hue=\"Motorway\",palette=\"Set2\")\n",
    "axes[1,3].set_ylabel('Density',fontsize=15)\n",
    "axes[1,3].set_xlabel('Norm L-LDW',fontsize=15)\n",
    "plt.subplots_adjust(wspace = 0.3, hspace = 0.3) #make the figure look better\n",
    "# plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\figure.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Name of Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_name=\"Utrecht to Eindhoven\"\n",
    "city_name=\"Utrecht to Leek\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "class Clustering:\n",
    "    def __init__(self,feature,feature_name,df,increment,decrement):\n",
    "        self.feature = feature\n",
    "        self.feature_name = feature_name\n",
    "        self.df=df\n",
    "        self.increment =increment\n",
    "        self.decrement =decrement\n",
    "        \n",
    "    def preprocess(self,df):\n",
    "        \"\"\"Preprocess data for KMeans clustering\"\"\"\n",
    "    \n",
    "        data = np.array(self.df[self.feature])\n",
    "        data=data.reshape(-1, 1)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(data)\n",
    "        data = scaler.transform(data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def elbow_plot(self):\n",
    "        \"\"\"Create elbow plot from normalized data\"\"\"\n",
    "        data=self.preprocess(self.df)\n",
    "        sse = {}\n",
    "        \n",
    "        for k in range(2,11):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "            kmeans.fit(data)\n",
    "            sse[k] = kmeans.inertia_\n",
    "        \n",
    "        plt.title('Elbow plot for K selection'+\"\\n\"+feature_name+'-'+ city_name)\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('SSE')\n",
    "        sns.pointplot(x=list(sse.keys()),y=list(sse.values()),color=\"sandybrown\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def silhouette_coeff(self):\n",
    "        \"\"\"Checking silhouette score\"\"\"\n",
    "        data=self.preprocess(self.df)\n",
    "        range_n_clusters = range(2,10)\n",
    "        \n",
    "        for n_clusters in range_n_clusters:\n",
    "            clusterer = KMeans(n_clusters=n_clusters)\n",
    "            preds = clusterer.fit_predict(data)\n",
    "            centers = clusterer.cluster_centers_\n",
    "\n",
    "            score = silhouette_score(data, preds)\n",
    "            print(\"For n_clusters = {}, silhouette score is {})\".format(n_clusters, score))\n",
    "            \n",
    "            \n",
    "    def find_k(self):\n",
    "        \"\"\"Find the optimum k clusters\"\"\"\n",
    "        \n",
    "        data=self.preprocess(self.df)\n",
    "        sse = {}\n",
    "        \n",
    "        for k in range(2, 21):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "            kmeans.fit(data)\n",
    "            sse[k] = kmeans.inertia_\n",
    "        \n",
    "        kn = KneeLocator(x=list(sse.keys()), \n",
    "                    y=list(sse.values()), \n",
    "                    curve='convex', \n",
    "                    direction='decreasing')\n",
    "        k = kn.knee + self.increment - self.decrement\n",
    "        return k\n",
    "    \n",
    "    \n",
    "    def run_kmeans(self):\n",
    "        \"\"\"Run KMeans clustering, including the preprocessing of the data\n",
    "        and the automatic selection of the optimum k. \n",
    "        \"\"\"\n",
    "\n",
    "        data=self.preprocess(self.df)\n",
    "        k = self.find_k()\n",
    "        print(k)\n",
    "        kmeans = KMeans(n_clusters=k,init='k-means++')\n",
    "        x=kmeans.fit_predict(data)\n",
    "        return self.df.assign(Clusters=kmeans.labels_)\n",
    "    \n",
    "\n",
    "clustering_kmeans = Clustering(feature,feature_name,df_grouped_cities,increment=0, decrement=2) # increase or decrease number of assigned clusters using `increment` or `decrement`\n",
    "clustering_kmeans.elbow_plot() \n",
    "clustering_kmeans.silhouette_coeff()\n",
    "Clusters=clustering_kmeans.run_kmeans()\n",
    "Clusters\n",
    "# df_grouped_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_classes():\n",
    "    sns.set_palette(\"CMRmap\")\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==0][feature],label=\"0\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==1][feature],label=\"1\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==2][feature],label=\"2\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==3][feature],label=\"3\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==4][feature],label=\"4\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==5][feature],label=\"5\",fill=True,alpha=0.5,linewidth=2)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.title(r\"Distribution of \"+feature_name+\"on \"+ location+\"\\n\"+\"and \"+location1)\n",
    "    # plt.title(r\"Distribution of \"+feature_name+\" in \"+ city_name + \"\\n\"+\" and the NL (Urban Roads) - Clusters\")\n",
    "    plt.xlabel(feature_name)\n",
    "    \n",
    "viz_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_name=Clusters['Motorway'].unique()[0]\n",
    "corresponding_trips=Clusters['Motorway'].unique()[1]\n",
    "\n",
    "df_city=Clusters.loc[Clusters['Motorway']==highway_name]\n",
    "df_city = df_city.drop(df_city[df_city.Numberplate=='WPR23X'].index)\n",
    "df_not_city=Clusters.loc[Clusters['Motorway']==corresponding_trips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "sns.set_palette(\"CMRmap\")\n",
    "ax = sns.boxplot(x=df_city['Clusters'],y=df_city[feature],fliersize=5)\n",
    "for patch in ax.patches:\n",
    "    r, g, b, a = patch.get_facecolor()\n",
    "    patch.set_facecolor((r, g, b, .82))\n",
    "\n",
    "plt.ylabel(feature_name+\"\\n \"+ highway_name +\" - Highway\",fontsize=15)\n",
    "# plt.ylabel(feature_name)\n",
    "plt.xlabel(\"Cluster\",fontsize=15)\n",
    "# plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\p2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"CMRmap\")\n",
    "sns.kdeplot(df_city[df_city['Clusters']==0][feature],label=\"0\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_city[df_city['Clusters']==1][feature],label=\"1\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_city[df_city['Clusters']==2][feature],label=\"2\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_city[df_city['Clusters']==3][feature],label=\"3\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_city[df_city['Clusters']==4][feature],label=\"4\",fill=True,alpha=0.5,linewidth=2)\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.title(r\"Distribution of \"+ feature_name+\" of vehicles \"+\" on\"+\"\\n\"+highway_name +\" - Highway\",fontsize=15)\n",
    "plt.xlabel(feature_name,fontsize=15)\n",
    "plt.ylabel(\"Density\",fontsize=15)\n",
    "# plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\p5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"CMRmap\")\n",
    "sns.kdeplot(df_not_city[df_not_city['Clusters']==0][feature],label=\"0\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_not_city[df_not_city['Clusters']==1][feature],label=\"1\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_not_city[df_not_city['Clusters']==2][feature],label=\"2\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_not_city[df_not_city['Clusters']==3][feature],label=\"3\",fill=True,alpha=0.5,linewidth=2)\n",
    "sns.kdeplot(df_not_city[df_not_city['Clusters']==4][feature],label=\"4\",fill=True,alpha=0.5,linewidth=2)\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.title(\"Distribution of \"+ feature_name+\" of\"+\"\\n\"+\"correponding Numberplates across motorways in the NL \")\n",
    "plt.xlabel(\"Mean Point Speed (km/h)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city_cluster0=df_city[df_city['Clusters']==0]\n",
    "df_city_cluster0_nums=list(df_city_cluster0['Numberplate'])\n",
    "\n",
    "df_city_cluster1=df_city[df_city['Clusters']==1]\n",
    "df_city_cluster1_nums=list(df_city_cluster1['Numberplate'])\n",
    "\n",
    "df_city_cluster2=df_city[df_city['Clusters']==2]\n",
    "df_city_cluster2_nums=list(df_city_cluster2['Numberplate'])\n",
    "\n",
    "df_city_cluster3=df_city[df_city['Clusters']==3]\n",
    "df_city_cluster3_nums=list(df_city_cluster3['Numberplate'])\n",
    "\n",
    "df_city_cluster4=df_city[df_city['Clusters']==4]\n",
    "df_city_cluster4_nums=list(df_city_cluster4['Numberplate'])\n",
    "\n",
    "df_city_cluster5=df_city[df_city['Clusters']==5]\n",
    "df_city_cluster5_nums=list(df_city_cluster5['Numberplate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "df_not_city_cluster0_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster0_nums)]\n",
    "df_not_city_cluster0_nums['Cluster_city']=0\n",
    "df_not_city_cluster1_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster1_nums)]\n",
    "df_not_city_cluster1_nums['Cluster_city']=1\n",
    "df_not_city_cluster2_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster2_nums)]\n",
    "df_not_city_cluster2_nums['Cluster_city']=2\n",
    "df_not_city_cluster3_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster3_nums)]\n",
    "df_not_city_cluster3_nums['Cluster_city']=3\n",
    "df_not_city_cluster4_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster4_nums)]\n",
    "df_not_city_cluster4_nums['Cluster_city']=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dataframes=[df_not_city_cluster0_nums,df_not_city_cluster1_nums,df_not_city_cluster2_nums,df_not_city_cluster3_nums]\n",
    "df_not_city_new_clus = pd.concat(list_of_dataframes)\n",
    "df_not_city_new_clus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "ax = sns.boxplot(x=df_not_city_new_clus['Cluster_city'],y=df_not_city_new_clus[feature],fliersize=5)\n",
    "for patch in ax.patches:\n",
    "    r, g, b, a = patch.get_facecolor()\n",
    "    patch.set_facecolor((r, g, b, .82))\n",
    "    \n",
    "plt.ylabel(feature_name+\" across motorways in the NL\",fontsize=15)\n",
    "plt.xlabel(\"Cluster\",fontsize=15)\n",
    "plt.title(feature_name+ \" of corresponding vehicles \"+\"\\n\"+\"based on cluster assigned in \"+\"\\n\"+highway_name +\" - Highway\",fontsize=15)\n",
    "# plt.ylim(-0.1,1.4)\n",
    "# plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\p3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer = pd.merge(df_city, df_not_city, on='Numberplate', how='inner') #here Numberplate is common column\n",
    "df_outer['cluster_comp'] = np.where(df_outer['Clusters_x']==df_outer['Clusters_y'], 'True', 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_outer[df_outer['cluster_comp']=='True']\n",
    "# a['clusters_utrecht'].value_counts()\n",
    "len(df_outer[df_outer['cluster_comp']=='True'])/len(df_outer)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer_true=df_outer[df_outer['cluster_comp']==\"True\"]\n",
    "df_outer_true['Clusters_y'].value_counts()/len(df_outer_true)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=\"_x\"\n",
    "location1=\"_y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"CMRmap\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.scatterplot(data=df_outer[df_outer['Clusters_x']==0],x=feature+location,y=feature+location1,alpha=0.8,label=0)\n",
    "sns.scatterplot(data=df_outer[df_outer['Clusters_x']==1],x=feature+location,y=feature+location1,alpha=0.8,label=1)\n",
    "sns.scatterplot(data=df_outer[df_outer['Clusters_x']==2],x=feature+location,y=feature+location1,alpha=0.8,label=2)\n",
    "sns.scatterplot(data=df_outer[df_outer['Clusters_x']==3],x=feature+location,y=feature+location1,alpha=0.8,label=3)\n",
    "plt.legend(title=\"Cluster\")\n",
    "\n",
    "plt.xlabel(feature_name+\"- \"+highway_name,fontsize=15)\n",
    "plt.ylabel(feature_name+\" on motorways\"+\"\\n\"+\"across the Netherlands\",fontsize=15)\n",
    "plt.title(feature_name+ \"of vehicles \"+\"and their corresponding clusters\",fontsize=15)\n",
    "# plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\p4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2cfa282833ad131b813daadc2d579e64b9e3379708ebc6d12c1926855f4c941"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file analyses clusters of data to understand how it is affected by external criteria (mass, power and type of work).\n",
    "\n",
    "Vehicle characteristics were obtained by automatically querying the Dutch vehicle registration database : https://www.rdwdata.nl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import vaex # https://vaex.io/docs/index.html\n",
    "import pathlib\n",
    "from pathlib import *\n",
    "import os\n",
    "import pickle\n",
    "# import cufflinks as cf\n",
    "# import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,plot,iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO -> Create functions for repetitive tasks\n",
    "\n",
    "# ,skiprows=range(3, 260000000)\n",
    "# Input the csv\n",
    "# Extracting a subset of 1000000 rows by default\n",
    "def load_data(dir_name,base_filename):\n",
    "    complete_path=os.path.join(dir_name, base_filename + \".\" + \"csv\")\n",
    "    # df=pd.read_csv(complete_path,sep=';',encoding= 'unicode_escape',nrows=10000,engine='c',infer_datetime_format=True,usecols=['Trip_Summary_Id','Numberplate','Point_time-stamp','Latitude',\n",
    "    #                                                                                                                           'Longitude','Meters_travelled','Time_elapsed','Point_speed','Number_of_lanes',\n",
    "    #                                                                                                                           'Road_type','Road_class','Road_form','Speed_restriction','TNO_Time-stamp'])\n",
    "    # df = pd.concat((chunk for chunk in pd.read_csv(complete_path,sep=';',nrows=5000000,encoding= 'unicode_escape',engine='c',infer_datetime_format=True,chunksize=1000000,low_memory=False,usecols=['Numberplate','Latitude',\n",
    "    #                                                                                                                           'Longitude','Meters_travelled','Time_elapsed','Point_speed','Number_of_lanes',\n",
    "    #                                                                                                                           'Road_type','Road_class','Speed_restriction','TNO_Time-stamp'])))\n",
    "    \n",
    "    df = pd.concat((chunk for chunk in pd.read_csv(complete_path,sep=';',nrows=20000000,encoding= 'unicode_escape',engine='c',infer_datetime_format=True,chunksize=1000000,low_memory=False)))\n",
    "    return df\n",
    "\n",
    "# Dropping the first and last row of csv (\"------\")\n",
    "def drop_first_row(df):\n",
    "    df=df.iloc[1:]\n",
    "    df=df[:-1]\n",
    "    return df\n",
    "\n",
    "def resetIndex(df):\n",
    "    return df.reset_index()\n",
    "\n",
    "\n",
    "##TODO -> Rewrite this function\n",
    "\n",
    "def cast_to_correct_dtype(df):\n",
    "    \n",
    "    if 'Id' in df.columns:\n",
    "        df['Id'] = df['Id'].astype('int')\n",
    "        \n",
    "    if 'AOS_position_Id' in df.columns:\n",
    "        df['AOS_position_Id'] = df['AOS_position_Id'].astype('int')\n",
    "    \n",
    "    if 'Acceleration_x' in df.columns:\n",
    "        df['Acceleration_x'] = df['Acceleration_x'].astype('float')\n",
    "        \n",
    "    if 'Acceleration_y' in df.columns:\n",
    "        df['Acceleration_y'] = df['Acceleration_y'].astype('float')\n",
    "        \n",
    "    if 'TNO_Valid' in df.columns:\n",
    "        df['TNO_Valid'] = df['TNO_Valid'].astype('int')\n",
    "    \n",
    "    if 'Latitude' in df.columns:\n",
    "        df['Latitude'] = df['Latitude'].astype('float')\n",
    "        \n",
    "    if 'Longitude' in df.columns:\n",
    "        df['Longitude'] = df['Longitude'].astype('float')\n",
    "        \n",
    "    if 'Event/action_speed' in df.columns:\n",
    "        df['Event/action_speed'] = df['Event/action_speed'].astype('int')\n",
    "        \n",
    "    if 'Event/action_type' in df.columns:\n",
    "        df['Event/action_type'] = df['Event/action_type'].astype('int')    \n",
    "        \n",
    "    if 'Number_of_lanes' in df.columns:\n",
    "        df['Number_of_lanes'] = df['Number_of_lanes'].astype('int')\n",
    "        \n",
    "    if 'Road_class' in df.columns:\n",
    "        df['Road_class'] = df['Road_class'].astype('int')\n",
    "        \n",
    "    if 'Road_type' in df.columns:\n",
    "        df['Road_type'] = df['Road_type'].astype('int')\n",
    "        \n",
    "    if 'Crash_position_Id' in df.columns:\n",
    "        df['Crash_position_Id']=df['Crash_position_Id'].astype('int')\n",
    "        \n",
    "    if 'Crash_position_Id' in df.columns:\n",
    "        df['Crash_position_Id'] = df['Crash_position_Id'].astype('int')\n",
    "        \n",
    "    if 'Point_speed' in df.columns:\n",
    "        df['Point_speed'] = df['Point_speed'].astype('float')\n",
    "        \n",
    "    if 'Average_speed_fpp' in df.columns:\n",
    "        df['Average_speed_fpp'] = df['Average_speed_fpp'].astype('float')  \n",
    "        \n",
    "    if 'Average_Speed' in df.columns:\n",
    "        df['Average_Speed'] = df['Average_Speed'].astype('float')        \n",
    "\n",
    "    if 'Maximum_speed' in df.columns:\n",
    "        df['Maximum_speed'] = df['Maximum_speed'].astype('float')     \n",
    "        \n",
    "    if 'Meters_travelled' in df.columns:\n",
    "        df['Meters_travelled'] = df['Meters_travelled'].astype('int')  \n",
    "\n",
    "    if 'Road_form' in df.columns:\n",
    "        df['Road_form'] = df['Road_form'].astype('int') \n",
    "        \n",
    "    if 'Speed_restriction' in df.columns:\n",
    "        df['Speed_restriction'] = df['Speed_restriction'].astype('int') \n",
    "        \n",
    "    if 'Crash_speed' in df.columns:\n",
    "        df['Crash_speed'] = df['Crash_speed'].astype('int')\n",
    "        \n",
    "    if 'Maximum_acceleration' in df.columns:\n",
    "        df['Maximum_acceleration'] = df['Maximum_acceleration'].astype('float')\n",
    "        \n",
    "    if 'Numberplate' in df.columns:\n",
    "        df['Numberplate']=df['Numberplate'].astype('str')\n",
    "        \n",
    "\n",
    "    return df\n",
    "\n",
    "            \n",
    "\n",
    "## Handling date time related fields\n",
    "\n",
    "def cast_date_time(df):\n",
    "    if 'AOS_event/action_time' in df.columns:\n",
    "        df['AOS_event/action_time']=pd.datetime(df['AOS_event/action_time'],errors='coerce')\n",
    "        df['AOS_event/action_time_hour']=df['AOS_event/action_time'].dt.hour\n",
    "    \n",
    "    if 'TNO_Trip-start' in df.columns:\n",
    "        df['TNO_Trip-start'] = pd.to_datetime(df['TNO_Trip-start'],errors='coerce')\n",
    "        df['TNO_Trip-start_hour'] = df['TNO_Trip-start'].dt.hour\n",
    "        \n",
    "    if 'TNO_Trip-end' in df.columns:\n",
    "        df['TNO_Trip-end'] = pd.to_datetime(df['TNO_Trip-end'],errors='coerce')\n",
    "        \n",
    "    if 'Position_time' in df.columns:\n",
    "        df['Position_time'] = pd.to_datetime(df['Position_time'],errors='coerce')\n",
    "\n",
    "    if 'TNO_Time-stamp' in df.columns:\n",
    "        df['TNO_Time-stamp'] = pd.to_datetime(df['TNO_Time-stamp'],errors='coerce')\n",
    "        df['TNO_Time-stamp_hour'] = df['TNO_Time-stamp'].dt.hour\n",
    "        \n",
    "    return df\n",
    "\n",
    "## Converting Time Stamps to datetime\n",
    "\n",
    "def date_and_time_columns(df):\n",
    "    if 'AOS_event/action_time' in df.columns:\n",
    "        df['AOS Trip Date']=df['AOS_event/action_time'].dt.date\n",
    "        df['AOS Event Time']=df['AOS_event/action_time'].dt.time\n",
    "        df['AOS Trip Hour']=df['AOS_event/action_time'].dt.hour\n",
    "    \n",
    "    \n",
    "    if 'TNO_Time-stamp' in df.columns:\n",
    "        df['TNO Trip Date'] = df['TNO_Time-stamp'].dt.date\n",
    "        df['TNO Trip Time'] = df['TNO_Time-stamp'].dt.time\n",
    "        df['TNO Trip Hour']=df['TNO_Time-stamp'].dt.hour\n",
    "        # df['TNO Trip Hour'] = df['TNO Trip Time'].dt.hour\n",
    "    return df\n",
    "\n",
    "def Time_of_the_day(x):\n",
    "    if (x > 4) and (x <= 8):\n",
    "        return 'Early Morning'\n",
    "    elif (x > 8) and (x < 12 ):\n",
    "        return 'Morning'\n",
    "    elif (x >= 12) and (x <= 16):\n",
    "        return'Noon'\n",
    "    elif (x > 16) and (x <= 20) :\n",
    "        return 'Evening'\n",
    "    elif (x > 20) and (x <= 24):\n",
    "        return'Night'\n",
    "    elif (x <= 4):\n",
    "        return'Late Night'\n",
    "    \n",
    "    \n",
    "def rename_some_stuff(df):\n",
    "    if 'Event/action_type' in df.columns:\n",
    "        df[\"Event type Rename\"]=df[\"Event/action_type\"].replace({0: 'Headway Warning = OFF', 1: 'Headway Warning (long)', 2: 'Headway Warning (medium)'\n",
    "                                                                                 ,3: 'Headway Warning (short)',10:'Lane Departure Warning = OFF',11:'Left Lane Departure Warning = ON'\n",
    "                                                                                 ,12:'Right Lane Departure Warning = ON',13:'Left and Right Lane Departure Warning = ON'\n",
    "                                                                                 ,20:' Indicators = OFF',21:'Left Indicator = ON',22:'Right Indicator = ON',23:'Left and Right Indicator = ON'\n",
    "                                                                                 ,40:'Brakes = OFF',41:'Brakes = ON'})\n",
    "        \n",
    "    if 'Road_type' in df.columns:\n",
    "        df[\"Road_type_Rename\"]=df[\"Road_type\"].replace({0: \"Urban\", 1: \"Motorway\",2:\"Extra Urban\",3:\"Unavailable\"})\n",
    "        \n",
    "    return df\n",
    "\n",
    "def detect_overspeeding_count(df):\n",
    "    # create a list of our conditions\n",
    "    # if 'Event/action_speed' and 'Speed_restriction' in df.columns:\n",
    "    #     conditions = [(df['Event/action_speed']> df['Speed_restriction'])]\n",
    "    #     # # create a list of the values we want to assign for each condition\n",
    "    #     values = [1]\n",
    "    #     # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    #     df['Overspeeding_event'] = np.select(conditions, values)\n",
    "        \n",
    "    # return df\n",
    "\n",
    "    if 'Point_speed' and 'Speed_restriction' in df.columns:\n",
    "        conditions = [(df['Point_speed']> df['Speed_restriction'])]\n",
    "        # # create a list of the values we want to assign for each condition\n",
    "        values = [1]\n",
    "        # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "        df['Overspeeding_event'] = np.select(conditions, values)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def some_processing(df):\n",
    "    if 'Meters_travelled' in df.columns:\n",
    "        df['KmTravelled']=df['Meters_travelled']/1000\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_city_to_explore(city_name):\n",
    "    if city_name=='Amsterdam':\n",
    "        city_coordinates = [(52.430779, 4.737382), (52.422361, 4.811680), (52.418126, 4.850948), \n",
    "                            (52.431506, 4.859627),(52.421959, 4.913905),(52.414543, 4.933522),(52.425437, 4.954927),\n",
    "                            (52.428570, 4.982090),(52.423581, 5.017310),(52.417493, 5.067539),(52.397841, 5.031621),\n",
    "                            (52.373215, 5.014760),(52.352051, 5.030236),(52.324595, 5.019149),(52.304151, 5.024817),\n",
    "                            (52.277836, 4.960200),(52.307825, 4.925153),(52.318055, 4.910773),(52.323740, 4.820309),\n",
    "                            (52.339239, 4.789761),(52.357192, 4.752847),(52.387835, 4.753389),(52.399444, 4.729131),(52.430091, 4.737165)]\n",
    "    elif city_name=='Rotterdam':\n",
    "        city_coordinates = [(51.964720, 4.379695), (51.979081, 4.427803), (51.982006, 4.467663), \n",
    "                            (51.963745, 4.515691),(51.975121, 4.546658),(51.986527, 4.558397),(51.995767, 4.594196),\n",
    "                            (51.968611, 4.599813),(51.955476, 4.566894),(51.943379, 4.576685),(52.397841, 5.031621),\n",
    "                            (51.905291, 4.577125),(51.868921, 4.570220),(51.868888, 4.396928),(51.964029, 4.377486)]\n",
    "        \n",
    "    elif city_name ==\"Zwolle\":\n",
    "        city_coordinates = [(52.549349, 6.004091), (52.568947, 6.063982), (52.554697, 6.089382), (52.568898, 6.101135),\n",
    "                         (52.555875, 6.138225),(52.566288, 6.160296),(52.585973, 6.144575),(52.569103, 6.212615),\n",
    "                         (52.537363, 6.193830),(52.517736, 6.181333),(52.495107, 6.202496),(52.480071, 6.194845),\n",
    "                         (52.467620, 6.150828),(52.447958, 6.155530),(52.440524, 6.103350),(52.508357, 6.024621),\n",
    "                         (52.526347, 6.010919),(52.531352, 6.026051),(52.550606, 5.999967)]\n",
    "        \n",
    "    return city_name,city_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name,city_coords=select_city_to_explore('Amsterdam')\n",
    "# city_name,city_coords=select_city_to_explore('Rotterdam')\n",
    "# city_name,city_coords=select_city_to_explore('Zwolle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(city_name):\n",
    "    # city_name,_=select_city_to_explore('Amsterdam')\n",
    "    if city_name == 'Amsterdam':\n",
    "        df_intra_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Amsterdam\\df_grp_aos_trip_detail_amsterdam.csv\")\n",
    "        df_inter_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Amsterdam\\df_grp_aos_trip_detail_complete_amsterdam_updated2.csv\")\n",
    "        city_name='Amsterdam'\n",
    "        location=\"Amsterdam\"\n",
    "        location1=\"across cities the NL\"\n",
    "        \n",
    "    elif city_name=='Rotterdam':\n",
    "        df_intra_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Rotterdam\\df_grp_aos_trip_detail_rotterdam.csv\")\n",
    "        df_inter_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Rotterdam\\df_grp_aos_trip_detail_complete_rotterdam_updated2.csv\")\n",
    "        city_name='Rotterdam'\n",
    "        location=\"Rotterdam\"\n",
    "        location1=\"across cities the NL\"\n",
    "        \n",
    "    elif city_name=='Zwolle':\n",
    "        df_intra_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Zwolle\\df_grp_aos_trip_detail_zwolle.csv\")\n",
    "        df_inter_city=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering\\Summary\\Zwolle\\df_grp_aos_trip_detail_complete_zwolle_updated2.csv\")\n",
    "        city_name='Zwolle'\n",
    "        location=\"Zwolle\"\n",
    "        location1=\"across cities the NL\"\n",
    "        \n",
    "    return df_intra_city,df_inter_city,city_name,location,location1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intra_city,df_inter_city,city_name,location,location1=load_files(city_name) # This function should run automatically if you've called `select_city_to_explore` function before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_processing:\n",
    "    \n",
    "    def __init__(self,df_intra_city,df_inter_city):\n",
    "        self.df_intra_city = df_intra_city\n",
    "        self.df_inter_city = df_inter_city\n",
    "        \n",
    "    def rename_columns(self):\n",
    "        # self.df_inter_city.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "        # self.df_intra_city.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
    "    \n",
    "        # self.df_intra_city.rename(columns={'Point_speed_mean_intra_city': 'Point_speed','KmTravelled_sum_intra_city': 'Km_travelled'},inplace=True, errors='raise')\n",
    "    \n",
    "        return df_intra_city,df_inter_city\n",
    "    \n",
    "    def concat_df(self):\n",
    "        self.df_intra_city,self.df_inter_city=self.rename_columns()\n",
    "        df_grouped_cities=pd.concat([self.df_intra_city, self.df_inter_city])\n",
    "        return df_grouped_cities\n",
    "    \n",
    "    def filtering_df(self):\n",
    "        df_grouped_cities=self.concat_df()\n",
    "        df_grouped_cities = df_grouped_cities.drop(df_grouped_cities[df_grouped_cities['norm_brakes = ON']>4].index)\n",
    "        df_grouped_cities = df_grouped_cities.drop(df_grouped_cities[df_grouped_cities['norm_headway_warning(long)']>3].index)\n",
    "        df_grouped_cities = df_grouped_cities.drop(df_grouped_cities[df_grouped_cities['Point_speed']<20].index)\n",
    "        df_grouped_cities = df_grouped_cities.drop(df_grouped_cities[df_grouped_cities['Km_travelled']<50].index)\n",
    "        \n",
    "        return df_grouped_cities\n",
    "    \n",
    "    \n",
    "pre_processed_data = pre_processing(df_intra_city,df_inter_city)\n",
    "df_grouped_cities=pre_processed_data.filtering_df() \n",
    "# df_grouped_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature_to_examine(feature):\n",
    "    if feature==\"norm_headway_warning(long)\":\n",
    "        feature_name=\"Norm HW-L(I) \"\n",
    "    \n",
    "    elif feature=='norm_headway_warning(medium)':\n",
    "        feature_name=\"Norm HW-L(II) \"\n",
    "\n",
    "    elif feature=='norm_headway_warning(short)':\n",
    "        feature_name=\"Norm HW-L(III) \"\n",
    "        \n",
    "    elif feature=='Point_speed':\n",
    "        feature_name=\"Mean Point Speed \"\n",
    "        \n",
    "    elif feature=='norm_Left Lane Departure Warning = ON':\n",
    "        feature_name=\"Norm L-LDW \"\n",
    "        \n",
    "    elif feature=='norm_Right Lane Departure Warning = ON':\n",
    "        feature_name=\"Norm R-LDW \"\n",
    "        \n",
    "    elif feature=='norm_brakes = ON':\n",
    "        feature_name=\"Norm Braking Events \"\n",
    "        \n",
    "    return feature,feature_name\n",
    "\n",
    "\"\"\"Uncomment feature to be examined\"\"\"\n",
    "\n",
    "feature,feature_name=select_feature_to_examine('Point_speed')\n",
    "# feature,feature_name=select_feature_to_examine('norm_brakes = ON')\n",
    "# feature,feature_name=select_feature_to_examine('norm_headway_warning(long)')\n",
    "# feature,feature_name=select_feature_to_examine('norm_headway_warning(medium)')\n",
    "# feature,feature_name=select_feature_to_examine('norm_headway_warning(short)')\n",
    "# feature,feature_name=select_feature_to_examine('norm_Left Lane Departure Warning = ON')\n",
    "# feature,feature_name=select_feature_to_examine('norm_Right Lane Departure Warning = ON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer = pd.merge(df_intra_city, df_inter_city, on='Numberplate', how='inner') #here Numberplate is common column\n",
    "df_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer = df_outer.drop(df_outer[df_outer['norm_brakes = ON_x']>4].index)\n",
    "df_outer = df_outer.drop(df_outer[df_outer['norm_brakes = ON_y']>4].index)\n",
    "df_outer = df_outer.drop(df_outer[df_outer['norm_headway_warning(long)_x']>3].index)\n",
    "df_outer = df_outer.drop(df_outer[df_outer['norm_headway_warning(long)_y']>3].index)\n",
    "df_outer = df_outer.drop(df_outer[df_outer['Point_speed_x']<20].index)\n",
    "df_outer = df_outer.drop(df_outer[df_outer['Point_speed_y']<20].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x= feature_name+'in '\n",
    "feature_y=feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_outer.drop([' Indicators = OFF_x',\n",
    "       'Brakes = OFF_x', 'Brakes = ON_x', 'Headway Warning (long)_x',\n",
    "       'Headway Warning (medium)_x', 'Headway Warning (short)_x',\n",
    "       'Headway Warning = OFF_x', 'Lane Departure Warning = OFF_x',\n",
    "       'Left Indicator = ON_x', 'Left Lane Departure Warning = ON_x',\n",
    "       'Left and Right Indicator = ON_x', 'Right Indicator = ON_x',\n",
    "       'Right Lane Departure Warning = ON_x','norm_Indicators = OFF_x','norm_brakes = OFF_x','norm_Headway Warning = OFF_x','norm_Left Indicator = ON_x', 'norm_Left and Right Indicator = ON_x', 'norm_Right Indicator = ON_x'], axis = 1, inplace = True) \n",
    "    \n",
    "    \n",
    "df_outer.drop([' Indicators = OFF_y',\n",
    "       'Brakes = OFF_y', 'Brakes = ON_y', 'Headway Warning (long)_y',\n",
    "       'Headway Warning (medium)_y', 'Headway Warning (short)_y',\n",
    "       'Headway Warning = OFF_y', 'Lane Departure Warning = OFF_y',\n",
    "       'Left Indicator = ON_y', 'Left Lane Departure Warning = ON_y',\n",
    "       'Left and Right Indicator = ON_y', 'Right Indicator = ON_y',\n",
    "       'Right Lane Departure Warning = ON_y','norm_Indicators = OFF_y','norm_brakes = OFF_y','norm_Headway Warning = OFF_y','norm_Left Indicator = ON_y', 'norm_Left and Right Indicator = ON_y', 'norm_Right Indicator = ON_y'], axis = 1, inplace = True) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer.rename(columns={'Point_speed_x': 'Mean Point Speed in '+location,\n",
    "                         'Point_speed_y': 'Mean Point Speed '+location1,\n",
    "                         'norm_brakes = ON_x': 'Norm Braking Events in '+location,\n",
    "                         'norm_brakes = ON_y': 'Norm Braking Events '+location1,\n",
    "                         'norm_headway_warning(long)_x': 'Norm HW-L(I) in '+location,\n",
    "                         'norm_headway_warning(long)_y': 'Norm HW-L(I) '+location1,\n",
    "                         'norm_headway_warning(medium)_x': 'Norm HW-L(II) in '+location,\n",
    "                         'norm_headway_warning(medium)_y': 'Norm HW-L(II) '+location1,\n",
    "                         'norm_headway_warning(short)_x': 'Norm HW-L(III) in '+location,\n",
    "                         'norm_headway_warning(short)_y': 'Norm HW-L(III) '+location1,\n",
    "                         'norm_Right Lane Departure Warning = ON_x': 'Norm R-LDW in '+location,\n",
    "                         'norm_Right Lane Departure Warning = ON_y': 'Norm R-LDW '+location1,\n",
    "                         'norm_Left Lane Departure Warning = ON_x': 'Norm L-LDW in '+location,\n",
    "                         'norm_Left Lane Departure Warning = ON_y': 'Norm L-LDW '+location1\n",
    "                         },\n",
    "          inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.regplot(data=df_outer,x=feature_x+location, y=feature_y+location1,color=\"sandybrown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.jointplot(x=feature_x+location, y=feature_y+location1, data=df_outer, kind=\"reg\",palette=\"pastel\",color=\"sandybrown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import pandas as pd \n",
    "#  import seaborn as sns\n",
    "#  import matplotlib.pyplot as plt \n",
    "# import stats\n",
    "# import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "# sns.set(rc = {'figure.figsize':(15,8)})\n",
    "# from matplotlib import rcParams\n",
    "\n",
    "# # figure size in inches\n",
    "# rcParams['figure.figsize'] = 15,8\n",
    "\n",
    "# sandybrown\n",
    "#mediumseagreen\n",
    "#cornflowerblue\n",
    "\n",
    "# feature_x=\"Mean Point Speed in \"\n",
    "# feature_y=\"Mean Point Speed \"\n",
    "# sns.set_style(\"ticks\")\n",
    "# df = pd.read_excel('data.xlsx')\n",
    "# assume some random columns called EAV and PAV in your DataFrame \n",
    "# assume a third variable used for grouping called \"Mammal\" which will be used for color coding\n",
    "p = sns.lmplot(x=feature_x+location, y=feature_y+location1,\n",
    "        data=df_outer,scatter_kws={\"color\": \"sandybrown\"},\n",
    "        line_kws={'label':\"Linear Reg\",\"color\":\"sandybrown\"}, legend=True)\n",
    "\n",
    "ax = p.axes[0, 0]\n",
    "ax.legend()\n",
    "leg = ax.get_legend()\n",
    "L_labels = leg.get_texts()\n",
    "# assuming you computed r_squared which is the coefficient of determination somewhere else\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_outer[feature_x+location],df_outer[feature_y+location1])\n",
    "label_line_1 = r'$y={0:.1f}x+{1:.1f}'.format(slope,intercept)\n",
    "label_line_2 = r'$r:{0:.2f}$'.format(r_value) # as an exampple or whatever you want[!\n",
    "# L_labels[0].set_text(label_line_1)\n",
    "L_labels[0].set_text(label_line_2)\n",
    "\n",
    "plt.xlabel(feature_x+location, fontsize=14)\n",
    "plt.ylabel(feature_y+location1, fontsize=14)\n",
    "# ax.xlabel(feature_x+location,fontsize=10)\n",
    "plt.savefig(r\"C:\\Users\\ivasu\\Desktop\\p1.png\")\n",
    "# plt.title(\"Normalized Braking Events - Amsterdam & the NL (Urban Roads)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    def __init__(self,feature,feature_name,df,increment,decrement):\n",
    "        self.feature = feature\n",
    "        self.feature_name = feature_name\n",
    "        self.df=df\n",
    "        self.increment =increment\n",
    "        self.decrement =decrement\n",
    "        \n",
    "    def preprocess(self,df):\n",
    "        \"\"\"Preprocess data for KMeans clustering\"\"\"\n",
    "    \n",
    "        data = np.array(self.df[self.feature])\n",
    "        data=data.reshape(-1, 1)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(data)\n",
    "        data = scaler.transform(data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def elbow_plot(self):\n",
    "        \"\"\"Create elbow plot from normalized data\"\"\"\n",
    "        data=self.preprocess(self.df)\n",
    "        sse = {}\n",
    "        \n",
    "        for k in range(2,11):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "            kmeans.fit(data)\n",
    "            sse[k] = kmeans.inertia_\n",
    "        \n",
    "        plt.title('Elbow plot for K selection'+\"\\n\"+feature_name+'-'+ city_name)\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('SSE')\n",
    "        sns.pointplot(x=list(sse.keys()),y=list(sse.values()),color=\"sandybrown\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def silhouette_coeff(self):\n",
    "        \"\"\"Checking silhouette score\"\"\"\n",
    "        data=self.preprocess(self.df)\n",
    "        range_n_clusters = range(2,10)\n",
    "        \n",
    "        for n_clusters in range_n_clusters:\n",
    "            clusterer = KMeans(n_clusters=n_clusters)\n",
    "            preds = clusterer.fit_predict(data)\n",
    "            centers = clusterer.cluster_centers_ \n",
    "\n",
    "            score = silhouette_score(data, preds)\n",
    "            print(\"For n_clusters = {}, silhouette score is {})\".format(n_clusters, score))\n",
    "            \n",
    "            \n",
    "    def find_k(self):\n",
    "        \"\"\"Find the optimum k clusters\"\"\"\n",
    "        \n",
    "        data=self.preprocess(self.df)\n",
    "        sse = {}\n",
    "        \n",
    "        for k in range(2, 21):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "            kmeans.fit(data)\n",
    "            sse[k] = kmeans.inertia_\n",
    "        \n",
    "        kn = KneeLocator(x=list(sse.keys()), \n",
    "                    y=list(sse.values()), \n",
    "                    curve='convex', \n",
    "                    direction='decreasing')\n",
    "        k = kn.knee + self.increment - self.decrement\n",
    "        return k\n",
    "    \n",
    "    \n",
    "    def run_kmeans(self):\n",
    "        \"\"\"Run KMeans clustering, including the preprocessing of the data\n",
    "        and the automatic selection of the optimum k. \n",
    "        \"\"\"\n",
    "\n",
    "        data=self.preprocess(self.df)\n",
    "        k = self.find_k()\n",
    "        print(k)\n",
    "        kmeans = KMeans(n_clusters=k,init='k-means++')\n",
    "        x=kmeans.fit_predict(data)\n",
    "        return self.df.assign(Clusters=kmeans.labels_)\n",
    "    \n",
    "\n",
    "clustering_kmeans = Clustering(feature,feature_name,df_grouped_cities,increment=0, decrement=2) # increase or decrease number of assigned clusters using `increment` or `decrement`\n",
    "clustering_kmeans.elbow_plot() \n",
    "clustering_kmeans.silhouette_coeff()\n",
    "Clusters=clustering_kmeans.run_kmeans()\n",
    "# Clusters\n",
    "# df_grouped_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_classes():\n",
    "    sns.set_palette(\"CMRmap\")\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==0][feature],label=\"0\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==1][feature],label=\"1\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==2][feature],label=\"2\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==3][feature],label=\"3\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==4][feature],label=\"4\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(Clusters[Clusters['Clusters']==5][feature],label=\"5\",fill=True,alpha=0.5,linewidth=2)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.title(r\"Distribution of \"+feature_name+\" in \"+ city_name)\n",
    "    # plt.title(r\"Distribution of \"+feature_name+\" in \"+ city_name + \"\\n\"+\" and the NL (Urban Roads) - Clusters\")\n",
    "    plt.xlabel(feature_name)\n",
    "    \n",
    "viz_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intra_city.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def processing_data_plots(df_clusters):\n",
    "    df_city=df_clusters.loc[df_clusters['City'] == city_name]\n",
    "    df_not_city=df_clusters.loc[df_clusters['City'] == city_name+\"_complete\"]\n",
    "    \n",
    "    sns.set_palette(\"CMRmap\")\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==0][feature],label=\"0\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==1][feature],label=\"1\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==2][feature],label=\"2\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==3][feature],label=\"3\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==4][feature],label=\"4\",fill=True,alpha=0.5,linewidth=2)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.title(r\"Distribution of \"+ feature_name+\" in \"+city_name)\n",
    "    plt.xlabel(feature_name)\n",
    "    \n",
    "    \n",
    "    df_city.drop([' Indicators = OFF',\n",
    "       'Brakes = OFF', 'Brakes = ON', 'Headway Warning (long)',\n",
    "       'Headway Warning (medium)', 'Headway Warning (short)',\n",
    "       'Headway Warning = OFF', 'Lane Departure Warning = OFF',\n",
    "       'Left Indicator = ON', 'Left Lane Departure Warning = ON',\n",
    "       'Left and Right Indicator = ON', 'Right Indicator = ON',\n",
    "       'Right Lane Departure Warning = ON','norm_Indicators = OFF','norm_brakes = OFF','norm_Headway Warning = OFF','norm_Left Indicator = ON', 'norm_Left and Right Indicator = ON', 'norm_Right Indicator = ON'], axis = 1, inplace = True) \n",
    "    \n",
    "    \n",
    "    df_not_city.drop([ \n",
    "       'Brakes = OFF', 'Brakes = ON', 'Headway Warning (long)',\n",
    "       'Headway Warning (medium)', 'Headway Warning (short)',\n",
    "       'Headway Warning = OFF', 'Lane Departure Warning = OFF',\n",
    "       'Left Indicator = ON', 'Left Lane Departure Warning = ON',\n",
    "       'Left and Right Indicator = ON', 'Right Indicator = ON',\n",
    "       'Right Lane Departure Warning = ON','norm_Indicators = OFF','norm_brakes = OFF','norm_Headway Warning = OFF','norm_Left Indicator = ON', 'norm_Left and Right Indicator = ON', 'norm_Right Indicator = ON'], axis = 1, inplace = True) \n",
    "    \n",
    "    df_city.reset_index(drop=True)\n",
    "    df_city['Numberplate'] = df_city['Numberplate'].astype(str)\n",
    "    df_city['City'] = df_city['City'].astype(str)\n",
    "    df_not_city['Numberplate'] = df_not_city['Numberplate'].astype(str)\n",
    "    df_not_city['City'] = df_not_city['City'].astype(str)\n",
    "    \n",
    "    return df_city,df_not_city\n",
    "\n",
    "    \n",
    "df_city,df_not_city=processing_data_plots(Clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "sns.set_palette(\"CMRmap\")\n",
    "ax = sns.boxplot(x=Clusters['Clusters'],y=Clusters[feature],fliersize=5)\n",
    "for patch in ax.artists:\n",
    "    fc = patch.get_facecolor()\n",
    "    patch.set_facecolor(mpl.colors.to_rgba(fc, 0.7))\n",
    "\n",
    "plt.ylabel(feature_name+\" - \"+ city_name)\n",
    "# plt.ylabel(feature_name)\n",
    "plt.xlabel(\"Cluster\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city_cluster0=df_city[df_city['Clusters']==0]\n",
    "df_city_cluster0_nums=list(df_city_cluster0['Numberplate'])\n",
    "\n",
    "df_city_cluster1=df_city[df_city['Clusters']==1]\n",
    "df_city_cluster1_nums=list(df_city_cluster1['Numberplate'])\n",
    "\n",
    "df_city_cluster2=df_city[df_city['Clusters']==2]\n",
    "df_city_cluster2_nums=list(df_city_cluster2['Numberplate'])\n",
    "\n",
    "df_city_cluster3=df_city[df_city['Clusters']==3]\n",
    "df_city_cluster3_nums=list(df_city_cluster3['Numberplate'])\n",
    "\n",
    "df_city_cluster4=df_city[df_city['Clusters']==4]\n",
    "df_city_cluster4_nums=list(df_city_cluster4['Numberplate'])\n",
    "\n",
    "df_city_cluster5=df_city[df_city['Clusters']==5]\n",
    "df_city_cluster5_nums=list(df_city_cluster5['Numberplate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "df_not_city_cluster0_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster0_nums)]\n",
    "df_not_city_cluster0_nums['Cluster_city']=0\n",
    "df_not_city_cluster1_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster1_nums)]\n",
    "df_not_city_cluster1_nums['Cluster_city']=1\n",
    "df_not_city_cluster2_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster2_nums)]\n",
    "df_not_city_cluster2_nums['Cluster_city']=2\n",
    "df_not_city_cluster3_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster3_nums)]\n",
    "df_not_city_cluster3_nums['Cluster_city']=3\n",
    "df_not_city_cluster4_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster4_nums)]\n",
    "df_not_city_cluster4_nums['Cluster_city']=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dataframes=[df_not_city_cluster0_nums,df_not_city_cluster1_nums,df_not_city_cluster2_nums,df_not_city_cluster3_nums]\n",
    "df_not_city_new_clus = pd.concat(list_of_dataframes)\n",
    "df_not_city_new_clus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "ax = sns.boxplot(x=df_not_city_new_clus['Cluster_city'],y=df_not_city_new_clus[feature],fliersize=5)\n",
    "for patch in ax.artists:\n",
    "    fc = patch.get_facecolor()\n",
    "    patch.set_facecolor(mpl.colors.to_rgba(fc, 0.7))\n",
    "    \n",
    "plt.ylabel(feature_name+\" across the NL\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.title(feature_name+ \" of corresponding \"+\"\\n\"+r\"vehicles based on cluster assigned in \"+city_name)\n",
    "# plt.ylim(-0.1,1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer = pd.merge(df_city, df_not_city_new_clus, on='Numberplate', how='inner') #here Numberplate is common column\n",
    "# df_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer.rename(columns={'Point_speed_x': 'Mean Point Speed in '+location,\n",
    "                         'Point_speed_y': 'Mean Point Speed '+location1,\n",
    "                         'norm_brakes = ON_x': 'Norm Braking Events in '+location,\n",
    "                         'norm_brakes = ON_y': 'Norm Braking Events '+location1,\n",
    "                         'norm_headway_warning(long)_x': 'Norm L(I)-HW in '+location,\n",
    "                         'norm_headway_warning(long)_y': 'Norm L(I)-HW '+location1,\n",
    "                         'norm_headway_warning(medium)_x': 'Norm L(II)-HW in '+location,\n",
    "                         'norm_headway_warning(medium)_y': 'Norm L(II)-HW '+location1,\n",
    "                         'norm_headway_warning(short)_x': 'Norm L(III)-HW in '+location,\n",
    "                         'norm_headway_warning(short)_y': 'Norm L(III)-HW '+location1,\n",
    "                         'norm_Right Lane Departure Warning = ON_x': 'Norm R-LDW in '+location,\n",
    "                         'norm_Right Lane Departure Warning = ON_y': 'Norm R-LDW '+location1,\n",
    "                         'norm_Left Lane Departure Warning = ON_x': 'Norm L-LDW in '+location,\n",
    "                         'norm_Left Lane Departure Warning = ON_y': 'Norm L-LDW '+location1\n",
    "                         },\n",
    "          inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x= feature_name+'in '\n",
    "feature_y=feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"CMRmap\")\n",
    "feature_name_x=\"Mean Point Speed in \"\n",
    "feature_name_y=\"Mean Point Speed \"\n",
    "sns.scatterplot(data=df_outer[df_outer['Clusters_x']==0],x=feature_name_x+location,y=feature_name_y+location1,alpha=0.8,label=0)\n",
    "sns.scatterplot(data=df_outer[df_outer['Clusters_x']==1],x=feature_name_x+location,y=feature_name_y+location1,alpha=0.8,label=1)\n",
    "sns.scatterplot(data=df_outer[df_outer['Clusters_x']==2],x=feature_name_x+location,y=feature_name_y+location1,alpha=0.8,label=2)\n",
    "sns.scatterplot(data=df_outer[df_outer['Clusters_x']==3],x=feature_name_x+location,y=feature_name_y+location1,alpha=0.8,label=3)\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.xlabel(feature_x+city_name)\n",
    "plt.ylabel(feature_y+\" across the NL\" +\"\\n\"+\"(urban roads)\")\n",
    "plt.title(feature_y+\" of vehicles \"+\"\\n\"+\"and their corresponding clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outer.to_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering City\\Clustering_results\\df_outer_hw_norm_l1_amsterdam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outer=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Individual Clustering City\\Clustering_results\\df_outer_hw_norm_l1_amsterdam.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kentekens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kentekens=pd.read_csv(r\"C:\\Users\\ivasu\\Desktop\\Robotics\\2021-2022\\Thesis\\code\\DataAnalysis\\CarrierWeb\\Data\\kentekens_iva.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer_kentekens = pd.merge(kentekens, df_outer, on='Numberplate', how='inner') #here Numberplate is the common column\n",
    "df_outer_kentekens['Power_int']=df_outer_kentekens[\"Power\"].str[0:3]\n",
    "df_outer_kentekens['Power_int'] = df_outer_kentekens['Power_int'].astype('int')\n",
    "\n",
    "df_outer_kentekens.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer_kentekens = df_outer_kentekens.drop(df_outer_kentekens[df_outer_kentekens['Cylinder capacity']=='onbekend'].index)\n",
    "df_outer_kentekens['Cylinder capacity']=df_outer_kentekens[\"Cylinder capacity\"].str[0:5]\n",
    "df_outer_kentekens['Cylinder_capacity_int'] = df_outer_kentekens['Cylinder capacity'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_df=pd.read_csv(r\"D:\\AOS FOT\\Octo\\CSV Export\\Other Tables\\BCI - Copy.csv\",delimiter=';', encoding='unicode_escape')\n",
    "# bic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city_cluster_true_kentekens_more_info= pd.merge(df_outer_kentekens, bic_df, on='Numberplate', how='inner') #here Numberplate is common column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Important columns\n",
    "\n",
    "- Year\n",
    "- Mass empty vehicle\n",
    "- Brand\n",
    "- Transporter\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_city_cluster_true_kentekens_more_info[['Numberplate','Brand_x','Year','Mass empty vehicle','Cylinder capacity','Power_int','Transporter']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discussion = pd.merge(df, df_outer, on='Numberplate', how='inner') #here Numberplate is the common column\n",
    "# df_discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discussion['Mass_empty_vehicle_int']=df_discussion[\"Mass empty vehicle\"].str[0:5]\n",
    "df_discussion['Mass_empty_vehicle_int'] = df_discussion['Mass_empty_vehicle_int'].astype('int')\n",
    "df_discussion['Year'] = df_discussion['Year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discussion['cluster_comp'] = np.where(df_discussion['Clusters_x']==df_discussion['Clusters_y'], 'True', 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_discussion[df_discussion['cluster_comp']=='True']\n",
    "# a['clusters_utrecht'].value_counts()\n",
    "len(df_discussion[df_discussion['cluster_comp']=='True'])/len(df_discussion)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Clusters_x'].value_counts()/len(a)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discussion_cluster1=df_discussion[df_discussion['Clusters_x']==1]\n",
    "# df_discussion_cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_discussion[df_discussion['Clusters_x']==0],x=\"Power_int\",y=\"Norm L(I)-HW in \"+city_name,hue='Transporter')\n",
    "plt.xlabel(\"Power (kW)\")\n",
    "plt.ylabel(\"Norm L(I)-HW\")\n",
    "plt.legend(loc='best', bbox_to_anchor=(1., 0., 0.0, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_discussion[df_discussion['Clusters_x']==2],x=\"Power_int\",y=\"Norm L(I)-HW in \"+city_name,hue='Transporter')\n",
    "plt.xlabel(\"Power (kW)\")\n",
    "plt.ylabel(\"Norm L(I)-HW\")\n",
    "plt.legend(loc='best', bbox_to_anchor=(1., 0., 0.0, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discussion_cluster1=df_discussion[df_discussion['Clusters_x']==1]\n",
    "df_discussion_cluster0=df_discussion[df_discussion['Clusters_x']==0]\n",
    "df_discussion_cluster2=df_discussion[df_discussion['Clusters_x']==2]\n",
    "df_discussion_cluster3=df_discussion[df_discussion['Clusters_x']==3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discussion_cluster1_transporter=df_discussion_cluster1['Transporter'].value_counts()\n",
    "df_discussion_cluster0_transporter=df_discussion_cluster0['Transporter'].value_counts()\n",
    "df_discussion_cluster2_transporter=df_discussion_cluster2['Transporter'].value_counts()\n",
    "df_discussion_cluster3_transporter=df_discussion_cluster3['Transporter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_discussion_transporte_cluster_comp=df_discussion['cluster_comp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discussion_transporter=df_discussion['Transporter'].value_counts()\n",
    "# df_discussion_transporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "  \n",
    "# intialise data of lists.\n",
    "data = {'All Transporter':df_discussion_transporter,\n",
    "        'Cluster1':df_discussion_cluster1_transporter,\n",
    "        'Perc_cluster1':(df_discussion_cluster1_transporter/df_discussion_transporter)*100,\n",
    "        'Cluster0':df_discussion_cluster0_transporter,\n",
    "        'Perc_cluster0':(df_discussion_cluster0_transporter/df_discussion_transporter)*100,\n",
    "        'Cluster2':df_discussion_cluster2_transporter,\n",
    "        'Perc_cluster2':(df_discussion_cluster2_transporter/df_discussion_transporter)*100,\n",
    "        'Cluster3':df_discussion_cluster3_transporter,\n",
    "        'Perc_cluster3':(df_discussion_cluster3_transporter/df_discussion_transporter)*100,\n",
    "        'Cluster_Comp':df_discussion_transporte_cluster_comp}\n",
    "  \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "  \n",
    "# Print the output.\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_50_clustrer1=df[df['Perc_cluster1']>50]\n",
    "list_of_vehicles_cluster1_50=list(df_50_clustrer1['index'])\n",
    "\n",
    "df_50_clustrer1_complete_info = df_discussion[df_discussion['Transporter'].isin(list_of_vehicles_cluster1_50)]\n",
    "df_50_clustrer1_complete_info=df_50_clustrer1_complete_info[df_50_clustrer1_complete_info['Cluster_city']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_50_clustrer1_complete_info,x=\"Mass_empty_vehicle_int\",y=\"Norm L(I)-HW in \"+city_name,hue='Transporter')\n",
    "plt.xlabel(\"Mass (kg)\")\n",
    "plt.ylabel(\"Norm L(I)-HW\")\n",
    "plt.legend(loc='best', bbox_to_anchor=(1., 0.55, 0.0, 0.5))\n",
    "plt.title(\"Headway Warnings vs Mass of vehicle (kg)\"+\"\\n\"+\"(Transport companies with majority of driver assigned lowest cluster)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_50_clustrer1_complete_info,x=\"Power_int\",y=\"Norm L(I)-HW in \"+city_name,hue='Transporter')\n",
    "plt.xlabel(\"Power (kW)\")\n",
    "plt.ylabel(\"Norm L(I)-HW\")\n",
    "plt.legend(loc='best', bbox_to_anchor=(1., 0.1, 0.0, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_50_clustrer0=df[df['Perc_cluster2']>50]\n",
    "list_of_vehicles_cluster0_50=list(df_50_clustrer0['index'])\n",
    "\n",
    "df_50_clustrer0_complete_info = df_discussion[df_discussion['Transporter'].isin(list_of_vehicles_cluster0_50)]\n",
    "df_50_clustrer0_complete_info=df_50_clustrer0_complete_info[df_50_clustrer0_complete_info['Cluster_city']==2]\n",
    "# df_50_clustrer0_complete_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_50_clustrer0_complete_info,x=\"Power_int\",y=\"Norm L(I)-HW in \"+city_name,hue='Brand_x')\n",
    "plt.xlabel(\"Power (kW)\")\n",
    "plt.ylabel(\"Norm L(I)-HW\")\n",
    "# plt.legend(loc='best', bbox_to_anchor=(1., 0.55, 0.0, 0.5))\n",
    "plt.title(\"Headway Warnings vs Power (kW)\"+\"\\n\"+\"(Transport companies with majority of driver assigned lowest cluster)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_discussion[df_discussion['cluster_comp']=='True']\n",
    "a['Cluster_city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exploring indi clusters\n",
    "sns.scatterplot(data=df_discussion[df_discussion['Cluster_city']==1],x=\"Mass_empty_vehicle_int\",y=\"Norm L(I)-HW in \"+city_name)\n",
    "plt.xlabel(\"Mass (kg)\")\n",
    "plt.ylabel(\"Norm L(I)-HW\")\n",
    "# plt.legend(loc='best', bbox_to_anchor=(1., 0.55, 0.0, 0.5))\n",
    "plt.title(\"Headway Warnings vs Mass of vehicle (kg)\"+\"\\n\"+\"(Transport companies with majority of driver assigned lowest cluster)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.kdeplot(df_discussion['Mass_empty_vehicle_int'],hue=df_discussion['Cluster_city'],linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"CMRmap\")\n",
    "sns.jointplot(data=df_discussion,x=\"Mass_empty_vehicle_int\",y=\"Power_int\",hue=\"Cluster_city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "sns.set_palette(\"CMRmap\")\n",
    "ax = sns.boxplot(x=df_city['Clusters'],y=df_city[feature],fliersize=5)\n",
    "for patch in ax.patches:\n",
    "    r, g, b, a = patch.get_facecolor()\n",
    "    patch.set_facecolor((r, g, b, .82))\n",
    "\n",
    "plt.ylabel(feature_name+\" - \"+ city_name,fontsize=15)\n",
    "# plt.ylabel(feature_name)\n",
    "plt.xlabel(\"Cluster\",fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_city_cluster0_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster0_nums)]\n",
    "df_not_city_cluster0_nums['Cluster_city']=0\n",
    "df_not_city_cluster1_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster1_nums)]\n",
    "df_not_city_cluster1_nums['Cluster_city']=1\n",
    "df_not_city_cluster2_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster2_nums)]\n",
    "df_not_city_cluster2_nums['Cluster_city']=2\n",
    "df_not_city_cluster3_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster3_nums)]\n",
    "df_not_city_cluster3_nums['Cluster_city']=3\n",
    "df_not_city_cluster4_nums = df_not_city[df_not_city['Numberplate'].isin(df_city_cluster4_nums)]\n",
    "df_not_city_cluster4_nums['Cluster_city']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dataframes=[df_not_city_cluster0_nums,df_not_city_cluster1_nums,df_not_city_cluster2_nums,df_not_city_cluster3_nums]\n",
    "df_not_city_new_clus = pd.concat(list_of_dataframes)\n",
    "# df_not_city_new_clus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "sns.set_context(\"notebook\")\n",
    "ax = sns.boxplot(x=df_not_city_new_clus['Cluster_city'],y=df_not_city_new_clus[feature],fliersize=5)\n",
    "for patch in ax.patches:\n",
    "    r, g, b, a = patch.get_facecolor()\n",
    "    patch.set_facecolor((r, g, b, .82))\n",
    "    \n",
    "plt.ylabel(feature_name+\" across cities in the NL\",fontsize=15)\n",
    "plt.xlabel(\"Cluster\",fontsize=15)\n",
    "plt.title(feature_name+ \" of corresponding \"+\"\\n\"+r\"vehicles based on cluster assigned in \"+city_name,fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_discussion[df_discussion['Cluster_city']==0]['Power_int'].median()\n",
    "df_discussion[df_discussion['Cluster_city']==0]['Mass_empty_vehicle_int'].median()\n",
    "# Mass_empty_vehicle_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_discussion[df_discussion['Cluster_city']==1]['Power_int'].median()\n",
    "df_discussion[df_discussion['Cluster_city']==1]['Mass_empty_vehicle_int'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_discussion[df_discussion['Cluster_city']==2]['Power_int'].median()\n",
    "df_discussion[df_discussion['Cluster_city']==2]['Mass_empty_vehicle_int'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discussion[df_discussion['Cluster_city']==3]['Power_int'].median()\n",
    "# df_discussion[df_discussion['Cluster_city']==3]['Mass_empty_vehicle_int'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_2 = sns.color_palette([\"slateblue\",\"rebeccapurple\",\"palevioletred\",\"coral\"])\n",
    "# palette_2\n",
    "sns.boxplot(x=df_discussion['Cluster_city'],y=df_discussion['Power_int'],palette=palette_2)\n",
    "plt.ylabel(\"Power (kW)\",fontsize=15)\n",
    "plt.xlabel(\"Clusters\",fontsize=15)\n",
    "plt.title(\"Engine Power of different clusters in Amsterdam\"+\"\\n\"+\"(Feature for clustering - \"+ feature_name+\")\",fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discussion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_classes():\n",
    "    sns.set_palette(\"CMRmap\")\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==0][feature],label=\"0\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==1][feature],label=\"1\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==2][feature],label=\"2\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==3][feature],label=\"3\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==4][feature],label=\"4\",fill=True,alpha=0.5,linewidth=2)\n",
    "    sns.kdeplot(df_city[df_city['Clusters']==5][feature],label=\"5\",fill=True,alpha=0.5,linewidth=2)\n",
    "    plt.legend(title=\"Cluster\",fontsize=15)\n",
    "    # plt.title(r\"Distribution of \"+feature_name+\" in \"+ city_name)\n",
    "    plt.title(r\"Distribution of \"+feature_name+\" in \"+ city_name,fontsize=15)\n",
    "    plt.xlabel(feature_name,fontsize=15)\n",
    "    plt.ylabel(\"Density\",fontsize=15)\n",
    "viz_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette_2 = sns.color_palette([\"slateblue\",\"coral\",\"rebeccapurple\",\"palevioletred\"])\n",
    "palette_2 = sns.color_palette([\"slateblue\",\"rebeccapurple\",\"palevioletred\",\"coral\"])\n",
    "palette_2\n",
    "sns.set_palette(\"CMRmap\")\n",
    "sns.kdeplot(data=df_discussion,x=\"Power_int\",hue=\"Cluster_city\",linewidth=3,palette=palette_2)\n",
    "plt.xlabel(\"Power (kW)\")\n",
    "plt.title(\"Power distribution of different clusters in Amsterdam\"+\"\\n\"+\"(Feature for Clustering-Mean Point Speed)\")\n",
    "# plt.legend(title='Cluster')\n",
    "# plt.legend(title=\"Cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette_2 = sns.color_palette([\"slateblue\",\"coral\",\"rebeccapurple\",\"palevioletred\"])\n",
    "palette_2 = sns.color_palette([\"slateblue\",\"rebeccapurple\",\"palevioletred\",\"coral\"])\n",
    "palette_2\n",
    "sns.set_palette(\"CMRmap\")\n",
    "sns.boxplot(data=df_discussion,y=\"Mass_empty_vehicle_int\",x=\"Cluster_city\",palette=palette_2)\n",
    "plt.ylabel(\"Mass empty vehicle (kg)\")\n",
    "plt.xlabel(\"Clusters\")\n",
    "# plt.title(\"Power distribution of different clusters in Amsterdam\"+\"\\n\"+\"(Feature for Clustering-Norm HW-L(I))\")\n",
    "# plt.legend(title='Cluster')\n",
    "# plt.legend(title=\"Cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette_2 = sns.color_palette([\"slateblue\",\"coral\",\"rebeccapurple\",\"palevioletred\"])\n",
    "palette_2 = sns.color_palette([\"slateblue\",\"rebeccapurple\",\"palevioletred\",\"coral\"])\n",
    "palette_2\n",
    "sns.set_palette(\"CMRmap\")\n",
    "sns.boxplot(data=df_outer_kentekens,y=\"Power_int\",x=\"Cluster_city\",palette=palette_2)\n",
    "plt.ylabel(\"Power (kW)\",fontsize=15)\n",
    "plt.xlabel(\"Clusters\",fontsize=15)\n",
    "plt.title(\"Engine Power of different clusters in Amsterdam\"+\"\\n\"+\"(Feature for clustering - \"+ feature_name+\")\",fontsize=15)\n",
    "# plt.legend(title='Cluster')\n",
    "# plt.legend(title=\"Cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette_2 = sns.color_palette([\"slateblue\",\"coral\",\"rebeccapurple\",\"palevioletred\"])\n",
    "palette_2 = sns.color_palette([\"slateblue\",\"rebeccapurple\",\"palevioletred\",\"coral\"])\n",
    "palette_2\n",
    "sns.set_palette(\"CMRmap\")\n",
    "sns.boxplot(data=df_outer_kentekens,y=\"Cylinder_capacity_int\",x=\"Cluster_city\",palette=palette_2)\n",
    "plt.ylabel(\"Engine Capacity (cc)\")\n",
    "plt.xlabel(\"Clusters\")\n",
    "plt.title(\"Engine capacity of different clusters in Amsterdam\"+\"\\n\"+\"(Feature for clustering - \"+ feature_name+\")\")\n",
    "# plt.legend(title='Cluster')\n",
    "# plt.legend(title=\"Cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discussion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_2 = sns.color_palette([\"slateblue\",\"rebeccapurple\",\"palevioletred\",\"coral\"])\n",
    "palette_2\n",
    "sns.set_palette(\"CMRmap\")\n",
    "sns.kdeplot(data=df_outer_kentekens,x=\"Cylinder_capacity_int\",hue=\"Cluster_city\",linewidth=3,palette=palette_2)\n",
    "plt.xlabel(\"Engine Capacity (cc)\")\n",
    "plt.title(\"Engine Capacity of different clusters in Amsterdam \"+\"\\n\"+\"(Feature for Clustering-Mean Point Speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_2 = sns.color_palette([\"slateblue\",\"rebeccapurple\",\"palevioletred\",\"coral\"])\n",
    "palette_2\n",
    "sns.set_palette(\"CMRmap\")\n",
    "sns.kdeplot(data=df_outer_kentekens,x=\"Power_int\",hue=\"Cluster_city\",linewidth=3,palette=palette_2)\n",
    "plt.xlabel(\"Power (kW)\")\n",
    "plt.title(\"Power distribution of different clusters in Amsterdam \"+\"\\n\"+\"(Feature for Clustering-Mean Point Speed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discussion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df_outer_kentekens,x=\"Cylinder_capacity_int\",hue=\"Cluster_city\",linewidth=3)\n",
    "plt.xlabel(\"Power (kW)\")\n",
    "plt.title(\"Power (kW) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_norml1_hw=pd.read_excel(r\"C:\\Users\\ivasu\\Desktop\\Robotics\\2021-2022\\Thesis\\code\\DataAnalysis\\CarrierWeb\\Data\\Book12.xlsx\")\n",
    "city_norml1_hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y=city_norml1_hw[\"Power (kW)\"],x=city_norml1_hw[\"Cluster \"],hue=city_norml1_hw[\"City\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2cfa282833ad131b813daadc2d579e64b9e3379708ebc6d12c1926855f4c941"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
